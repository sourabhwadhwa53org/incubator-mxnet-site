{"nbformat": 4, "cells": [{"source": "<!--- Licensed to the Apache Software Foundation (ASF) under one -->\n<!--- or more contributor license agreements.  See the NOTICE file -->\n<!--- distributed with this work for additional information -->\n<!--- regarding copyright ownership.  The ASF licenses this file -->\n<!--- to you under the Apache License, Version 2.0 (the -->\n<!--- \"License\"); you may not use this file except in compliance -->\n<!--- with the License.  You may obtain a copy of the License at -->\n\n<!---   http://www.apache.org/licenses/LICENSE-2.0 -->\n\n<!--- Unless required by applicable law or agreed to in writing, -->\n<!--- software distributed under the License is distributed on an -->\n<!--- \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY -->\n<!--- KIND, either express or implied.  See the License for the -->\n<!--- specific language governing permissions and limitations -->\n<!--- under the License. -->\n\n# Distributed Key-Value Store\n\nKVStore is a place for data sharing. Think of it as a single object shared\nacross different devices (GPUs and computers), where each device can push data in\nand pull data out.\n\n## Initialization\n\nLet's consider a simple example: initializing\na (`int`, `NDArray`) pair into the store, and then pulling the value out:", "cell_type": "markdown", "metadata": {}}, {"source": "import mxnet as mx\n\nkv = mx.kv.create('local') # create a local kv store.\nshape = (2,3)\nkv.init(3, mx.nd.ones(shape)*2)\na = mx.nd.zeros(shape)\nkv.pull(3, out = a)\nprint(a.asnumpy())", "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {}}, {"source": "## Push, Aggregate, and Update\n\nFor any key that has been initialized, you can push a new value with the same shape to the key:", "cell_type": "markdown", "metadata": {}}, {"source": "kv.push(3, mx.nd.ones(shape)*8)\nkv.pull(3, out = a) # pull out the value\nprint(a.asnumpy())", "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {}}, {"source": "The data for pushing can be stored on any device. Furthermore, you can push multiple\nvalues into the same key, where KVStore will first sum all of these\nvalues and then push the aggregated value. Here we will just demonstrate pushing a list of values on CPU.\nPlease note summation only happens if the value list is longer than one", "cell_type": "markdown", "metadata": {}}, {"source": "contexts = [mx.cpu(i) for i in range(4)]\nb = [mx.nd.ones(shape, ctx) for ctx in contexts]\nkv.push(3, b)\nkv.pull(3, out = a)\nprint(a.asnumpy())", "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {}}, {"source": "For each push, KVStore combines the pushed value with the value stored using an\n`updater`. The default updater is `ASSIGN`. You can replace the default to\ncontrol how data is merged:", "cell_type": "markdown", "metadata": {}}, {"source": "def update(key, input, stored):\n    print(\"update on key: %d\" % key)\n    stored += input * 2\nkv._set_updater(update)\nkv.pull(3, out=a)\nprint(a.asnumpy())", "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {}}, {"source": "kv.push(3, mx.nd.ones(shape))\nkv.pull(3, out=a)\nprint(a.asnumpy())", "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {}}, {"source": "## Pull\n\nYou've already seen how to pull a single key-value pair. Similarly, to push, you can\npull the value onto several devices with a single call:", "cell_type": "markdown", "metadata": {}}, {"source": "b = [mx.nd.ones(shape, ctx) for ctx in contexts]\nkv.pull(3, out = b)\nprint(b[1].asnumpy())", "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {}}, {"source": "## Handle a List of Key-Value Pairs\n\nAll operations introduced so far involve a single key. KVStore also provides\nan interface for a list of key-value pairs. \n\nFor a single device:", "cell_type": "markdown", "metadata": {}}, {"source": "keys = [5, 7, 9]\nkv.init(keys, [mx.nd.ones(shape)]*len(keys))\nkv.push(keys, [mx.nd.ones(shape)]*len(keys))\nb = [mx.nd.zeros(shape)]*len(keys)\nkv.pull(keys, out = b)\nprint(b[1].asnumpy())", "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {}}, {"source": "For multiple devices:", "cell_type": "markdown", "metadata": {}}, {"source": "b = [[mx.nd.ones(shape, ctx) for ctx in contexts]] * len(keys)\nkv.push(keys, b)\nkv.pull(keys, out = b)\nprint(b[1][1].asnumpy())", "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {}}, {"source": "\n\n\n\n\n## Run on Multiple Machines\nBased on parameter server, the `updater` runs on the server nodes.\nWhen the distributed version is ready, we will update this section.\n\n\n<!-- ## How to Choose Between APIs -->\n\n<!-- You can mix APIs as much as you like. Here are some guidelines -->\n<!-- * Use the Symbolic API and a coarse-grained operator to create  an established structure. -->\n<!-- * Use a fine-grained operator to extend parts of a more flexible symbolic graph. -->\n<!-- * Do some dynamic NDArray tricks, which are even more flexible, between the calls of forward and backward executors. -->\n\n<!-- Different approaches offer you different levels of flexibility and -->\n<!-- efficiency. Normally, you do not need to be flexible in all parts of the -->\n<!-- network, so use the parts optimized for speed, and compose it -->\n<!-- flexibly with a fine-grained operator or a dynamic NDArray. Such a -->\n<!-- mixture allows you to build the deep learning architecture both efficiently and -->\n<!-- flexibly as your choice.  -->\n\n## Next Steps\n* [MXNet tutorials index](http://mxnet.io/tutorials/index.html)\n\n<!-- INSERT SOURCE DOWNLOAD BUTTONS -->\n\n", "cell_type": "markdown", "metadata": {}}], "metadata": {"display_name": "", "name": "", "language": "python"}, "nbformat_minor": 2}