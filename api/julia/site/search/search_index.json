{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"MXNet Documentation MXNet.jl is the Julia package of dmlc/mxnet . MXNet.jl brings flexible and efficient GPU computing and state-of-art deep learning to Julia. Some highlight of features include: Efficient tensor/matrix computation across multiple devices, including multiple CPUs, GPUs and distributed server nodes. Flexible symbolic manipulation to composite and construct state-of-the-art deep learning models. For more details, see documentation below. Please also checkout the examples directory. Tutorials Digit Recognition on MNIST Simple 3-layer MLP Convolutional Neural Networks Predicting with a trained model Generating Random Sentence with LSTM RNN LSTM Cells Unfolding LSTM Data Provider for Text Sequences Training the LSTM Sampling Random Sentences Visualizing the LSTM User's Guide Installation Guide Automatic Installation Manual Compilation Overview MXNet.jl Namespace Low Level Interface Intermediate Level Interface High Level Interface FAQ Running MXNet on AWS GPU instances API Documentation Context NDArray API Arithmetic Operations Trigonometric Functions Hyperbolic Functions Activation Functions Reference Symbolic API Model Evaluation Metrics Data Providers AbstractDataProvider interface AbstractDataBatch interface Implemented providers and other methods Neural Network Factory Executor Network Visualization","title":"Home"},{"location":"#mxnet-documentation","text":"MXNet.jl is the Julia package of dmlc/mxnet . MXNet.jl brings flexible and efficient GPU computing and state-of-art deep learning to Julia. Some highlight of features include: Efficient tensor/matrix computation across multiple devices, including multiple CPUs, GPUs and distributed server nodes. Flexible symbolic manipulation to composite and construct state-of-the-art deep learning models. For more details, see documentation below. Please also checkout the examples directory.","title":"MXNet Documentation"},{"location":"#tutorials","text":"Digit Recognition on MNIST Simple 3-layer MLP Convolutional Neural Networks Predicting with a trained model Generating Random Sentence with LSTM RNN LSTM Cells Unfolding LSTM Data Provider for Text Sequences Training the LSTM Sampling Random Sentences Visualizing the LSTM","title":"Tutorials"},{"location":"#users-guide","text":"Installation Guide Automatic Installation Manual Compilation Overview MXNet.jl Namespace Low Level Interface Intermediate Level Interface High Level Interface FAQ Running MXNet on AWS GPU instances","title":"User's Guide"},{"location":"#api-documentation","text":"Context NDArray API Arithmetic Operations Trigonometric Functions Hyperbolic Functions Activation Functions Reference Symbolic API Model Evaluation Metrics Data Providers AbstractDataProvider interface AbstractDataBatch interface Implemented providers and other methods Neural Network Factory Executor Network Visualization","title":"API Documentation"},{"location":"api/","text":"API Documentation Symbolic API NDArray API Arithmetic Operations Trigonometric Functions Hyperbolic Functions Activation Functions Reference Context Model Evaluation Metrics Data Providers AbstractDataProvider interface AbstractDataBatch interface Implemented providers and other methods Neural Network Factory Executor Network Visualization","title":"Api"},{"location":"api/#api-documentation","text":"Symbolic API NDArray API Arithmetic Operations Trigonometric Functions Hyperbolic Functions Activation Functions Reference Context Model Evaluation Metrics Data Providers AbstractDataProvider interface AbstractDataBatch interface Implemented providers and other methods Neural Network Factory Executor Network Visualization","title":"API Documentation"},{"location":"api/callback/","text":"Callback in training # MXNet.mx.AbstractBatchCallback Type . AbstractBatchCallback Abstract type of callbacks to be called every mini-batch. source # MXNet.mx.AbstractCallback Type . AbstractCallback Abstract type of callback functions used in training. source # MXNet.mx.AbstractEpochCallback Type . AbstractEpochCallback Abstract type of callbacks to be called every epoch. source # MXNet.mx.do_checkpoint Method . do_checkpoint(prefix; frequency=1, save_epoch_0=false) Create an AbstractEpochCallback that save checkpoints of the model to disk. The checkpoints can be loaded back later on. Arguments prefix::AbstractString : the prefix of the filenames to save the model. The model architecture will be saved to prefix-symbol.json, while the weights will be saved to prefix-0012.params, for example, for the 12-th epoch. frequency::Int : keyword argument, default is 1. The frequency (measured in epochs) to save checkpoints. save_epoch_0::Bool : keyword argument, default false. Whether we should save a checkpoint for epoch 0 (model initialized but not seen any data yet). source # MXNet.mx.every_n_batch Method . every_n_batch(callback :: Function, n :: Int; call_on_0 = false) A convenient function to construct a callback that runs every n mini-batches. Arguments call_on_0::Bool : keyword argument, default false. Unless set, the callback will not be run on batch 0. For example, the speedometer callback is defined as every_n_batch(frequency, call_on_0=true) do state :: OptimizationState if state.curr_batch == 0 # reset timer else # compute and print speed end end See also every_n_epoch and speedometer . source # MXNet.mx.every_n_epoch Method . every_n_epoch(callback :: Function, n :: Int; call_on_0 = false) A convenient function to construct a callback that runs every n full data-passes. call_on_0::Bool : keyword argument, default false. Unless set, the callback will not be run on epoch 0. Epoch 0 means no training has been performed yet. This is useful if you want to inspect the randomly initialized model that has not seen any data yet. See also every_n_batch . source # MXNet.mx.speedometer Method . speedometer(;frequency=50) Create an AbstractBatchCallback that measure the training speed (number of samples processed per second) every k mini-batches. Arguments frequency::Int : keyword argument, default 50. The frequency (number of min-batches) to measure and report the speed. source","title":"Callbacks in training"},{"location":"api/callback/#callback-in-training","text":"# MXNet.mx.AbstractBatchCallback Type . AbstractBatchCallback Abstract type of callbacks to be called every mini-batch. source # MXNet.mx.AbstractCallback Type . AbstractCallback Abstract type of callback functions used in training. source # MXNet.mx.AbstractEpochCallback Type . AbstractEpochCallback Abstract type of callbacks to be called every epoch. source # MXNet.mx.do_checkpoint Method . do_checkpoint(prefix; frequency=1, save_epoch_0=false) Create an AbstractEpochCallback that save checkpoints of the model to disk. The checkpoints can be loaded back later on. Arguments prefix::AbstractString : the prefix of the filenames to save the model. The model architecture will be saved to prefix-symbol.json, while the weights will be saved to prefix-0012.params, for example, for the 12-th epoch. frequency::Int : keyword argument, default is 1. The frequency (measured in epochs) to save checkpoints. save_epoch_0::Bool : keyword argument, default false. Whether we should save a checkpoint for epoch 0 (model initialized but not seen any data yet). source # MXNet.mx.every_n_batch Method . every_n_batch(callback :: Function, n :: Int; call_on_0 = false) A convenient function to construct a callback that runs every n mini-batches. Arguments call_on_0::Bool : keyword argument, default false. Unless set, the callback will not be run on batch 0. For example, the speedometer callback is defined as every_n_batch(frequency, call_on_0=true) do state :: OptimizationState if state.curr_batch == 0 # reset timer else # compute and print speed end end See also every_n_epoch and speedometer . source # MXNet.mx.every_n_epoch Method . every_n_epoch(callback :: Function, n :: Int; call_on_0 = false) A convenient function to construct a callback that runs every n full data-passes. call_on_0::Bool : keyword argument, default false. Unless set, the callback will not be run on epoch 0. Epoch 0 means no training has been performed yet. This is useful if you want to inspect the randomly initialized model that has not seen any data yet. See also every_n_batch . source # MXNet.mx.speedometer Method . speedometer(;frequency=50) Create an AbstractBatchCallback that measure the training speed (number of samples processed per second) every k mini-batches. Arguments frequency::Int : keyword argument, default 50. The frequency (number of min-batches) to measure and report the speed. source","title":"Callback in training"},{"location":"api/context/","text":"Context # MXNet.mx.Context Type . Context(dev_type, dev_id) A context describes the device type and id on which computation should be carried on. source # MXNet.mx.context Method . context(x::NDArray) Get the context that this NDArray lives on. source # MXNet.mx.cpu Function . cpu(dev_id) Get a CPU context with a specific id. cpu() is usually the default context for many operations when no context is specified. Arguments dev_id::Integer = 0 : the CPU id. source # MXNet.mx.gpu Function . gpu(dev_id) Get a GPU context with a specific id. The K GPUs on a node is typically numbered as 0,...,K-1. Arguments dev_id::Integer = 0 the GPU device id. source","title":"Context"},{"location":"api/context/#context","text":"# MXNet.mx.Context Type . Context(dev_type, dev_id) A context describes the device type and id on which computation should be carried on. source # MXNet.mx.context Method . context(x::NDArray) Get the context that this NDArray lives on. source # MXNet.mx.cpu Function . cpu(dev_id) Get a CPU context with a specific id. cpu() is usually the default context for many operations when no context is specified. Arguments dev_id::Integer = 0 : the CPU id. source # MXNet.mx.gpu Function . gpu(dev_id) Get a GPU context with a specific id. The K GPUs on a node is typically numbered as 0,...,K-1. Arguments dev_id::Integer = 0 the GPU device id. source","title":"Context"},{"location":"api/executor/","text":"Executor # MXNet.mx.Executor Type . Executor An executor is a realization of a symbolic architecture defined by a SymbolicNode . The actual forward and backward computation specified by the network architecture can be carried out with an executor. source # Base.bind Method . bind(sym, ctx, args; args_grad=Dict(), aux_states=Dict(), grad_req=GRAD_WRITE) Create an Executor by binding a SymbolicNode to concrete NDArray . Arguments sym::SymbolicNode : the network architecture describing the computation graph. ctx::Context : the context on which the computation should run. args : either a list of NDArray or a dictionary of name-array pairs. Concrete arrays for all the inputs in the network architecture. The inputs typically include network parameters (weights, bias, filters, etc.), data and labels. See list_arguments and infer_shape . args_grad : a Vector of NDArray or a Dict contains NDArray aux_states : a Vector of NDArray or a Dict contains NDArray grad_req : single value, a Vector of GRAD_REQ or a Dict{Symbol,GRAD_REQ} source # Base.print Method . print([io::IO], x::Executor) Get a debug string about internal execution plan. Can be used to get an estimated about the memory cost. julia x = mx.Variable(:x) MXNet.mx.SymbolicNode x julia exec = mx.bind(x + 1, mx.cpu(), Dict(:x = mx.ones(2,3))) mx.Executor Ptr{Nothing} @0x000055c3dee9eb30 julia print(exec) Symbol Outputs: output[0]=_plus_scalar0(0) Variable:x -------------------- Op:_plus_scalar, Name=_plus_scalar0 Inputs: arg[0]=x(0) version=0 Attrs: scalar=1.00000000e+00 Total 0 MB allocated Total 11 TempSpace resource requested source","title":"Executor"},{"location":"api/executor/#executor","text":"# MXNet.mx.Executor Type . Executor An executor is a realization of a symbolic architecture defined by a SymbolicNode . The actual forward and backward computation specified by the network architecture can be carried out with an executor. source # Base.bind Method . bind(sym, ctx, args; args_grad=Dict(), aux_states=Dict(), grad_req=GRAD_WRITE) Create an Executor by binding a SymbolicNode to concrete NDArray . Arguments sym::SymbolicNode : the network architecture describing the computation graph. ctx::Context : the context on which the computation should run. args : either a list of NDArray or a dictionary of name-array pairs. Concrete arrays for all the inputs in the network architecture. The inputs typically include network parameters (weights, bias, filters, etc.), data and labels. See list_arguments and infer_shape . args_grad : a Vector of NDArray or a Dict contains NDArray aux_states : a Vector of NDArray or a Dict contains NDArray grad_req : single value, a Vector of GRAD_REQ or a Dict{Symbol,GRAD_REQ} source # Base.print Method . print([io::IO], x::Executor) Get a debug string about internal execution plan. Can be used to get an estimated about the memory cost. julia x = mx.Variable(:x) MXNet.mx.SymbolicNode x julia exec = mx.bind(x + 1, mx.cpu(), Dict(:x = mx.ones(2,3))) mx.Executor Ptr{Nothing} @0x000055c3dee9eb30 julia print(exec) Symbol Outputs: output[0]=_plus_scalar0(0) Variable:x -------------------- Op:_plus_scalar, Name=_plus_scalar0 Inputs: arg[0]=x(0) version=0 Attrs: scalar=1.00000000e+00 Total 0 MB allocated Total 11 TempSpace resource requested source","title":"Executor"},{"location":"api/initializer/","text":"Initializer # MXNet.mx.AbstractInitializer Type . AbstractInitializer The abstract base class for all initializers. To define a new initializer, it is enough to derive a new type, and implement one or more of the following methods: _init_weight(self :: AbstractInitializer, name :: Base.Symbol, array :: NDArray) _init_bias(self :: AbstractInitializer, name :: Base.Symbol, array :: NDArray) _init_gamma(self :: AbstractInitializer, name :: Base.Symbol, array :: NDArray) _init_beta(self :: AbstractInitializer, name :: Base.Symbol, array :: NDArray) Or, if full behavior customization is needed, override the following function init(self :: AbstractInitializer, name :: Base.Symbol, array :: NDArray) source # MXNet.mx.NormalInitializer Type . NormalInitializer Initialize weights according to a univariate Gaussian distribution. source # MXNet.mx.NormalInitializer Method . NormalInitializer(; mu=0, sigma=0.01) Construct a NormalInitializer with mean mu and variance sigma . source # MXNet.mx.UniformInitializer Type . UniformInitializer Initialize weights according to a uniform distribution within the provided scale. source # MXNet.mx.UniformInitializer Method . UniformInitializer(scale=0.07) Construct a UniformInitializer with the specified scale. source # MXNet.mx.XavierInitializer Type . XavierInitializer The initializer documented in the paper [Bengio and Glorot 2010]: Understanding the difficulty of training deep feedforward neuralnetworks . There are several different version of the XavierInitializer used in the wild. The general idea is that the variance of the initialization distribution is controlled by the dimensionality of the input and output. As a distribution one can either choose a normal distribution with \u03bc = 0 and \u03c3\u00b2 or a uniform distribution from -\u03c3 to \u03c3. Several different ways of calculating the variance are given in the literature or are used by various libraries. [Bengio and Glorot 2010]: mx.XavierInitializer(distribution = mx.xv_uniform, regularization = mx.xv_avg, magnitude = 1) [K. He, X. Zhang, S. Ren, and J. Sun 2015]: mx.XavierInitializer(distribution = mx.xv_gaussian, regularization = mx.xv_in, magnitude = 2) caffe*avg: mx.XavierInitializer(distribution = mx.xv*uniform, regularization = mx.xv_avg, magnitude = 3) source","title":"Initializers"},{"location":"api/initializer/#initializer","text":"# MXNet.mx.AbstractInitializer Type . AbstractInitializer The abstract base class for all initializers. To define a new initializer, it is enough to derive a new type, and implement one or more of the following methods: _init_weight(self :: AbstractInitializer, name :: Base.Symbol, array :: NDArray) _init_bias(self :: AbstractInitializer, name :: Base.Symbol, array :: NDArray) _init_gamma(self :: AbstractInitializer, name :: Base.Symbol, array :: NDArray) _init_beta(self :: AbstractInitializer, name :: Base.Symbol, array :: NDArray) Or, if full behavior customization is needed, override the following function init(self :: AbstractInitializer, name :: Base.Symbol, array :: NDArray) source # MXNet.mx.NormalInitializer Type . NormalInitializer Initialize weights according to a univariate Gaussian distribution. source # MXNet.mx.NormalInitializer Method . NormalInitializer(; mu=0, sigma=0.01) Construct a NormalInitializer with mean mu and variance sigma . source # MXNet.mx.UniformInitializer Type . UniformInitializer Initialize weights according to a uniform distribution within the provided scale. source # MXNet.mx.UniformInitializer Method . UniformInitializer(scale=0.07) Construct a UniformInitializer with the specified scale. source # MXNet.mx.XavierInitializer Type . XavierInitializer The initializer documented in the paper [Bengio and Glorot 2010]: Understanding the difficulty of training deep feedforward neuralnetworks . There are several different version of the XavierInitializer used in the wild. The general idea is that the variance of the initialization distribution is controlled by the dimensionality of the input and output. As a distribution one can either choose a normal distribution with \u03bc = 0 and \u03c3\u00b2 or a uniform distribution from -\u03c3 to \u03c3. Several different ways of calculating the variance are given in the literature or are used by various libraries. [Bengio and Glorot 2010]: mx.XavierInitializer(distribution = mx.xv_uniform, regularization = mx.xv_avg, magnitude = 1) [K. He, X. Zhang, S. Ren, and J. Sun 2015]: mx.XavierInitializer(distribution = mx.xv_gaussian, regularization = mx.xv_in, magnitude = 2) caffe*avg: mx.XavierInitializer(distribution = mx.xv*uniform, regularization = mx.xv_avg, magnitude = 3) source","title":"Initializer"},{"location":"api/io/","text":"Data Providers Data providers are wrappers that load external data, be it images, text, or general tensors, and split it into mini-batches so that the model can consume the data in a uniformed way. AbstractDataProvider interface # MXNet.mx.AbstractDataProvider Type . AbstractDataProvider The root type for all data provider. A data provider should implement the following interfaces: get_batch_size provide_data provide_label As well as the Julia iterator interface (see the Julia manual ). Normally this involves defining: Base.eltype(provider) - AbstractDataBatch Base.iterate(provider[, state]) - (AbstractDataBatch, AbstractDataProvider) source The difference between data and label is that during training stage, both data and label will be feeded into the model, while during prediction stage, only data is loaded. Otherwise, they could be anything, with any names, and of any shapes. The provided data and label names here should match the input names in a target SymbolicNode . A data provider should also implement the Julia iteration interface, in order to allow iterating through the data set. The provider will be called in the following way: for batch in eachbatch(provider) data = get_data(provider, batch) end which will be translated by Julia compiler into state = Base.start(eachbatch(provider)) while !Base.done(provider, state) (batch, state) = Base.next(provider, state) data = get_data(provider, batch) end By default, eachbatch simply returns the provider itself, so the iterator interface is implemented on the provider type itself. But the extra layer of abstraction allows us to implement a data provider easily via a Julia Task coroutine. See the data provider defined in the char-lstm example for an example of using coroutine to define data providers. The detailed interface functions for the iterator API is listed below: Base.eltype(provider) - AbstractDataBatch Returns the specific subtype representing a data batch. See AbstractDataBatch . provider::AbstractDataProvider : the data provider. Base.start(provider) - AbstractDataProviderState This function is always called before iterating into the dataset. It should initialize the iterator, reset the index, and do data shuffling if needed. provider::AbstractDataProvider : the data provider. Base.done(provider, state) - Bool True if there is no more data to iterate in this dataset. provider::AbstractDataProvider : the data provider. state::AbstractDataProviderState : the state returned by Base.start and Base.next . Base.next(provider) - (AbstractDataBatch, AbstractDataProviderState) Returns the current data batch, and the state for the next iteration. provider::AbstractDataProvider : the data provider. Note sometimes you are wrapping an existing data iterator (e.g. the built-in libmxnet data iterator) that is built with a different convention. It might be difficult to adapt to the interfaces stated here. In this case, you can safely assume that Base.start will always be called, and called only once before the iteration starts. Base.done will always be called at the beginning of every iteration and always be called once. If Base.done return true, the iteration will stop, until the next round, again, starting with a call to Base.start . Base.next will always be called only once in each iteration. It will always be called after one and only one call to Base.done ; but if Base.done returns true, Base.next will not be called. With those assumptions, it will be relatively easy to adapt any existing iterator. See the implementation of the built-in MXDataProvider for example. Note Please do not use the one data provider simultaneously in two different places, either in parallel, or in a nested loop. For example, the behavior for the following code is undefined ```julia for batch in data # updating the parameters # now let's test the performance on the training set for b2 in data # ... end end ``` # MXNet.mx.get_batch_size Function . get_batch_size(provider) - Int Arguments: provider::AbstractDataProvider : the data provider. Returns the mini-batch size of the provided data. All the provided data should have the same mini-batch size (i.e. the last dimension). source # MXNet.mx.provide_data Function . provide_data(provider) - Vector{Tuple{Base.Symbol, Tuple}} Arguments: provider::AbstractDataProvider : the data provider. Returns a vector of (name, shape) pairs describing the names of the data it provides, and the corresponding shapes. source # MXNet.mx.provide_label Function . provide_label(provider) - Vector{Tuple{Base.Symbol, Tuple}} Arguments: provider::AbstractDataProvider : the data provider. Returns a vector of (name, shape) pairs describing the names of the labels it provides, and the corresponding shapes. source AbstractDataBatch interface # MXNet.mx.AbstractDataProviderState Type . AbstractDataProviderState Base type for data provider states. source # MXNet.mx.count_samples Function . count_samples(provider, batch) - Int Arguments: batch::AbstractDataBatch : the data batch object. Returns the number of samples in this batch. This number should be greater than 0, but less than or equal to the batch size. This is used to indicate at the end of the data set, there might not be enough samples for a whole mini-batch. source # MXNet.mx.get_data Function . get_data(provider, batch) - Vector{NDArray} Arguments: provider::AbstractDataProvider : the data provider. batch::AbstractDataBatch : the data batch object. Returns a vector of data in this batch, should be in the same order as declared in provide_data() AbstractDataProvider.provide_data . The last dimension of each NDArray should always match the batch*size, even when count*samples returns a value less than the batch size. In this case, the data provider is free to pad the remaining contents with any value. source # MXNet.mx.get_label Function . get_label(provider, batch) - Vector{NDArray} Arguments: provider::AbstractDataProvider : the data provider. batch::AbstractDataBatch : the data batch object. Returns a vector of labels in this batch. Similar to get_data . source # Base.get Function . get(sched) sched::AbstractMomentumScheduler : the momentum scheduler. Returns the current momentum. source # MXNet.mx.load_data! Function . load_data!(provider, batch, targets) Arguments: provider::AbstractDataProvider : the data provider. batch::AbstractDataBatch : the data batch object. targets::Vector{Vector{SlicedNDArray}} : the targets to load data into. The targets is a list of the same length as number of data provided by this provider. Each element in the list is a list of SlicedNDArray . This list described a spliting scheme of this data batch into different slices, each slice is specified by a slice-ndarray pair, where slice specify the range of samples in the mini-batch that should be loaded into the corresponding ndarray . This utility function is used in data parallelization, where a mini-batch is splited and computed on several different devices. source # MXNet.mx.load_label! Function . load_label!(provider, batch, targets) provider::AbstractDataProvider provider : the data provider. batch::AbstractDataBatch batch : the data batch object. targets::Vector{Vector{SlicedNDArray}} : the targets to load label into. The same as load_data! , except that this is for loading labels. source Implemented providers and other methods # MXNet.mx.AbstractDataBatch Type . AbstractDataBatch Base type for a data mini-batch. It should implement the following interfaces: count_samples get_data get_label The following utility functions will be automatically defined: get load_data! load_label! source # MXNet.mx.ArrayDataProvider Type . ArrayDataProvider A convenient tool to iterate NDArray or Julia Array . ArrayDataProvider(data[, label]; batch_size, shuffle, data_padding, label_padding) Construct a data provider from NDArray or Julia Arrays. Arguments: data : the data, could be a NDArray , or a Julia Array. This is equivalent to :data = data . a name-data pair, like :mydata = array , where :mydata is the name of the data and array is an NDArray or a Julia Array. a list of name-data pairs. label : the same as the data parameter. When this argument is omitted, the constructed provider will provide no labels. batch_size::Int : the batch size, default is 0, which means treating the whole array as a single mini-batch. shuffle::Bool : turn on if the data should be shuffled at every epoch. data_padding::Real : when the mini-batch goes beyond the dataset boundary, there might be less samples to include than a mini-batch. This value specify a scalar to pad the contents of all the missing data points. label_padding::Real : the same as data_padding , except for the labels. TODO: remove data_padding and label_padding , and implement rollover that copies the last or first several training samples to feed the padding. source # MXNet.mx.DataBatch Type . DataBatch A basic subclass of AbstractDataBatch , that implement the interface by accessing member fields. source # MXNet.mx.MXDataProvider Type . MXDataProvider A data provider that wrap built-in data iterators from libmxnet. See below for a list of built-in data iterators. source # MXNet.mx.SlicedNDArray Type . SlicedNDArray A alias type of Tuple{UnitRange{Int},NDArray} . source # Base.get Method . get(provider, batch, name) - NDArray provider::AbstractDataProvider : the data provider. batch::AbstractDataBatch : the data batch object. name::Symbol : the name of the data to get, should be one of the names provided in either provide_data() AbstractDataProvider.provide_data or provide_label() AbstractDataProvider.provide_label . Returns the corresponding data array corresponding to that name. source # MXNet.mx.CSVIter Method . CSVIter(data_csv, data_shape, label_csv, label_shape, batch_size, round_batch, prefetch_buffer, ctx, dtype) Can also be called with the alias CSVProvider . Returns the CSV file iterator. In this function, the data_shape parameter is used to set the shape of each line of the input data. If a row in an input file is 1,2,3,4,5,6``and data_shape` is (3,2), that row will be reshaped, yielding the array [[1,2],[3,4],[5,6]] of shape (3,2). By default, the CSVIter has round_batch parameter set to $True$. So, if batch_size is 3 and there are 4 total rows in CSV file, 2 more examples are consumed at the first round. If reset function is called after first round, the call is ignored and remaining examples are returned in the second round. If one wants all the instances in the second round after calling reset , make sure to set round_batch to False. If $data_csv = 'data/'$ is set, then all the files in this directory will be read. $reset()$ is expected to be called only after a complete pass of data. By default, the CSVIter parses all entries in the data file as float32 data type, if dtype argument is set to be 'int32' or 'int64' then CSVIter will parse all entries in the file as int32 or int64 data type accordingly. Examples:: // Contents of CSV file $data/data.csv$. 1,2,3 2,3,4 3,4,5 4,5,6 // Creates a CSVIter with batch_size =2 and default round_batch =True. CSVIter = mx.io.CSVIter(data csv = 'data/data.csv', data shape = (3,), batch_size = 2) // Two batches read from the above iterator are as follows: [[ 1. 2. 3.] [ 2. 3. 4.]] [[ 3. 4. 5.] [ 4. 5. 6.]] // Creates a CSVIter with default round_batch set to True. CSVIter = mx.io.CSVIter(data csv = 'data/data.csv', data shape = (3,), batch_size = 3) // Two batches read from the above iterator in the first pass are as follows: [[1. 2. 3.] [2. 3. 4.] [3. 4. 5.]] [[4. 5. 6.] [1. 2. 3.] [2. 3. 4.]] // Now, reset method is called. CSVIter.reset() // Batch read from the above iterator in the second pass is as follows: [[ 3. 4. 5.] [ 4. 5. 6.] [ 1. 2. 3.]] // Creates a CSVIter with round_batch =False. CSVIter = mx.io.CSVIter(data csv = 'data/data.csv', data shape = (3,), batch size = 3, round batch=False) // Contents of two batches read from the above iterator in both passes, after calling // reset method before second pass, is as follows: [[1. 2. 3.] [2. 3. 4.] [3. 4. 5.]] [[4. 5. 6.] [2. 3. 4.] [3. 4. 5.]] // Creates a 'CSVIter' with dtype ='int32' CSVIter = mx.io.CSVIter(data csv = 'data/data.csv', data shape = (3,), batch size = 3, round batch=False, dtype='int32') // Contents of two batches read from the above iterator in both passes, after calling // reset method before second pass, is as follows: [[1 2 3] [2 3 4] [3 4 5]] [[4 5 6] [2 3 4] [3 4 5]] Defined in src/io/iter_csv.cc:L308 Arguments: data_name::Symbol : keyword argument, default :data . The name of the data. label_name::Symbol : keyword argument, default :softmax_label . The name of the label. Could be nothing if no label is presented in this dataset. data_csv::string, required : The input CSV file or a directory path. data_shape::Shape(tuple), required : The shape of one example. label_csv::string, optional, default='NULL' : The input CSV file or a directory path. If NULL, all labels will be returned as 0. label_shape::Shape(tuple), optional, default=[1] : The shape of one label. batch_size::int (non-negative), required : Batch size. round_batch::boolean, optional, default=1 : Whether to use round robin to handle overflow batch or not. prefetch_buffer::long (non-negative), optional, default=4 : Maximum number of batches to prefetch. ctx::{'cpu', 'gpu'},optional, default='gpu' : Context data loader optimized for. dtype::{None, 'float16', 'float32', 'float64', 'int32', 'int64', 'int8', 'uint8'},optional, default='None' : Output data type. $None$ means no change. Returns the constructed MXDataProvider . source # MXNet.mx.ImageDetRecordIter Method . ImageDetRecordIter(path_imglist, path_imgrec, aug_seq, label_width, data_shape, preprocess_threads, verbose, num_parts, part_index, shuffle_chunk_size, shuffle_chunk_seed, label_pad_width, label_pad_value, shuffle, seed, verbose, batch_size, round_batch, prefetch_buffer, ctx, dtype, resize, rand_crop_prob, min_crop_scales, max_crop_scales, min_crop_aspect_ratios, max_crop_aspect_ratios, min_crop_overlaps, max_crop_overlaps, min_crop_sample_coverages, max_crop_sample_coverages, min_crop_object_coverages, max_crop_object_coverages, num_crop_sampler, crop_emit_mode, emit_overlap_thresh, max_crop_trials, rand_pad_prob, max_pad_scale, max_random_hue, random_hue_prob, max_random_saturation, random_saturation_prob, max_random_illumination, random_illumination_prob, max_random_contrast, random_contrast_prob, rand_mirror_prob, fill_value, inter_method, data_shape, resize_mode, seed, mean_img, mean_r, mean_g, mean_b, mean_a, std_r, std_g, std_b, std_a, scale, verbose) Can also be called with the alias ImageDetRecordProvider . Create iterator for image detection dataset packed in recordio. Arguments: data_name::Symbol : keyword argument, default :data . The name of the data. label_name::Symbol : keyword argument, default :softmax_label . The name of the label. Could be nothing if no label is presented in this dataset. path_imglist::string, optional, default='' : Dataset Param: Path to image list. path_imgrec::string, optional, default='./data/imgrec.rec' : Dataset Param: Path to image record file. aug_seq::string, optional, default='det_aug_default' : Augmentation Param: the augmenter names to represent sequence of augmenters to be applied, seperated by comma. Additional keyword parameters will be seen by these augmenters. Make sure you don't use normal augmenters for detection tasks. label_width::int, optional, default='-1' : Dataset Param: How many labels for an image, -1 for variable label size. data_shape::Shape(tuple), required : Dataset Param: Shape of each instance generated by the DataIter. preprocess_threads::int, optional, default='4' : Backend Param: Number of thread to do preprocessing. verbose::boolean, optional, default=1 : Auxiliary Param: Whether to output parser information. num_parts::int, optional, default='1' : partition the data into multiple parts part_index::int, optional, default='0' : the index of the part will read shuffle_chunk_size::long (non-negative), optional, default=0 : the size(MB) of the shuffle chunk, used with shuffle=True, it can enable global shuffling shuffle_chunk_seed::int, optional, default='0' : the seed for chunk shuffling label_pad_width::int, optional, default='0' : pad output label width if set larger than 0, -1 for auto estimate label_pad_value::float, optional, default=-1 : label padding value if enabled shuffle::boolean, optional, default=0 : Augmentation Param: Whether to shuffle data. seed::int, optional, default='0' : Augmentation Param: Random Seed. batch_size::int (non-negative), required : Batch size. round_batch::boolean, optional, default=1 : Whether to use round robin to handle overflow batch or not. prefetch_buffer::long (non-negative), optional, default=4 : Maximum number of batches to prefetch. ctx::{'cpu', 'gpu'},optional, default='gpu' : Context data loader optimized for. dtype::{None, 'float16', 'float32', 'float64', 'int32', 'int64', 'int8', 'uint8'},optional, default='None' : Output data type. $None$ means no change. resize::int, optional, default='-1' : Augmentation Param: scale shorter edge to size before applying other augmentations, -1 to disable. rand_crop_prob::float, optional, default=0 : Augmentation Param: Probability of random cropping, = 0 to disable min_crop_scales::tuple of float , optional, default=[0] : Augmentation Param: Min crop scales. max_crop_scales::tuple of float , optional, default=[1] : Augmentation Param: Max crop scales. min_crop_aspect_ratios::tuple of float , optional, default=[1] : Augmentation Param: Min crop aspect ratios. max_crop_aspect_ratios::tuple of float , optional, default=[1] : Augmentation Param: Max crop aspect ratios. min_crop_overlaps::tuple of float , optional, default=[0] : Augmentation Param: Minimum crop IOU between crop_box and ground-truths. max_crop_overlaps::tuple of float , optional, default=[1] : Augmentation Param: Maximum crop IOU between crop_box and ground-truth. min_crop_sample_coverages::tuple of float , optional, default=[0] : Augmentation Param: Minimum ratio of intersect/crop_area between crop box and ground-truths. max_crop_sample_coverages::tuple of float , optional, default=[1] : Augmentation Param: Maximum ratio of intersect/crop_area between crop box and ground-truths. min_crop_object_coverages::tuple of float , optional, default=[0] : Augmentation Param: Minimum ratio of intersect/gt_area between crop box and ground-truths. max_crop_object_coverages::tuple of float , optional, default=[1] : Augmentation Param: Maximum ratio of intersect/gt_area between crop box and ground-truths. num_crop_sampler::int, optional, default='1' : Augmentation Param: Number of crop samplers. crop_emit_mode::{'center', 'overlap'},optional, default='center' : Augmentation Param: Emition mode for invalid ground-truths after crop. center: emit if centroid of object is out of crop region; overlap: emit if overlap is less than emit overlap thresh. emit_overlap_thresh::float, optional, default=0.300000012 : Augmentation Param: Emit overlap thresh for emit mode overlap only. max_crop_trials::Shape(tuple), optional, default=[25] : Augmentation Param: Skip cropping if fail crop trail count exceeds this number. rand_pad_prob::float, optional, default=0 : Augmentation Param: Probability for random padding. max_pad_scale::float, optional, default=1 : Augmentation Param: Maximum padding scale. max_random_hue::int, optional, default='0' : Augmentation Param: Maximum random value of H channel in HSL color space. random_hue_prob::float, optional, default=0 : Augmentation Param: Probability to apply random hue. max_random_saturation::int, optional, default='0' : Augmentation Param: Maximum random value of S channel in HSL color space. random_saturation_prob::float, optional, default=0 : Augmentation Param: Probability to apply random saturation. max_random_illumination::int, optional, default='0' : Augmentation Param: Maximum random value of L channel in HSL color space. random_illumination_prob::float, optional, default=0 : Augmentation Param: Probability to apply random illumination. max_random_contrast::float, optional, default=0 : Augmentation Param: Maximum random value of delta contrast. random_contrast_prob::float, optional, default=0 : Augmentation Param: Probability to apply random contrast. rand_mirror_prob::float, optional, default=0 : Augmentation Param: Probability to apply horizontal flip aka. mirror. fill_value::int, optional, default='127' : Augmentation Param: Filled color value while padding. inter_method::int, optional, default='1' : Augmentation Param: 0-NN 1-bilinear 2-cubic 3-area 4-lanczos4 9-auto 10-rand. resize_mode::{'fit', 'force', 'shrink'},optional, default='force' : Augmentation Param: How image data fit in data shape. force: force reshape to data shape regardless of aspect ratio; shrink: ensure each side fit in data shape, preserve aspect ratio; fit: fit image to data shape, preserve ratio, will upscale if applicable. mean_img::string, optional, default='' : Augmentation Param: Mean Image to be subtracted. mean_r::float, optional, default=0 : Augmentation Param: Mean value on R channel. mean_g::float, optional, default=0 : Augmentation Param: Mean value on G channel. mean_b::float, optional, default=0 : Augmentation Param: Mean value on B channel. mean_a::float, optional, default=0 : Augmentation Param: Mean value on Alpha channel. std_r::float, optional, default=0 : Augmentation Param: Standard deviation on R channel. std_g::float, optional, default=0 : Augmentation Param: Standard deviation on G channel. std_b::float, optional, default=0 : Augmentation Param: Standard deviation on B channel. std_a::float, optional, default=0 : Augmentation Param: Standard deviation on Alpha channel. scale::float, optional, default=1 : Augmentation Param: Scale in color space. Returns the constructed MXDataProvider . source # MXNet.mx.ImageRecordInt8Iter Method . ImageRecordInt8Iter(path_imglist, path_imgrec, path_imgidx, aug_seq, label_width, data_shape, preprocess_threads, verbose, num_parts, part_index, device_id, shuffle_chunk_size, shuffle_chunk_seed, seed_aug, shuffle, seed, verbose, batch_size, round_batch, prefetch_buffer, ctx, dtype, resize, rand_crop, random_resized_crop, max_rotate_angle, max_aspect_ratio, min_aspect_ratio, max_shear_ratio, max_crop_size, min_crop_size, max_random_scale, min_random_scale, max_random_area, min_random_area, max_img_size, min_img_size, brightness, contrast, saturation, pca_noise, random_h, random_s, random_l, rotate, fill_value, data_shape, inter_method, pad) Can also be called with the alias ImageRecordInt8Provider . Iterating on image RecordIO files .. note:: $ImageRecordInt8Iter$ is deprecated. Use ImageRecordIter(dtype='int8') instead. This iterator is identical to $ImageRecordIter$ except for using $int8$ as the data type instead of $float$. Defined in src/io/iter image recordio_2.cc:L934 Arguments: data_name::Symbol : keyword argument, default :data . The name of the data. label_name::Symbol : keyword argument, default :softmax_label . The name of the label. Could be nothing if no label is presented in this dataset. path_imglist::string, optional, default='' : Path to the image list (.lst) file. Generally created with tools/im2rec.py. Format (Tab separated): . path_imgrec::string, optional, default='' : Path to the image RecordIO (.rec) file or a directory path. Created with tools/im2rec.py. path_imgidx::string, optional, default='' : Path to the image RecordIO index (.idx) file. Created with tools/im2rec.py. aug_seq::string, optional, default='aug_default' : The augmenter names to represent sequence of augmenters to be applied, seperated by comma. Additional keyword parameters will be seen by these augmenters. label_width::int, optional, default='1' : The number of labels per image. data_shape::Shape(tuple), required : The shape of one output image in (channels, height, width) format. preprocess_threads::int, optional, default='4' : The number of threads to do preprocessing. verbose::boolean, optional, default=1 : If or not output verbose information. num_parts::int, optional, default='1' : Virtually partition the data into these many parts. part_index::int, optional, default='0' : The i -th virtual partition to be read. device_id::int, optional, default='0' : The device id used to create context for internal NDArray. Setting device id to -1 will create Context::CPU(0). Setting device id to valid positive device id will create Context::CPUPinned(device_id). Default is 0. shuffle_chunk_size::long (non-negative), optional, default=0 : The data shuffle buffer size in MB. Only valid if shuffle is true. shuffle_chunk_seed::int, optional, default='0' : The random seed for shuffling seed_aug::int or None, optional, default='None' : Random seed for augmentations. shuffle::boolean, optional, default=0 : Whether to shuffle data randomly or not. seed::int, optional, default='0' : The random seed. batch_size::int (non-negative), required : Batch size. round_batch::boolean, optional, default=1 : Whether to use round robin to handle overflow batch or not. prefetch_buffer::long (non-negative), optional, default=4 : Maximum number of batches to prefetch. ctx::{'cpu', 'gpu'},optional, default='gpu' : Context data loader optimized for. dtype::{None, 'float16', 'float32', 'float64', 'int32', 'int64', 'int8', 'uint8'},optional, default='None' : Output data type. $None$ means no change. resize::int, optional, default='-1' : Down scale the shorter edge to a new size before applying other augmentations. rand_crop::boolean, optional, default=0 : If or not randomly crop the image random_resized_crop::boolean, optional, default=0 : If or not perform random resized cropping on the image, as a standard preprocessing for resnet training on ImageNet data. max_rotate_angle::int, optional, default='0' : Rotate by a random degree in $[-v, v]$ max_aspect_ratio::float, optional, default=0 : Change the aspect (namely width/height) to a random value. If min aspect ratio is None then the aspect ratio ins sampled from [1 - max aspect ratio, 1 + max aspect ratio], else it is in $[min_aspect_ratio, max_aspect_ratio]$ min_aspect_ratio::float or None, optional, default=None : Change the aspect (namely width/height) to a random value in $[min_aspect_ratio, max_aspect_ratio]$ max_shear_ratio::float, optional, default=0 : Apply a shear transformation (namely $(x,y)- (x+my,y)$) with $m$ randomly chose from $[-max_shear_ratio, max_shear_ratio]$ max_crop_size::int, optional, default='-1' : Crop both width and height into a random size in $[min_crop_size, max_crop_size].$Ignored if $random_resized_crop$ is True. min_crop_size::int, optional, default='-1' : Crop both width and height into a random size in $[min_crop_size, max_crop_size].$Ignored if $random_resized_crop$ is True. max_random_scale::float, optional, default=1 : Resize into $[width s, height s]$ with $s$ randomly chosen from $[min_random_scale, max_random_scale]$. Ignored if $random_resized_crop$ is True. min_random_scale::float, optional, default=1 : Resize into $[width s, height s]$ with $s$ randomly chosen from $[min_random_scale, max_random_scale]$Ignored if $random_resized_crop$ is True. max_random_area::float, optional, default=1 : Change the area (namely width * height) to a random value in $[min_random_area, max_random_area]$. Ignored if $random_resized_crop$ is False. min_random_area::float, optional, default=1 : Change the area (namely width * height) to a random value in $[min_random_area, max_random_area]$. Ignored if $random_resized_crop$ is False. max_img_size::float, optional, default=1e+10 : Set the maximal width and height after all resize and rotate argumentation are applied min_img_size::float, optional, default=0 : Set the minimal width and height after all resize and rotate argumentation are applied brightness::float, optional, default=0 : Add a random value in $[-brightness, brightness]$ to the brightness of image. contrast::float, optional, default=0 : Add a random value in $[-contrast, contrast]$ to the contrast of image. saturation::float, optional, default=0 : Add a random value in $[-saturation, saturation]$ to the saturation of image. pca_noise::float, optional, default=0 : Add PCA based noise to the image. random_h::int, optional, default='0' : Add a random value in $[-random_h, random_h]$ to the H channel in HSL color space. random_s::int, optional, default='0' : Add a random value in $[-random_s, random_s]$ to the S channel in HSL color space. random_l::int, optional, default='0' : Add a random value in $[-random_l, random_l]$ to the L channel in HSL color space. rotate::int, optional, default='-1' : Rotate by an angle. If set, it overwrites the $max_rotate_angle$ option. fill_value::int, optional, default='255' : Set the padding pixels value to $fill_value$. inter_method::int, optional, default='1' : The interpolation method: 0-NN 1-bilinear 2-cubic 3-area 4-lanczos4 9-auto 10-rand. pad::int, optional, default='0' : Change size from $[width, height]$ into $[pad + width + pad, pad + height + pad]$ by padding pixes Returns the constructed MXDataProvider . source # MXNet.mx.ImageRecordIter Method . ImageRecordIter(path_imglist, path_imgrec, path_imgidx, aug_seq, label_width, data_shape, preprocess_threads, verbose, num_parts, part_index, device_id, shuffle_chunk_size, shuffle_chunk_seed, seed_aug, shuffle, seed, verbose, batch_size, round_batch, prefetch_buffer, ctx, dtype, resize, rand_crop, random_resized_crop, max_rotate_angle, max_aspect_ratio, min_aspect_ratio, max_shear_ratio, max_crop_size, min_crop_size, max_random_scale, min_random_scale, max_random_area, min_random_area, max_img_size, min_img_size, brightness, contrast, saturation, pca_noise, random_h, random_s, random_l, rotate, fill_value, data_shape, inter_method, pad, seed, mirror, rand_mirror, mean_img, mean_r, mean_g, mean_b, mean_a, std_r, std_g, std_b, std_a, scale, max_random_contrast, max_random_illumination, verbose) Can also be called with the alias ImageRecordProvider . Iterates on image RecordIO files Reads batches of images from .rec RecordIO files. One can use $im2rec.py$ tool (in tools/) to pack raw image files into RecordIO files. This iterator is less flexible to customization but is fast and has lot of language bindings. To iterate over raw images directly use $ImageIter$ instead (in Python). Example:: data iter = mx.io.ImageRecordIter( path imgrec=\"./sample.rec\", # The target record file. data shape=(3, 227, 227), # Output data shape; 227x227 region will be cropped from the original image. batch size=4, # Number of items per batch. resize=256 # Resize the shorter edge to 256 before cropping. # You can specify more augmentation options. Use help(mx.io.ImageRecordIter) to see all the options. ) You can now use the data_iter to access batches of images. batch = data iter.next() # first batch. images = batch.data[0] # This will contain 4 (=batch size) images each of 3x227x227. process the images ... data_iter.reset() # To restart the iterator from the beginning. Defined in src/io/iter image recordio_2.cc:L897 Arguments: data_name::Symbol : keyword argument, default :data . The name of the data. label_name::Symbol : keyword argument, default :softmax_label . The name of the label. Could be nothing if no label is presented in this dataset. path_imglist::string, optional, default='' : Path to the image list (.lst) file. Generally created with tools/im2rec.py. Format (Tab separated): . path_imgrec::string, optional, default='' : Path to the image RecordIO (.rec) file or a directory path. Created with tools/im2rec.py. path_imgidx::string, optional, default='' : Path to the image RecordIO index (.idx) file. Created with tools/im2rec.py. aug_seq::string, optional, default='aug_default' : The augmenter names to represent sequence of augmenters to be applied, seperated by comma. Additional keyword parameters will be seen by these augmenters. label_width::int, optional, default='1' : The number of labels per image. data_shape::Shape(tuple), required : The shape of one output image in (channels, height, width) format. preprocess_threads::int, optional, default='4' : The number of threads to do preprocessing. verbose::boolean, optional, default=1 : If or not output verbose information. num_parts::int, optional, default='1' : Virtually partition the data into these many parts. part_index::int, optional, default='0' : The i -th virtual partition to be read. device_id::int, optional, default='0' : The device id used to create context for internal NDArray. Setting device id to -1 will create Context::CPU(0). Setting device id to valid positive device id will create Context::CPUPinned(device_id). Default is 0. shuffle_chunk_size::long (non-negative), optional, default=0 : The data shuffle buffer size in MB. Only valid if shuffle is true. shuffle_chunk_seed::int, optional, default='0' : The random seed for shuffling seed_aug::int or None, optional, default='None' : Random seed for augmentations. shuffle::boolean, optional, default=0 : Whether to shuffle data randomly or not. seed::int, optional, default='0' : The random seed. batch_size::int (non-negative), required : Batch size. round_batch::boolean, optional, default=1 : Whether to use round robin to handle overflow batch or not. prefetch_buffer::long (non-negative), optional, default=4 : Maximum number of batches to prefetch. ctx::{'cpu', 'gpu'},optional, default='gpu' : Context data loader optimized for. dtype::{None, 'float16', 'float32', 'float64', 'int32', 'int64', 'int8', 'uint8'},optional, default='None' : Output data type. $None$ means no change. resize::int, optional, default='-1' : Down scale the shorter edge to a new size before applying other augmentations. rand_crop::boolean, optional, default=0 : If or not randomly crop the image random_resized_crop::boolean, optional, default=0 : If or not perform random resized cropping on the image, as a standard preprocessing for resnet training on ImageNet data. max_rotate_angle::int, optional, default='0' : Rotate by a random degree in $[-v, v]$ max_aspect_ratio::float, optional, default=0 : Change the aspect (namely width/height) to a random value. If min aspect ratio is None then the aspect ratio ins sampled from [1 - max aspect ratio, 1 + max aspect ratio], else it is in $[min_aspect_ratio, max_aspect_ratio]$ min_aspect_ratio::float or None, optional, default=None : Change the aspect (namely width/height) to a random value in $[min_aspect_ratio, max_aspect_ratio]$ max_shear_ratio::float, optional, default=0 : Apply a shear transformation (namely $(x,y)- (x+my,y)$) with $m$ randomly chose from $[-max_shear_ratio, max_shear_ratio]$ max_crop_size::int, optional, default='-1' : Crop both width and height into a random size in $[min_crop_size, max_crop_size].$Ignored if $random_resized_crop$ is True. min_crop_size::int, optional, default='-1' : Crop both width and height into a random size in $[min_crop_size, max_crop_size].$Ignored if $random_resized_crop$ is True. max_random_scale::float, optional, default=1 : Resize into $[width s, height s]$ with $s$ randomly chosen from $[min_random_scale, max_random_scale]$. Ignored if $random_resized_crop$ is True. min_random_scale::float, optional, default=1 : Resize into $[width s, height s]$ with $s$ randomly chosen from $[min_random_scale, max_random_scale]$Ignored if $random_resized_crop$ is True. max_random_area::float, optional, default=1 : Change the area (namely width * height) to a random value in $[min_random_area, max_random_area]$. Ignored if $random_resized_crop$ is False. min_random_area::float, optional, default=1 : Change the area (namely width * height) to a random value in $[min_random_area, max_random_area]$. Ignored if $random_resized_crop$ is False. max_img_size::float, optional, default=1e+10 : Set the maximal width and height after all resize and rotate argumentation are applied min_img_size::float, optional, default=0 : Set the minimal width and height after all resize and rotate argumentation are applied brightness::float, optional, default=0 : Add a random value in $[-brightness, brightness]$ to the brightness of image. contrast::float, optional, default=0 : Add a random value in $[-contrast, contrast]$ to the contrast of image. saturation::float, optional, default=0 : Add a random value in $[-saturation, saturation]$ to the saturation of image. pca_noise::float, optional, default=0 : Add PCA based noise to the image. random_h::int, optional, default='0' : Add a random value in $[-random_h, random_h]$ to the H channel in HSL color space. random_s::int, optional, default='0' : Add a random value in $[-random_s, random_s]$ to the S channel in HSL color space. random_l::int, optional, default='0' : Add a random value in $[-random_l, random_l]$ to the L channel in HSL color space. rotate::int, optional, default='-1' : Rotate by an angle. If set, it overwrites the $max_rotate_angle$ option. fill_value::int, optional, default='255' : Set the padding pixels value to $fill_value$. inter_method::int, optional, default='1' : The interpolation method: 0-NN 1-bilinear 2-cubic 3-area 4-lanczos4 9-auto 10-rand. pad::int, optional, default='0' : Change size from $[width, height]$ into $[pad + width + pad, pad + height + pad]$ by padding pixes mirror::boolean, optional, default=0 : Whether to mirror the image or not. If true, images are flipped along the horizontal axis. rand_mirror::boolean, optional, default=0 : Whether to randomly mirror images or not. If true, 50% of the images will be randomly mirrored (flipped along the horizontal axis) mean_img::string, optional, default='' : Filename of the mean image. mean_r::float, optional, default=0 : The mean value to be subtracted on the R channel mean_g::float, optional, default=0 : The mean value to be subtracted on the G channel mean_b::float, optional, default=0 : The mean value to be subtracted on the B channel mean_a::float, optional, default=0 : The mean value to be subtracted on the alpha channel std_r::float, optional, default=1 : Augmentation Param: Standard deviation on R channel. std_g::float, optional, default=1 : Augmentation Param: Standard deviation on G channel. std_b::float, optional, default=1 : Augmentation Param: Standard deviation on B channel. std_a::float, optional, default=1 : Augmentation Param: Standard deviation on Alpha channel. scale::float, optional, default=1 : Multiply the image with a scale value. max_random_contrast::float, optional, default=0 : Change the contrast with a value randomly chosen from $[-max_random_contrast, max_random_contrast]$ max_random_illumination::float, optional, default=0 : Change the illumination with a value randomly chosen from $[-max_random_illumination, max_random_illumination]$ Returns the constructed MXDataProvider . source # MXNet.mx.ImageRecordIter_v1 Method . ImageRecordIter_v1(path_imglist, path_imgrec, path_imgidx, aug_seq, label_width, data_shape, preprocess_threads, verbose, num_parts, part_index, device_id, shuffle_chunk_size, shuffle_chunk_seed, seed_aug, shuffle, seed, verbose, batch_size, round_batch, prefetch_buffer, ctx, dtype, resize, rand_crop, random_resized_crop, max_rotate_angle, max_aspect_ratio, min_aspect_ratio, max_shear_ratio, max_crop_size, min_crop_size, max_random_scale, min_random_scale, max_random_area, min_random_area, max_img_size, min_img_size, brightness, contrast, saturation, pca_noise, random_h, random_s, random_l, rotate, fill_value, data_shape, inter_method, pad, seed, mirror, rand_mirror, mean_img, mean_r, mean_g, mean_b, mean_a, std_r, std_g, std_b, std_a, scale, max_random_contrast, max_random_illumination, verbose) Iterating on image RecordIO files .. note:: $ImageRecordIter_v1$ is deprecated. Use $ImageRecordIter$ instead. Read images batches from RecordIO files with a rich of data augmentation options. One can use $tools/im2rec.py$ to pack individual image files into RecordIO files. Defined in src/io/iter image recordio.cc:L352 Arguments: data_name::Symbol : keyword argument, default :data . The name of the data. label_name::Symbol : keyword argument, default :softmax_label . The name of the label. Could be nothing if no label is presented in this dataset. path_imglist::string, optional, default='' : Path to the image list (.lst) file. Generally created with tools/im2rec.py. Format (Tab separated): . path_imgrec::string, optional, default='' : Path to the image RecordIO (.rec) file or a directory path. Created with tools/im2rec.py. path_imgidx::string, optional, default='' : Path to the image RecordIO index (.idx) file. Created with tools/im2rec.py. aug_seq::string, optional, default='aug_default' : The augmenter names to represent sequence of augmenters to be applied, seperated by comma. Additional keyword parameters will be seen by these augmenters. label_width::int, optional, default='1' : The number of labels per image. data_shape::Shape(tuple), required : The shape of one output image in (channels, height, width) format. preprocess_threads::int, optional, default='4' : The number of threads to do preprocessing. verbose::boolean, optional, default=1 : If or not output verbose information. num_parts::int, optional, default='1' : Virtually partition the data into these many parts. part_index::int, optional, default='0' : The i -th virtual partition to be read. device_id::int, optional, default='0' : The device id used to create context for internal NDArray. Setting device id to -1 will create Context::CPU(0). Setting device id to valid positive device id will create Context::CPUPinned(device_id). Default is 0. shuffle_chunk_size::long (non-negative), optional, default=0 : The data shuffle buffer size in MB. Only valid if shuffle is true. shuffle_chunk_seed::int, optional, default='0' : The random seed for shuffling seed_aug::int or None, optional, default='None' : Random seed for augmentations. shuffle::boolean, optional, default=0 : Whether to shuffle data randomly or not. seed::int, optional, default='0' : The random seed. batch_size::int (non-negative), required : Batch size. round_batch::boolean, optional, default=1 : Whether to use round robin to handle overflow batch or not. prefetch_buffer::long (non-negative), optional, default=4 : Maximum number of batches to prefetch. ctx::{'cpu', 'gpu'},optional, default='gpu' : Context data loader optimized for. dtype::{None, 'float16', 'float32', 'float64', 'int32', 'int64', 'int8', 'uint8'},optional, default='None' : Output data type. $None$ means no change. resize::int, optional, default='-1' : Down scale the shorter edge to a new size before applying other augmentations. rand_crop::boolean, optional, default=0 : If or not randomly crop the image random_resized_crop::boolean, optional, default=0 : If or not perform random resized cropping on the image, as a standard preprocessing for resnet training on ImageNet data. max_rotate_angle::int, optional, default='0' : Rotate by a random degree in $[-v, v]$ max_aspect_ratio::float, optional, default=0 : Change the aspect (namely width/height) to a random value. If min aspect ratio is None then the aspect ratio ins sampled from [1 - max aspect ratio, 1 + max aspect ratio], else it is in $[min_aspect_ratio, max_aspect_ratio]$ min_aspect_ratio::float or None, optional, default=None : Change the aspect (namely width/height) to a random value in $[min_aspect_ratio, max_aspect_ratio]$ max_shear_ratio::float, optional, default=0 : Apply a shear transformation (namely $(x,y)- (x+my,y)$) with $m$ randomly chose from $[-max_shear_ratio, max_shear_ratio]$ max_crop_size::int, optional, default='-1' : Crop both width and height into a random size in $[min_crop_size, max_crop_size].$Ignored if $random_resized_crop$ is True. min_crop_size::int, optional, default='-1' : Crop both width and height into a random size in $[min_crop_size, max_crop_size].$Ignored if $random_resized_crop$ is True. max_random_scale::float, optional, default=1 : Resize into $[width s, height s]$ with $s$ randomly chosen from $[min_random_scale, max_random_scale]$. Ignored if $random_resized_crop$ is True. min_random_scale::float, optional, default=1 : Resize into $[width s, height s]$ with $s$ randomly chosen from $[min_random_scale, max_random_scale]$Ignored if $random_resized_crop$ is True. max_random_area::float, optional, default=1 : Change the area (namely width * height) to a random value in $[min_random_area, max_random_area]$. Ignored if $random_resized_crop$ is False. min_random_area::float, optional, default=1 : Change the area (namely width * height) to a random value in $[min_random_area, max_random_area]$. Ignored if $random_resized_crop$ is False. max_img_size::float, optional, default=1e+10 : Set the maximal width and height after all resize and rotate argumentation are applied min_img_size::float, optional, default=0 : Set the minimal width and height after all resize and rotate argumentation are applied brightness::float, optional, default=0 : Add a random value in $[-brightness, brightness]$ to the brightness of image. contrast::float, optional, default=0 : Add a random value in $[-contrast, contrast]$ to the contrast of image. saturation::float, optional, default=0 : Add a random value in $[-saturation, saturation]$ to the saturation of image. pca_noise::float, optional, default=0 : Add PCA based noise to the image. random_h::int, optional, default='0' : Add a random value in $[-random_h, random_h]$ to the H channel in HSL color space. random_s::int, optional, default='0' : Add a random value in $[-random_s, random_s]$ to the S channel in HSL color space. random_l::int, optional, default='0' : Add a random value in $[-random_l, random_l]$ to the L channel in HSL color space. rotate::int, optional, default='-1' : Rotate by an angle. If set, it overwrites the $max_rotate_angle$ option. fill_value::int, optional, default='255' : Set the padding pixels value to $fill_value$. inter_method::int, optional, default='1' : The interpolation method: 0-NN 1-bilinear 2-cubic 3-area 4-lanczos4 9-auto 10-rand. pad::int, optional, default='0' : Change size from $[width, height]$ into $[pad + width + pad, pad + height + pad]$ by padding pixes mirror::boolean, optional, default=0 : Whether to mirror the image or not. If true, images are flipped along the horizontal axis. rand_mirror::boolean, optional, default=0 : Whether to randomly mirror images or not. If true, 50% of the images will be randomly mirrored (flipped along the horizontal axis) mean_img::string, optional, default='' : Filename of the mean image. mean_r::float, optional, default=0 : The mean value to be subtracted on the R channel mean_g::float, optional, default=0 : The mean value to be subtracted on the G channel mean_b::float, optional, default=0 : The mean value to be subtracted on the B channel mean_a::float, optional, default=0 : The mean value to be subtracted on the alpha channel std_r::float, optional, default=1 : Augmentation Param: Standard deviation on R channel. std_g::float, optional, default=1 : Augmentation Param: Standard deviation on G channel. std_b::float, optional, default=1 : Augmentation Param: Standard deviation on B channel. std_a::float, optional, default=1 : Augmentation Param: Standard deviation on Alpha channel. scale::float, optional, default=1 : Multiply the image with a scale value. max_random_contrast::float, optional, default=0 : Change the contrast with a value randomly chosen from $[-max_random_contrast, max_random_contrast]$ max_random_illumination::float, optional, default=0 : Change the illumination with a value randomly chosen from $[-max_random_illumination, max_random_illumination]$ Returns the constructed MXDataProvider . source # MXNet.mx.ImageRecordUInt8Iter Method . ImageRecordUInt8Iter(path_imglist, path_imgrec, path_imgidx, aug_seq, label_width, data_shape, preprocess_threads, verbose, num_parts, part_index, device_id, shuffle_chunk_size, shuffle_chunk_seed, seed_aug, shuffle, seed, verbose, batch_size, round_batch, prefetch_buffer, ctx, dtype, resize, rand_crop, random_resized_crop, max_rotate_angle, max_aspect_ratio, min_aspect_ratio, max_shear_ratio, max_crop_size, min_crop_size, max_random_scale, min_random_scale, max_random_area, min_random_area, max_img_size, min_img_size, brightness, contrast, saturation, pca_noise, random_h, random_s, random_l, rotate, fill_value, data_shape, inter_method, pad) Can also be called with the alias ImageRecordUInt8Provider . Iterating on image RecordIO files .. note:: ImageRecordUInt8Iter is deprecated. Use ImageRecordIter(dtype='uint8') instead. This iterator is identical to $ImageRecordIter$ except for using $uint8$ as the data type instead of $float$. Defined in src/io/iter image recordio_2.cc:L916 Arguments: data_name::Symbol : keyword argument, default :data . The name of the data. label_name::Symbol : keyword argument, default :softmax_label . The name of the label. Could be nothing if no label is presented in this dataset. path_imglist::string, optional, default='' : Path to the image list (.lst) file. Generally created with tools/im2rec.py. Format (Tab separated): . path_imgrec::string, optional, default='' : Path to the image RecordIO (.rec) file or a directory path. Created with tools/im2rec.py. path_imgidx::string, optional, default='' : Path to the image RecordIO index (.idx) file. Created with tools/im2rec.py. aug_seq::string, optional, default='aug_default' : The augmenter names to represent sequence of augmenters to be applied, seperated by comma. Additional keyword parameters will be seen by these augmenters. label_width::int, optional, default='1' : The number of labels per image. data_shape::Shape(tuple), required : The shape of one output image in (channels, height, width) format. preprocess_threads::int, optional, default='4' : The number of threads to do preprocessing. verbose::boolean, optional, default=1 : If or not output verbose information. num_parts::int, optional, default='1' : Virtually partition the data into these many parts. part_index::int, optional, default='0' : The i -th virtual partition to be read. device_id::int, optional, default='0' : The device id used to create context for internal NDArray. Setting device id to -1 will create Context::CPU(0). Setting device id to valid positive device id will create Context::CPUPinned(device_id). Default is 0. shuffle_chunk_size::long (non-negative), optional, default=0 : The data shuffle buffer size in MB. Only valid if shuffle is true. shuffle_chunk_seed::int, optional, default='0' : The random seed for shuffling seed_aug::int or None, optional, default='None' : Random seed for augmentations. shuffle::boolean, optional, default=0 : Whether to shuffle data randomly or not. seed::int, optional, default='0' : The random seed. batch_size::int (non-negative), required : Batch size. round_batch::boolean, optional, default=1 : Whether to use round robin to handle overflow batch or not. prefetch_buffer::long (non-negative), optional, default=4 : Maximum number of batches to prefetch. ctx::{'cpu', 'gpu'},optional, default='gpu' : Context data loader optimized for. dtype::{None, 'float16', 'float32', 'float64', 'int32', 'int64', 'int8', 'uint8'},optional, default='None' : Output data type. $None$ means no change. resize::int, optional, default='-1' : Down scale the shorter edge to a new size before applying other augmentations. rand_crop::boolean, optional, default=0 : If or not randomly crop the image random_resized_crop::boolean, optional, default=0 : If or not perform random resized cropping on the image, as a standard preprocessing for resnet training on ImageNet data. max_rotate_angle::int, optional, default='0' : Rotate by a random degree in $[-v, v]$ max_aspect_ratio::float, optional, default=0 : Change the aspect (namely width/height) to a random value. If min aspect ratio is None then the aspect ratio ins sampled from [1 - max aspect ratio, 1 + max aspect ratio], else it is in $[min_aspect_ratio, max_aspect_ratio]$ min_aspect_ratio::float or None, optional, default=None : Change the aspect (namely width/height) to a random value in $[min_aspect_ratio, max_aspect_ratio]$ max_shear_ratio::float, optional, default=0 : Apply a shear transformation (namely $(x,y)- (x+my,y)$) with $m$ randomly chose from $[-max_shear_ratio, max_shear_ratio]$ max_crop_size::int, optional, default='-1' : Crop both width and height into a random size in $[min_crop_size, max_crop_size].$Ignored if $random_resized_crop$ is True. min_crop_size::int, optional, default='-1' : Crop both width and height into a random size in $[min_crop_size, max_crop_size].$Ignored if $random_resized_crop$ is True. max_random_scale::float, optional, default=1 : Resize into $[width s, height s]$ with $s$ randomly chosen from $[min_random_scale, max_random_scale]$. Ignored if $random_resized_crop$ is True. min_random_scale::float, optional, default=1 : Resize into $[width s, height s]$ with $s$ randomly chosen from $[min_random_scale, max_random_scale]$Ignored if $random_resized_crop$ is True. max_random_area::float, optional, default=1 : Change the area (namely width * height) to a random value in $[min_random_area, max_random_area]$. Ignored if $random_resized_crop$ is False. min_random_area::float, optional, default=1 : Change the area (namely width * height) to a random value in $[min_random_area, max_random_area]$. Ignored if $random_resized_crop$ is False. max_img_size::float, optional, default=1e+10 : Set the maximal width and height after all resize and rotate argumentation are applied min_img_size::float, optional, default=0 : Set the minimal width and height after all resize and rotate argumentation are applied brightness::float, optional, default=0 : Add a random value in $[-brightness, brightness]$ to the brightness of image. contrast::float, optional, default=0 : Add a random value in $[-contrast, contrast]$ to the contrast of image. saturation::float, optional, default=0 : Add a random value in $[-saturation, saturation]$ to the saturation of image. pca_noise::float, optional, default=0 : Add PCA based noise to the image. random_h::int, optional, default='0' : Add a random value in $[-random_h, random_h]$ to the H channel in HSL color space. random_s::int, optional, default='0' : Add a random value in $[-random_s, random_s]$ to the S channel in HSL color space. random_l::int, optional, default='0' : Add a random value in $[-random_l, random_l]$ to the L channel in HSL color space. rotate::int, optional, default='-1' : Rotate by an angle. If set, it overwrites the $max_rotate_angle$ option. fill_value::int, optional, default='255' : Set the padding pixels value to $fill_value$. inter_method::int, optional, default='1' : The interpolation method: 0-NN 1-bilinear 2-cubic 3-area 4-lanczos4 9-auto 10-rand. pad::int, optional, default='0' : Change size from $[width, height]$ into $[pad + width + pad, pad + height + pad]$ by padding pixes Returns the constructed MXDataProvider . source # MXNet.mx.ImageRecordUInt8Iter_v1 Method . ImageRecordUInt8Iter_v1(path_imglist, path_imgrec, path_imgidx, aug_seq, label_width, data_shape, preprocess_threads, verbose, num_parts, part_index, device_id, shuffle_chunk_size, shuffle_chunk_seed, seed_aug, shuffle, seed, verbose, batch_size, round_batch, prefetch_buffer, ctx, dtype, resize, rand_crop, random_resized_crop, max_rotate_angle, max_aspect_ratio, min_aspect_ratio, max_shear_ratio, max_crop_size, min_crop_size, max_random_scale, min_random_scale, max_random_area, min_random_area, max_img_size, min_img_size, brightness, contrast, saturation, pca_noise, random_h, random_s, random_l, rotate, fill_value, data_shape, inter_method, pad) Iterating on image RecordIO files .. note:: $ImageRecordUInt8Iter_v1$ is deprecated. Use $ImageRecordUInt8Iter$ instead. This iterator is identical to $ImageRecordIter$ except for using $uint8$ as the data type instead of $float$. Defined in src/io/iter image recordio.cc:L377 Arguments: data_name::Symbol : keyword argument, default :data . The name of the data. label_name::Symbol : keyword argument, default :softmax_label . The name of the label. Could be nothing if no label is presented in this dataset. path_imglist::string, optional, default='' : Path to the image list (.lst) file. Generally created with tools/im2rec.py. Format (Tab separated): . path_imgrec::string, optional, default='' : Path to the image RecordIO (.rec) file or a directory path. Created with tools/im2rec.py. path_imgidx::string, optional, default='' : Path to the image RecordIO index (.idx) file. Created with tools/im2rec.py. aug_seq::string, optional, default='aug_default' : The augmenter names to represent sequence of augmenters to be applied, seperated by comma. Additional keyword parameters will be seen by these augmenters. label_width::int, optional, default='1' : The number of labels per image. data_shape::Shape(tuple), required : The shape of one output image in (channels, height, width) format. preprocess_threads::int, optional, default='4' : The number of threads to do preprocessing. verbose::boolean, optional, default=1 : If or not output verbose information. num_parts::int, optional, default='1' : Virtually partition the data into these many parts. part_index::int, optional, default='0' : The i -th virtual partition to be read. device_id::int, optional, default='0' : The device id used to create context for internal NDArray. Setting device id to -1 will create Context::CPU(0). Setting device id to valid positive device id will create Context::CPUPinned(device_id). Default is 0. shuffle_chunk_size::long (non-negative), optional, default=0 : The data shuffle buffer size in MB. Only valid if shuffle is true. shuffle_chunk_seed::int, optional, default='0' : The random seed for shuffling seed_aug::int or None, optional, default='None' : Random seed for augmentations. shuffle::boolean, optional, default=0 : Whether to shuffle data randomly or not. seed::int, optional, default='0' : The random seed. batch_size::int (non-negative), required : Batch size. round_batch::boolean, optional, default=1 : Whether to use round robin to handle overflow batch or not. prefetch_buffer::long (non-negative), optional, default=4 : Maximum number of batches to prefetch. ctx::{'cpu', 'gpu'},optional, default='gpu' : Context data loader optimized for. dtype::{None, 'float16', 'float32', 'float64', 'int32', 'int64', 'int8', 'uint8'},optional, default='None' : Output data type. $None$ means no change. resize::int, optional, default='-1' : Down scale the shorter edge to a new size before applying other augmentations. rand_crop::boolean, optional, default=0 : If or not randomly crop the image random_resized_crop::boolean, optional, default=0 : If or not perform random resized cropping on the image, as a standard preprocessing for resnet training on ImageNet data. max_rotate_angle::int, optional, default='0' : Rotate by a random degree in $[-v, v]$ max_aspect_ratio::float, optional, default=0 : Change the aspect (namely width/height) to a random value. If min aspect ratio is None then the aspect ratio ins sampled from [1 - max aspect ratio, 1 + max aspect ratio], else it is in $[min_aspect_ratio, max_aspect_ratio]$ min_aspect_ratio::float or None, optional, default=None : Change the aspect (namely width/height) to a random value in $[min_aspect_ratio, max_aspect_ratio]$ max_shear_ratio::float, optional, default=0 : Apply a shear transformation (namely $(x,y)- (x+my,y)$) with $m$ randomly chose from $[-max_shear_ratio, max_shear_ratio]$ max_crop_size::int, optional, default='-1' : Crop both width and height into a random size in $[min_crop_size, max_crop_size].$Ignored if $random_resized_crop$ is True. min_crop_size::int, optional, default='-1' : Crop both width and height into a random size in $[min_crop_size, max_crop_size].$Ignored if $random_resized_crop$ is True. max_random_scale::float, optional, default=1 : Resize into $[width s, height s]$ with $s$ randomly chosen from $[min_random_scale, max_random_scale]$. Ignored if $random_resized_crop$ is True. min_random_scale::float, optional, default=1 : Resize into $[width s, height s]$ with $s$ randomly chosen from $[min_random_scale, max_random_scale]$Ignored if $random_resized_crop$ is True. max_random_area::float, optional, default=1 : Change the area (namely width * height) to a random value in $[min_random_area, max_random_area]$. Ignored if $random_resized_crop$ is False. min_random_area::float, optional, default=1 : Change the area (namely width * height) to a random value in $[min_random_area, max_random_area]$. Ignored if $random_resized_crop$ is False. max_img_size::float, optional, default=1e+10 : Set the maximal width and height after all resize and rotate argumentation are applied min_img_size::float, optional, default=0 : Set the minimal width and height after all resize and rotate argumentation are applied brightness::float, optional, default=0 : Add a random value in $[-brightness, brightness]$ to the brightness of image. contrast::float, optional, default=0 : Add a random value in $[-contrast, contrast]$ to the contrast of image. saturation::float, optional, default=0 : Add a random value in $[-saturation, saturation]$ to the saturation of image. pca_noise::float, optional, default=0 : Add PCA based noise to the image. random_h::int, optional, default='0' : Add a random value in $[-random_h, random_h]$ to the H channel in HSL color space. random_s::int, optional, default='0' : Add a random value in $[-random_s, random_s]$ to the S channel in HSL color space. random_l::int, optional, default='0' : Add a random value in $[-random_l, random_l]$ to the L channel in HSL color space. rotate::int, optional, default='-1' : Rotate by an angle. If set, it overwrites the $max_rotate_angle$ option. fill_value::int, optional, default='255' : Set the padding pixels value to $fill_value$. inter_method::int, optional, default='1' : The interpolation method: 0-NN 1-bilinear 2-cubic 3-area 4-lanczos4 9-auto 10-rand. pad::int, optional, default='0' : Change size from $[width, height]$ into $[pad + width + pad, pad + height + pad]$ by padding pixes Returns the constructed MXDataProvider . source # MXNet.mx.LibSVMIter Method . LibSVMIter(data_libsvm, data_shape, label_libsvm, label_shape, num_parts, part_index, batch_size, round_batch, prefetch_buffer, ctx, dtype) Can also be called with the alias LibSVMProvider . Returns the LibSVM iterator which returns data with csr storage type. This iterator is experimental and should be used with care. The input data is stored in a format similar to LibSVM file format, except that the indices are expected to be zero-based instead of one-based, and the column indices for each row are expected to be sorted in ascending order . Details of the LibSVM format are available here. https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/ _ The data_shape parameter is used to set the shape of each line of the data. The dimension of both data_shape and label_shape are expected to be 1. The data_libsvm parameter is used to set the path input LibSVM file. When it is set to a directory, all the files in the directory will be read. When label_libsvm is set to $NULL$, both data and label are read from the file specified by data_libsvm . In this case, the data is stored in csr storage type, while the label is a 1D dense array. The LibSVMIter only support round_batch parameter set to $True$. Therefore, if batch_size is 3 and there are 4 total rows in libsvm file, 2 more examples are consumed at the first round. When num_parts and part_index are provided, the data is split into num_parts partitions, and the iterator only reads the part_index -th partition. However, the partitions are not guaranteed to be even. $reset()$ is expected to be called only after a complete pass of data. Example:: Contents of libsvm file $data.t$. 1.0 0:0.5 2:1.2 -2.0 -3.0 0:0.6 1:2.4 2:1.2 4 2:-1.2 Creates a LibSVMIter with batch_size =3. data iter = mx.io.LibSVMIter(data libsvm = 'data.t', data shape = (3,), batch size = 3) The data of the first batch is stored in csr storage type batch = data_iter.next() csr = batch.data[0] csr.asnumpy() [[ 0.5 0. 1.2 ] [ 0. 0. 0. ] [ 0.6 2.4 1.2]] The label of first batch label = batch.label[0] label [ 1. -2. -3.] second batch = data iter.next() The data of the second batch second_batch.data[0].asnumpy() [[ 0. 0. -1.2 ] [ 0.5 0. 1.2 ] [ 0. 0. 0. ]] The label of the second batch second_batch.label[0].asnumpy() [ 4. 1. -2.] data_iter.reset() To restart the iterator for the second pass of the data When label_libsvm is set to the path to another LibSVM file, data is read from data_libsvm and label from label_libsvm . In this case, both data and label are stored in the csr format. If the label column in the data_libsvm file is ignored. Example:: Contents of libsvm file $label.t$ 1.0 -2.0 0:0.125 -3.0 2:1.2 4 1:1.0 2:-1.2 Creates a LibSVMIter with specified label file data iter = mx.io.LibSVMIter(data libsvm = 'data.t', data_shape = (3,), label_libsvm = 'label.t', label_shape = (3,), batch_size = 3) Both data and label are in csr storage type batch = data iter.next() csr data = batch.data[0] csr_data.asnumpy() [[ 0.5 0. 1.2 ] [ 0. 0. 0. ] [ 0.6 2.4 1.2 ]] csr_label = batch.label[0] csr_label.asnumpy() [[ 0. 0. 0. ] [ 0.125 0. 0. ] [ 0. 0. 1.2 ]] Defined in src/io/iter_libsvm.cc:L298 Arguments: data_name::Symbol : keyword argument, default :data . The name of the data. label_name::Symbol : keyword argument, default :softmax_label . The name of the label. Could be nothing if no label is presented in this dataset. data_libsvm::string, required : The input zero-base indexed LibSVM data file or a directory path. data_shape::Shape(tuple), required : The shape of one example. label_libsvm::string, optional, default='NULL' : The input LibSVM label file or a directory path. If NULL, all labels will be read from $data_libsvm$. label_shape::Shape(tuple), optional, default=[1] : The shape of one label. num_parts::int, optional, default='1' : partition the data into multiple parts part_index::int, optional, default='0' : the index of the part will read batch_size::int (non-negative), required : Batch size. round_batch::boolean, optional, default=1 : Whether to use round robin to handle overflow batch or not. prefetch_buffer::long (non-negative), optional, default=4 : Maximum number of batches to prefetch. ctx::{'cpu', 'gpu'},optional, default='gpu' : Context data loader optimized for. dtype::{None, 'float16', 'float32', 'float64', 'int32', 'int64', 'int8', 'uint8'},optional, default='None' : Output data type. $None$ means no change. Returns the constructed MXDataProvider . source # MXNet.mx.MNISTIter Method . MNISTIter(image, label, batch_size, shuffle, flat, seed, silent, num_parts, part_index, prefetch_buffer, ctx, dtype) Can also be called with the alias MNISTProvider . Iterating on the MNIST dataset. One can download the dataset from http://yann.lecun.com/exdb/mnist/ Defined in src/io/iter_mnist.cc:L265 Arguments: data_name::Symbol : keyword argument, default :data . The name of the data. label_name::Symbol : keyword argument, default :softmax_label . The name of the label. Could be nothing if no label is presented in this dataset. image::string, optional, default='./train-images-idx3-ubyte' : Dataset Param: Mnist image path. label::string, optional, default='./train-labels-idx1-ubyte' : Dataset Param: Mnist label path. batch_size::int, optional, default='128' : Batch Param: Batch Size. shuffle::boolean, optional, default=1 : Augmentation Param: Whether to shuffle data. flat::boolean, optional, default=0 : Augmentation Param: Whether to flat the data into 1D. seed::int, optional, default='0' : Augmentation Param: Random Seed. silent::boolean, optional, default=0 : Auxiliary Param: Whether to print out data info. num_parts::int, optional, default='1' : partition the data into multiple parts part_index::int, optional, default='0' : the index of the part will read prefetch_buffer::long (non-negative), optional, default=4 : Maximum number of batches to prefetch. ctx::{'cpu', 'gpu'},optional, default='gpu' : Context data loader optimized for. dtype::{None, 'float16', 'float32', 'float64', 'int32', 'int64', 'int8', 'uint8'},optional, default='None' : Output data type. $None$ means no change. Returns the constructed MXDataProvider . source # MXNet.mx.eachbatch Method . eachbatch(provider::AbstractDataProvider) Allows you to perform operations on data every epoch. This is especially useful when you need to perform real-time augmentation of the data. Arguments: provider : an instance of the custom DataProvider type. You must return this instance after modifying its fields. source # MXNet.mx.from_json Method . from_json(repr :: AbstractString, ::Type{SymbolicNode}) Load a SymbolicNode from a JSON string representation. source # MXNet.mx.is_shared Method . is_shared(j_arr, arr) Test whether j_arr is sharing data with arr . Arguments: j_arr::Array : the Julia Array. arr::NDArray : the NDArray . source # MXNet.mx.load Method . load(filename, ::Type{NDArray}) Load NDArrays from binary file. Arguments: filename::String : the path of the file to load. It could be S3 or HDFS address. Returns either Dict{Symbol, NDArray} or Vector{NDArray} . filename can point to s3 or hdfs resources if the libmxnet is built with the corresponding components enabled. Examples: s3://my-bucket/path/my-s3-ndarray hdfs://my-bucket/path/my-hdfs-ndarray /path-to/my-local-ndarray source # MXNet.mx.load Method . load(filename :: AbstractString, ::Type{SymbolicNode}) Load a SymbolicNode from a JSON file. source # MXNet.mx.load_data! Method . load_data!(provider, batch, targets) Arguments: provider::AbstractDataProvider : the data provider. batch::AbstractDataBatch : the data batch object. targets::Vector{Vector{SlicedNDArray}} : the targets to load data into. The targets is a list of the same length as number of data provided by this provider. Each element in the list is a list of SlicedNDArray . This list described a spliting scheme of this data batch into different slices, each slice is specified by a slice-ndarray pair, where slice specify the range of samples in the mini-batch that should be loaded into the corresponding ndarray . This utility function is used in data parallelization, where a mini-batch is splited and computed on several different devices. source # MXNet.mx.load_label! Method . load_label!(provider, batch, targets) provider::AbstractDataProvider provider : the data provider. batch::AbstractDataBatch batch : the data batch object. targets::Vector{Vector{SlicedNDArray}} : the targets to load label into. The same as load_data! , except that this is for loading labels. source # MXNet.mx.save Method . save(filename :: AbstractString, node :: SymbolicNode) Save a SymbolicNode to a JSON file. source # MXNet.mx.save Method . save(filename::AbstractString, data) Save NDarrays to binary file. Filename could be S3 or HDFS address, if libmxnet is built with corresponding support (see load ). filename::String : path to the binary file to write to. data : data to save to file. Data can be a NDArray , a Vector of NDArray , or a Dict{Symbol} contains NDArray s. source # MXNet.mx.to_json Method . to_json(s::SymbolicNode) Convert a SymbolicNode into a JSON string. source # MXNet.mx.try_get_shared Method . try_get_shared(arr; sync=:nop) Try to create a Julia array by sharing the data with the underlying NDArray . Arguments: arr::NDArray : the array to be shared. Note The returned array does not guarantee to share data with the underlying NDArray . In particular, data sharing is possible only when the NDArray lives on CPU. sync::Symbol : :nop , :write , :read On CPU, invoke _wait_to_read if :read ; invoke _wait_to_write if :write . source","title":"Data Providers"},{"location":"api/io/#data-providers","text":"Data providers are wrappers that load external data, be it images, text, or general tensors, and split it into mini-batches so that the model can consume the data in a uniformed way.","title":"Data Providers"},{"location":"api/io/#abstractdataprovider-interface","text":"# MXNet.mx.AbstractDataProvider Type . AbstractDataProvider The root type for all data provider. A data provider should implement the following interfaces: get_batch_size provide_data provide_label As well as the Julia iterator interface (see the Julia manual ). Normally this involves defining: Base.eltype(provider) - AbstractDataBatch Base.iterate(provider[, state]) - (AbstractDataBatch, AbstractDataProvider) source The difference between data and label is that during training stage, both data and label will be feeded into the model, while during prediction stage, only data is loaded. Otherwise, they could be anything, with any names, and of any shapes. The provided data and label names here should match the input names in a target SymbolicNode . A data provider should also implement the Julia iteration interface, in order to allow iterating through the data set. The provider will be called in the following way: for batch in eachbatch(provider) data = get_data(provider, batch) end which will be translated by Julia compiler into state = Base.start(eachbatch(provider)) while !Base.done(provider, state) (batch, state) = Base.next(provider, state) data = get_data(provider, batch) end By default, eachbatch simply returns the provider itself, so the iterator interface is implemented on the provider type itself. But the extra layer of abstraction allows us to implement a data provider easily via a Julia Task coroutine. See the data provider defined in the char-lstm example for an example of using coroutine to define data providers. The detailed interface functions for the iterator API is listed below: Base.eltype(provider) - AbstractDataBatch Returns the specific subtype representing a data batch. See AbstractDataBatch . provider::AbstractDataProvider : the data provider. Base.start(provider) - AbstractDataProviderState This function is always called before iterating into the dataset. It should initialize the iterator, reset the index, and do data shuffling if needed. provider::AbstractDataProvider : the data provider. Base.done(provider, state) - Bool True if there is no more data to iterate in this dataset. provider::AbstractDataProvider : the data provider. state::AbstractDataProviderState : the state returned by Base.start and Base.next . Base.next(provider) - (AbstractDataBatch, AbstractDataProviderState) Returns the current data batch, and the state for the next iteration. provider::AbstractDataProvider : the data provider. Note sometimes you are wrapping an existing data iterator (e.g. the built-in libmxnet data iterator) that is built with a different convention. It might be difficult to adapt to the interfaces stated here. In this case, you can safely assume that Base.start will always be called, and called only once before the iteration starts. Base.done will always be called at the beginning of every iteration and always be called once. If Base.done return true, the iteration will stop, until the next round, again, starting with a call to Base.start . Base.next will always be called only once in each iteration. It will always be called after one and only one call to Base.done ; but if Base.done returns true, Base.next will not be called. With those assumptions, it will be relatively easy to adapt any existing iterator. See the implementation of the built-in MXDataProvider for example. Note Please do not use the one data provider simultaneously in two different places, either in parallel, or in a nested loop. For example, the behavior for the following code is undefined ```julia for batch in data # updating the parameters # now let's test the performance on the training set for b2 in data # ... end end ``` # MXNet.mx.get_batch_size Function . get_batch_size(provider) - Int Arguments: provider::AbstractDataProvider : the data provider. Returns the mini-batch size of the provided data. All the provided data should have the same mini-batch size (i.e. the last dimension). source # MXNet.mx.provide_data Function . provide_data(provider) - Vector{Tuple{Base.Symbol, Tuple}} Arguments: provider::AbstractDataProvider : the data provider. Returns a vector of (name, shape) pairs describing the names of the data it provides, and the corresponding shapes. source # MXNet.mx.provide_label Function . provide_label(provider) - Vector{Tuple{Base.Symbol, Tuple}} Arguments: provider::AbstractDataProvider : the data provider. Returns a vector of (name, shape) pairs describing the names of the labels it provides, and the corresponding shapes. source","title":"AbstractDataProvider interface"},{"location":"api/io/#abstractdatabatch-interface","text":"# MXNet.mx.AbstractDataProviderState Type . AbstractDataProviderState Base type for data provider states. source # MXNet.mx.count_samples Function . count_samples(provider, batch) - Int Arguments: batch::AbstractDataBatch : the data batch object. Returns the number of samples in this batch. This number should be greater than 0, but less than or equal to the batch size. This is used to indicate at the end of the data set, there might not be enough samples for a whole mini-batch. source # MXNet.mx.get_data Function . get_data(provider, batch) - Vector{NDArray} Arguments: provider::AbstractDataProvider : the data provider. batch::AbstractDataBatch : the data batch object. Returns a vector of data in this batch, should be in the same order as declared in provide_data() AbstractDataProvider.provide_data . The last dimension of each NDArray should always match the batch*size, even when count*samples returns a value less than the batch size. In this case, the data provider is free to pad the remaining contents with any value. source # MXNet.mx.get_label Function . get_label(provider, batch) - Vector{NDArray} Arguments: provider::AbstractDataProvider : the data provider. batch::AbstractDataBatch : the data batch object. Returns a vector of labels in this batch. Similar to get_data . source # Base.get Function . get(sched) sched::AbstractMomentumScheduler : the momentum scheduler. Returns the current momentum. source # MXNet.mx.load_data! Function . load_data!(provider, batch, targets) Arguments: provider::AbstractDataProvider : the data provider. batch::AbstractDataBatch : the data batch object. targets::Vector{Vector{SlicedNDArray}} : the targets to load data into. The targets is a list of the same length as number of data provided by this provider. Each element in the list is a list of SlicedNDArray . This list described a spliting scheme of this data batch into different slices, each slice is specified by a slice-ndarray pair, where slice specify the range of samples in the mini-batch that should be loaded into the corresponding ndarray . This utility function is used in data parallelization, where a mini-batch is splited and computed on several different devices. source # MXNet.mx.load_label! Function . load_label!(provider, batch, targets) provider::AbstractDataProvider provider : the data provider. batch::AbstractDataBatch batch : the data batch object. targets::Vector{Vector{SlicedNDArray}} : the targets to load label into. The same as load_data! , except that this is for loading labels. source","title":"AbstractDataBatch interface"},{"location":"api/io/#implemented-providers-and-other-methods","text":"# MXNet.mx.AbstractDataBatch Type . AbstractDataBatch Base type for a data mini-batch. It should implement the following interfaces: count_samples get_data get_label The following utility functions will be automatically defined: get load_data! load_label! source # MXNet.mx.ArrayDataProvider Type . ArrayDataProvider A convenient tool to iterate NDArray or Julia Array . ArrayDataProvider(data[, label]; batch_size, shuffle, data_padding, label_padding) Construct a data provider from NDArray or Julia Arrays. Arguments: data : the data, could be a NDArray , or a Julia Array. This is equivalent to :data = data . a name-data pair, like :mydata = array , where :mydata is the name of the data and array is an NDArray or a Julia Array. a list of name-data pairs. label : the same as the data parameter. When this argument is omitted, the constructed provider will provide no labels. batch_size::Int : the batch size, default is 0, which means treating the whole array as a single mini-batch. shuffle::Bool : turn on if the data should be shuffled at every epoch. data_padding::Real : when the mini-batch goes beyond the dataset boundary, there might be less samples to include than a mini-batch. This value specify a scalar to pad the contents of all the missing data points. label_padding::Real : the same as data_padding , except for the labels. TODO: remove data_padding and label_padding , and implement rollover that copies the last or first several training samples to feed the padding. source # MXNet.mx.DataBatch Type . DataBatch A basic subclass of AbstractDataBatch , that implement the interface by accessing member fields. source # MXNet.mx.MXDataProvider Type . MXDataProvider A data provider that wrap built-in data iterators from libmxnet. See below for a list of built-in data iterators. source # MXNet.mx.SlicedNDArray Type . SlicedNDArray A alias type of Tuple{UnitRange{Int},NDArray} . source # Base.get Method . get(provider, batch, name) - NDArray provider::AbstractDataProvider : the data provider. batch::AbstractDataBatch : the data batch object. name::Symbol : the name of the data to get, should be one of the names provided in either provide_data() AbstractDataProvider.provide_data or provide_label() AbstractDataProvider.provide_label . Returns the corresponding data array corresponding to that name. source # MXNet.mx.CSVIter Method . CSVIter(data_csv, data_shape, label_csv, label_shape, batch_size, round_batch, prefetch_buffer, ctx, dtype) Can also be called with the alias CSVProvider . Returns the CSV file iterator. In this function, the data_shape parameter is used to set the shape of each line of the input data. If a row in an input file is 1,2,3,4,5,6``and data_shape` is (3,2), that row will be reshaped, yielding the array [[1,2],[3,4],[5,6]] of shape (3,2). By default, the CSVIter has round_batch parameter set to $True$. So, if batch_size is 3 and there are 4 total rows in CSV file, 2 more examples are consumed at the first round. If reset function is called after first round, the call is ignored and remaining examples are returned in the second round. If one wants all the instances in the second round after calling reset , make sure to set round_batch to False. If $data_csv = 'data/'$ is set, then all the files in this directory will be read. $reset()$ is expected to be called only after a complete pass of data. By default, the CSVIter parses all entries in the data file as float32 data type, if dtype argument is set to be 'int32' or 'int64' then CSVIter will parse all entries in the file as int32 or int64 data type accordingly. Examples:: // Contents of CSV file $data/data.csv$. 1,2,3 2,3,4 3,4,5 4,5,6 // Creates a CSVIter with batch_size =2 and default round_batch =True. CSVIter = mx.io.CSVIter(data csv = 'data/data.csv', data shape = (3,), batch_size = 2) // Two batches read from the above iterator are as follows: [[ 1. 2. 3.] [ 2. 3. 4.]] [[ 3. 4. 5.] [ 4. 5. 6.]] // Creates a CSVIter with default round_batch set to True. CSVIter = mx.io.CSVIter(data csv = 'data/data.csv', data shape = (3,), batch_size = 3) // Two batches read from the above iterator in the first pass are as follows: [[1. 2. 3.] [2. 3. 4.] [3. 4. 5.]] [[4. 5. 6.] [1. 2. 3.] [2. 3. 4.]] // Now, reset method is called. CSVIter.reset() // Batch read from the above iterator in the second pass is as follows: [[ 3. 4. 5.] [ 4. 5. 6.] [ 1. 2. 3.]] // Creates a CSVIter with round_batch =False. CSVIter = mx.io.CSVIter(data csv = 'data/data.csv', data shape = (3,), batch size = 3, round batch=False) // Contents of two batches read from the above iterator in both passes, after calling // reset method before second pass, is as follows: [[1. 2. 3.] [2. 3. 4.] [3. 4. 5.]] [[4. 5. 6.] [2. 3. 4.] [3. 4. 5.]] // Creates a 'CSVIter' with dtype ='int32' CSVIter = mx.io.CSVIter(data csv = 'data/data.csv', data shape = (3,), batch size = 3, round batch=False, dtype='int32') // Contents of two batches read from the above iterator in both passes, after calling // reset method before second pass, is as follows: [[1 2 3] [2 3 4] [3 4 5]] [[4 5 6] [2 3 4] [3 4 5]] Defined in src/io/iter_csv.cc:L308 Arguments: data_name::Symbol : keyword argument, default :data . The name of the data. label_name::Symbol : keyword argument, default :softmax_label . The name of the label. Could be nothing if no label is presented in this dataset. data_csv::string, required : The input CSV file or a directory path. data_shape::Shape(tuple), required : The shape of one example. label_csv::string, optional, default='NULL' : The input CSV file or a directory path. If NULL, all labels will be returned as 0. label_shape::Shape(tuple), optional, default=[1] : The shape of one label. batch_size::int (non-negative), required : Batch size. round_batch::boolean, optional, default=1 : Whether to use round robin to handle overflow batch or not. prefetch_buffer::long (non-negative), optional, default=4 : Maximum number of batches to prefetch. ctx::{'cpu', 'gpu'},optional, default='gpu' : Context data loader optimized for. dtype::{None, 'float16', 'float32', 'float64', 'int32', 'int64', 'int8', 'uint8'},optional, default='None' : Output data type. $None$ means no change. Returns the constructed MXDataProvider . source # MXNet.mx.ImageDetRecordIter Method . ImageDetRecordIter(path_imglist, path_imgrec, aug_seq, label_width, data_shape, preprocess_threads, verbose, num_parts, part_index, shuffle_chunk_size, shuffle_chunk_seed, label_pad_width, label_pad_value, shuffle, seed, verbose, batch_size, round_batch, prefetch_buffer, ctx, dtype, resize, rand_crop_prob, min_crop_scales, max_crop_scales, min_crop_aspect_ratios, max_crop_aspect_ratios, min_crop_overlaps, max_crop_overlaps, min_crop_sample_coverages, max_crop_sample_coverages, min_crop_object_coverages, max_crop_object_coverages, num_crop_sampler, crop_emit_mode, emit_overlap_thresh, max_crop_trials, rand_pad_prob, max_pad_scale, max_random_hue, random_hue_prob, max_random_saturation, random_saturation_prob, max_random_illumination, random_illumination_prob, max_random_contrast, random_contrast_prob, rand_mirror_prob, fill_value, inter_method, data_shape, resize_mode, seed, mean_img, mean_r, mean_g, mean_b, mean_a, std_r, std_g, std_b, std_a, scale, verbose) Can also be called with the alias ImageDetRecordProvider . Create iterator for image detection dataset packed in recordio. Arguments: data_name::Symbol : keyword argument, default :data . The name of the data. label_name::Symbol : keyword argument, default :softmax_label . The name of the label. Could be nothing if no label is presented in this dataset. path_imglist::string, optional, default='' : Dataset Param: Path to image list. path_imgrec::string, optional, default='./data/imgrec.rec' : Dataset Param: Path to image record file. aug_seq::string, optional, default='det_aug_default' : Augmentation Param: the augmenter names to represent sequence of augmenters to be applied, seperated by comma. Additional keyword parameters will be seen by these augmenters. Make sure you don't use normal augmenters for detection tasks. label_width::int, optional, default='-1' : Dataset Param: How many labels for an image, -1 for variable label size. data_shape::Shape(tuple), required : Dataset Param: Shape of each instance generated by the DataIter. preprocess_threads::int, optional, default='4' : Backend Param: Number of thread to do preprocessing. verbose::boolean, optional, default=1 : Auxiliary Param: Whether to output parser information. num_parts::int, optional, default='1' : partition the data into multiple parts part_index::int, optional, default='0' : the index of the part will read shuffle_chunk_size::long (non-negative), optional, default=0 : the size(MB) of the shuffle chunk, used with shuffle=True, it can enable global shuffling shuffle_chunk_seed::int, optional, default='0' : the seed for chunk shuffling label_pad_width::int, optional, default='0' : pad output label width if set larger than 0, -1 for auto estimate label_pad_value::float, optional, default=-1 : label padding value if enabled shuffle::boolean, optional, default=0 : Augmentation Param: Whether to shuffle data. seed::int, optional, default='0' : Augmentation Param: Random Seed. batch_size::int (non-negative), required : Batch size. round_batch::boolean, optional, default=1 : Whether to use round robin to handle overflow batch or not. prefetch_buffer::long (non-negative), optional, default=4 : Maximum number of batches to prefetch. ctx::{'cpu', 'gpu'},optional, default='gpu' : Context data loader optimized for. dtype::{None, 'float16', 'float32', 'float64', 'int32', 'int64', 'int8', 'uint8'},optional, default='None' : Output data type. $None$ means no change. resize::int, optional, default='-1' : Augmentation Param: scale shorter edge to size before applying other augmentations, -1 to disable. rand_crop_prob::float, optional, default=0 : Augmentation Param: Probability of random cropping, = 0 to disable min_crop_scales::tuple of float , optional, default=[0] : Augmentation Param: Min crop scales. max_crop_scales::tuple of float , optional, default=[1] : Augmentation Param: Max crop scales. min_crop_aspect_ratios::tuple of float , optional, default=[1] : Augmentation Param: Min crop aspect ratios. max_crop_aspect_ratios::tuple of float , optional, default=[1] : Augmentation Param: Max crop aspect ratios. min_crop_overlaps::tuple of float , optional, default=[0] : Augmentation Param: Minimum crop IOU between crop_box and ground-truths. max_crop_overlaps::tuple of float , optional, default=[1] : Augmentation Param: Maximum crop IOU between crop_box and ground-truth. min_crop_sample_coverages::tuple of float , optional, default=[0] : Augmentation Param: Minimum ratio of intersect/crop_area between crop box and ground-truths. max_crop_sample_coverages::tuple of float , optional, default=[1] : Augmentation Param: Maximum ratio of intersect/crop_area between crop box and ground-truths. min_crop_object_coverages::tuple of float , optional, default=[0] : Augmentation Param: Minimum ratio of intersect/gt_area between crop box and ground-truths. max_crop_object_coverages::tuple of float , optional, default=[1] : Augmentation Param: Maximum ratio of intersect/gt_area between crop box and ground-truths. num_crop_sampler::int, optional, default='1' : Augmentation Param: Number of crop samplers. crop_emit_mode::{'center', 'overlap'},optional, default='center' : Augmentation Param: Emition mode for invalid ground-truths after crop. center: emit if centroid of object is out of crop region; overlap: emit if overlap is less than emit overlap thresh. emit_overlap_thresh::float, optional, default=0.300000012 : Augmentation Param: Emit overlap thresh for emit mode overlap only. max_crop_trials::Shape(tuple), optional, default=[25] : Augmentation Param: Skip cropping if fail crop trail count exceeds this number. rand_pad_prob::float, optional, default=0 : Augmentation Param: Probability for random padding. max_pad_scale::float, optional, default=1 : Augmentation Param: Maximum padding scale. max_random_hue::int, optional, default='0' : Augmentation Param: Maximum random value of H channel in HSL color space. random_hue_prob::float, optional, default=0 : Augmentation Param: Probability to apply random hue. max_random_saturation::int, optional, default='0' : Augmentation Param: Maximum random value of S channel in HSL color space. random_saturation_prob::float, optional, default=0 : Augmentation Param: Probability to apply random saturation. max_random_illumination::int, optional, default='0' : Augmentation Param: Maximum random value of L channel in HSL color space. random_illumination_prob::float, optional, default=0 : Augmentation Param: Probability to apply random illumination. max_random_contrast::float, optional, default=0 : Augmentation Param: Maximum random value of delta contrast. random_contrast_prob::float, optional, default=0 : Augmentation Param: Probability to apply random contrast. rand_mirror_prob::float, optional, default=0 : Augmentation Param: Probability to apply horizontal flip aka. mirror. fill_value::int, optional, default='127' : Augmentation Param: Filled color value while padding. inter_method::int, optional, default='1' : Augmentation Param: 0-NN 1-bilinear 2-cubic 3-area 4-lanczos4 9-auto 10-rand. resize_mode::{'fit', 'force', 'shrink'},optional, default='force' : Augmentation Param: How image data fit in data shape. force: force reshape to data shape regardless of aspect ratio; shrink: ensure each side fit in data shape, preserve aspect ratio; fit: fit image to data shape, preserve ratio, will upscale if applicable. mean_img::string, optional, default='' : Augmentation Param: Mean Image to be subtracted. mean_r::float, optional, default=0 : Augmentation Param: Mean value on R channel. mean_g::float, optional, default=0 : Augmentation Param: Mean value on G channel. mean_b::float, optional, default=0 : Augmentation Param: Mean value on B channel. mean_a::float, optional, default=0 : Augmentation Param: Mean value on Alpha channel. std_r::float, optional, default=0 : Augmentation Param: Standard deviation on R channel. std_g::float, optional, default=0 : Augmentation Param: Standard deviation on G channel. std_b::float, optional, default=0 : Augmentation Param: Standard deviation on B channel. std_a::float, optional, default=0 : Augmentation Param: Standard deviation on Alpha channel. scale::float, optional, default=1 : Augmentation Param: Scale in color space. Returns the constructed MXDataProvider . source # MXNet.mx.ImageRecordInt8Iter Method . ImageRecordInt8Iter(path_imglist, path_imgrec, path_imgidx, aug_seq, label_width, data_shape, preprocess_threads, verbose, num_parts, part_index, device_id, shuffle_chunk_size, shuffle_chunk_seed, seed_aug, shuffle, seed, verbose, batch_size, round_batch, prefetch_buffer, ctx, dtype, resize, rand_crop, random_resized_crop, max_rotate_angle, max_aspect_ratio, min_aspect_ratio, max_shear_ratio, max_crop_size, min_crop_size, max_random_scale, min_random_scale, max_random_area, min_random_area, max_img_size, min_img_size, brightness, contrast, saturation, pca_noise, random_h, random_s, random_l, rotate, fill_value, data_shape, inter_method, pad) Can also be called with the alias ImageRecordInt8Provider . Iterating on image RecordIO files .. note:: $ImageRecordInt8Iter$ is deprecated. Use ImageRecordIter(dtype='int8') instead. This iterator is identical to $ImageRecordIter$ except for using $int8$ as the data type instead of $float$. Defined in src/io/iter image recordio_2.cc:L934 Arguments: data_name::Symbol : keyword argument, default :data . The name of the data. label_name::Symbol : keyword argument, default :softmax_label . The name of the label. Could be nothing if no label is presented in this dataset. path_imglist::string, optional, default='' : Path to the image list (.lst) file. Generally created with tools/im2rec.py. Format (Tab separated): . path_imgrec::string, optional, default='' : Path to the image RecordIO (.rec) file or a directory path. Created with tools/im2rec.py. path_imgidx::string, optional, default='' : Path to the image RecordIO index (.idx) file. Created with tools/im2rec.py. aug_seq::string, optional, default='aug_default' : The augmenter names to represent sequence of augmenters to be applied, seperated by comma. Additional keyword parameters will be seen by these augmenters. label_width::int, optional, default='1' : The number of labels per image. data_shape::Shape(tuple), required : The shape of one output image in (channels, height, width) format. preprocess_threads::int, optional, default='4' : The number of threads to do preprocessing. verbose::boolean, optional, default=1 : If or not output verbose information. num_parts::int, optional, default='1' : Virtually partition the data into these many parts. part_index::int, optional, default='0' : The i -th virtual partition to be read. device_id::int, optional, default='0' : The device id used to create context for internal NDArray. Setting device id to -1 will create Context::CPU(0). Setting device id to valid positive device id will create Context::CPUPinned(device_id). Default is 0. shuffle_chunk_size::long (non-negative), optional, default=0 : The data shuffle buffer size in MB. Only valid if shuffle is true. shuffle_chunk_seed::int, optional, default='0' : The random seed for shuffling seed_aug::int or None, optional, default='None' : Random seed for augmentations. shuffle::boolean, optional, default=0 : Whether to shuffle data randomly or not. seed::int, optional, default='0' : The random seed. batch_size::int (non-negative), required : Batch size. round_batch::boolean, optional, default=1 : Whether to use round robin to handle overflow batch or not. prefetch_buffer::long (non-negative), optional, default=4 : Maximum number of batches to prefetch. ctx::{'cpu', 'gpu'},optional, default='gpu' : Context data loader optimized for. dtype::{None, 'float16', 'float32', 'float64', 'int32', 'int64', 'int8', 'uint8'},optional, default='None' : Output data type. $None$ means no change. resize::int, optional, default='-1' : Down scale the shorter edge to a new size before applying other augmentations. rand_crop::boolean, optional, default=0 : If or not randomly crop the image random_resized_crop::boolean, optional, default=0 : If or not perform random resized cropping on the image, as a standard preprocessing for resnet training on ImageNet data. max_rotate_angle::int, optional, default='0' : Rotate by a random degree in $[-v, v]$ max_aspect_ratio::float, optional, default=0 : Change the aspect (namely width/height) to a random value. If min aspect ratio is None then the aspect ratio ins sampled from [1 - max aspect ratio, 1 + max aspect ratio], else it is in $[min_aspect_ratio, max_aspect_ratio]$ min_aspect_ratio::float or None, optional, default=None : Change the aspect (namely width/height) to a random value in $[min_aspect_ratio, max_aspect_ratio]$ max_shear_ratio::float, optional, default=0 : Apply a shear transformation (namely $(x,y)- (x+my,y)$) with $m$ randomly chose from $[-max_shear_ratio, max_shear_ratio]$ max_crop_size::int, optional, default='-1' : Crop both width and height into a random size in $[min_crop_size, max_crop_size].$Ignored if $random_resized_crop$ is True. min_crop_size::int, optional, default='-1' : Crop both width and height into a random size in $[min_crop_size, max_crop_size].$Ignored if $random_resized_crop$ is True. max_random_scale::float, optional, default=1 : Resize into $[width s, height s]$ with $s$ randomly chosen from $[min_random_scale, max_random_scale]$. Ignored if $random_resized_crop$ is True. min_random_scale::float, optional, default=1 : Resize into $[width s, height s]$ with $s$ randomly chosen from $[min_random_scale, max_random_scale]$Ignored if $random_resized_crop$ is True. max_random_area::float, optional, default=1 : Change the area (namely width * height) to a random value in $[min_random_area, max_random_area]$. Ignored if $random_resized_crop$ is False. min_random_area::float, optional, default=1 : Change the area (namely width * height) to a random value in $[min_random_area, max_random_area]$. Ignored if $random_resized_crop$ is False. max_img_size::float, optional, default=1e+10 : Set the maximal width and height after all resize and rotate argumentation are applied min_img_size::float, optional, default=0 : Set the minimal width and height after all resize and rotate argumentation are applied brightness::float, optional, default=0 : Add a random value in $[-brightness, brightness]$ to the brightness of image. contrast::float, optional, default=0 : Add a random value in $[-contrast, contrast]$ to the contrast of image. saturation::float, optional, default=0 : Add a random value in $[-saturation, saturation]$ to the saturation of image. pca_noise::float, optional, default=0 : Add PCA based noise to the image. random_h::int, optional, default='0' : Add a random value in $[-random_h, random_h]$ to the H channel in HSL color space. random_s::int, optional, default='0' : Add a random value in $[-random_s, random_s]$ to the S channel in HSL color space. random_l::int, optional, default='0' : Add a random value in $[-random_l, random_l]$ to the L channel in HSL color space. rotate::int, optional, default='-1' : Rotate by an angle. If set, it overwrites the $max_rotate_angle$ option. fill_value::int, optional, default='255' : Set the padding pixels value to $fill_value$. inter_method::int, optional, default='1' : The interpolation method: 0-NN 1-bilinear 2-cubic 3-area 4-lanczos4 9-auto 10-rand. pad::int, optional, default='0' : Change size from $[width, height]$ into $[pad + width + pad, pad + height + pad]$ by padding pixes Returns the constructed MXDataProvider . source # MXNet.mx.ImageRecordIter Method . ImageRecordIter(path_imglist, path_imgrec, path_imgidx, aug_seq, label_width, data_shape, preprocess_threads, verbose, num_parts, part_index, device_id, shuffle_chunk_size, shuffle_chunk_seed, seed_aug, shuffle, seed, verbose, batch_size, round_batch, prefetch_buffer, ctx, dtype, resize, rand_crop, random_resized_crop, max_rotate_angle, max_aspect_ratio, min_aspect_ratio, max_shear_ratio, max_crop_size, min_crop_size, max_random_scale, min_random_scale, max_random_area, min_random_area, max_img_size, min_img_size, brightness, contrast, saturation, pca_noise, random_h, random_s, random_l, rotate, fill_value, data_shape, inter_method, pad, seed, mirror, rand_mirror, mean_img, mean_r, mean_g, mean_b, mean_a, std_r, std_g, std_b, std_a, scale, max_random_contrast, max_random_illumination, verbose) Can also be called with the alias ImageRecordProvider . Iterates on image RecordIO files Reads batches of images from .rec RecordIO files. One can use $im2rec.py$ tool (in tools/) to pack raw image files into RecordIO files. This iterator is less flexible to customization but is fast and has lot of language bindings. To iterate over raw images directly use $ImageIter$ instead (in Python). Example:: data iter = mx.io.ImageRecordIter( path imgrec=\"./sample.rec\", # The target record file. data shape=(3, 227, 227), # Output data shape; 227x227 region will be cropped from the original image. batch size=4, # Number of items per batch. resize=256 # Resize the shorter edge to 256 before cropping. # You can specify more augmentation options. Use help(mx.io.ImageRecordIter) to see all the options. ) You can now use the data_iter to access batches of images. batch = data iter.next() # first batch. images = batch.data[0] # This will contain 4 (=batch size) images each of 3x227x227. process the images ... data_iter.reset() # To restart the iterator from the beginning. Defined in src/io/iter image recordio_2.cc:L897 Arguments: data_name::Symbol : keyword argument, default :data . The name of the data. label_name::Symbol : keyword argument, default :softmax_label . The name of the label. Could be nothing if no label is presented in this dataset. path_imglist::string, optional, default='' : Path to the image list (.lst) file. Generally created with tools/im2rec.py. Format (Tab separated): . path_imgrec::string, optional, default='' : Path to the image RecordIO (.rec) file or a directory path. Created with tools/im2rec.py. path_imgidx::string, optional, default='' : Path to the image RecordIO index (.idx) file. Created with tools/im2rec.py. aug_seq::string, optional, default='aug_default' : The augmenter names to represent sequence of augmenters to be applied, seperated by comma. Additional keyword parameters will be seen by these augmenters. label_width::int, optional, default='1' : The number of labels per image. data_shape::Shape(tuple), required : The shape of one output image in (channels, height, width) format. preprocess_threads::int, optional, default='4' : The number of threads to do preprocessing. verbose::boolean, optional, default=1 : If or not output verbose information. num_parts::int, optional, default='1' : Virtually partition the data into these many parts. part_index::int, optional, default='0' : The i -th virtual partition to be read. device_id::int, optional, default='0' : The device id used to create context for internal NDArray. Setting device id to -1 will create Context::CPU(0). Setting device id to valid positive device id will create Context::CPUPinned(device_id). Default is 0. shuffle_chunk_size::long (non-negative), optional, default=0 : The data shuffle buffer size in MB. Only valid if shuffle is true. shuffle_chunk_seed::int, optional, default='0' : The random seed for shuffling seed_aug::int or None, optional, default='None' : Random seed for augmentations. shuffle::boolean, optional, default=0 : Whether to shuffle data randomly or not. seed::int, optional, default='0' : The random seed. batch_size::int (non-negative), required : Batch size. round_batch::boolean, optional, default=1 : Whether to use round robin to handle overflow batch or not. prefetch_buffer::long (non-negative), optional, default=4 : Maximum number of batches to prefetch. ctx::{'cpu', 'gpu'},optional, default='gpu' : Context data loader optimized for. dtype::{None, 'float16', 'float32', 'float64', 'int32', 'int64', 'int8', 'uint8'},optional, default='None' : Output data type. $None$ means no change. resize::int, optional, default='-1' : Down scale the shorter edge to a new size before applying other augmentations. rand_crop::boolean, optional, default=0 : If or not randomly crop the image random_resized_crop::boolean, optional, default=0 : If or not perform random resized cropping on the image, as a standard preprocessing for resnet training on ImageNet data. max_rotate_angle::int, optional, default='0' : Rotate by a random degree in $[-v, v]$ max_aspect_ratio::float, optional, default=0 : Change the aspect (namely width/height) to a random value. If min aspect ratio is None then the aspect ratio ins sampled from [1 - max aspect ratio, 1 + max aspect ratio], else it is in $[min_aspect_ratio, max_aspect_ratio]$ min_aspect_ratio::float or None, optional, default=None : Change the aspect (namely width/height) to a random value in $[min_aspect_ratio, max_aspect_ratio]$ max_shear_ratio::float, optional, default=0 : Apply a shear transformation (namely $(x,y)- (x+my,y)$) with $m$ randomly chose from $[-max_shear_ratio, max_shear_ratio]$ max_crop_size::int, optional, default='-1' : Crop both width and height into a random size in $[min_crop_size, max_crop_size].$Ignored if $random_resized_crop$ is True. min_crop_size::int, optional, default='-1' : Crop both width and height into a random size in $[min_crop_size, max_crop_size].$Ignored if $random_resized_crop$ is True. max_random_scale::float, optional, default=1 : Resize into $[width s, height s]$ with $s$ randomly chosen from $[min_random_scale, max_random_scale]$. Ignored if $random_resized_crop$ is True. min_random_scale::float, optional, default=1 : Resize into $[width s, height s]$ with $s$ randomly chosen from $[min_random_scale, max_random_scale]$Ignored if $random_resized_crop$ is True. max_random_area::float, optional, default=1 : Change the area (namely width * height) to a random value in $[min_random_area, max_random_area]$. Ignored if $random_resized_crop$ is False. min_random_area::float, optional, default=1 : Change the area (namely width * height) to a random value in $[min_random_area, max_random_area]$. Ignored if $random_resized_crop$ is False. max_img_size::float, optional, default=1e+10 : Set the maximal width and height after all resize and rotate argumentation are applied min_img_size::float, optional, default=0 : Set the minimal width and height after all resize and rotate argumentation are applied brightness::float, optional, default=0 : Add a random value in $[-brightness, brightness]$ to the brightness of image. contrast::float, optional, default=0 : Add a random value in $[-contrast, contrast]$ to the contrast of image. saturation::float, optional, default=0 : Add a random value in $[-saturation, saturation]$ to the saturation of image. pca_noise::float, optional, default=0 : Add PCA based noise to the image. random_h::int, optional, default='0' : Add a random value in $[-random_h, random_h]$ to the H channel in HSL color space. random_s::int, optional, default='0' : Add a random value in $[-random_s, random_s]$ to the S channel in HSL color space. random_l::int, optional, default='0' : Add a random value in $[-random_l, random_l]$ to the L channel in HSL color space. rotate::int, optional, default='-1' : Rotate by an angle. If set, it overwrites the $max_rotate_angle$ option. fill_value::int, optional, default='255' : Set the padding pixels value to $fill_value$. inter_method::int, optional, default='1' : The interpolation method: 0-NN 1-bilinear 2-cubic 3-area 4-lanczos4 9-auto 10-rand. pad::int, optional, default='0' : Change size from $[width, height]$ into $[pad + width + pad, pad + height + pad]$ by padding pixes mirror::boolean, optional, default=0 : Whether to mirror the image or not. If true, images are flipped along the horizontal axis. rand_mirror::boolean, optional, default=0 : Whether to randomly mirror images or not. If true, 50% of the images will be randomly mirrored (flipped along the horizontal axis) mean_img::string, optional, default='' : Filename of the mean image. mean_r::float, optional, default=0 : The mean value to be subtracted on the R channel mean_g::float, optional, default=0 : The mean value to be subtracted on the G channel mean_b::float, optional, default=0 : The mean value to be subtracted on the B channel mean_a::float, optional, default=0 : The mean value to be subtracted on the alpha channel std_r::float, optional, default=1 : Augmentation Param: Standard deviation on R channel. std_g::float, optional, default=1 : Augmentation Param: Standard deviation on G channel. std_b::float, optional, default=1 : Augmentation Param: Standard deviation on B channel. std_a::float, optional, default=1 : Augmentation Param: Standard deviation on Alpha channel. scale::float, optional, default=1 : Multiply the image with a scale value. max_random_contrast::float, optional, default=0 : Change the contrast with a value randomly chosen from $[-max_random_contrast, max_random_contrast]$ max_random_illumination::float, optional, default=0 : Change the illumination with a value randomly chosen from $[-max_random_illumination, max_random_illumination]$ Returns the constructed MXDataProvider . source # MXNet.mx.ImageRecordIter_v1 Method . ImageRecordIter_v1(path_imglist, path_imgrec, path_imgidx, aug_seq, label_width, data_shape, preprocess_threads, verbose, num_parts, part_index, device_id, shuffle_chunk_size, shuffle_chunk_seed, seed_aug, shuffle, seed, verbose, batch_size, round_batch, prefetch_buffer, ctx, dtype, resize, rand_crop, random_resized_crop, max_rotate_angle, max_aspect_ratio, min_aspect_ratio, max_shear_ratio, max_crop_size, min_crop_size, max_random_scale, min_random_scale, max_random_area, min_random_area, max_img_size, min_img_size, brightness, contrast, saturation, pca_noise, random_h, random_s, random_l, rotate, fill_value, data_shape, inter_method, pad, seed, mirror, rand_mirror, mean_img, mean_r, mean_g, mean_b, mean_a, std_r, std_g, std_b, std_a, scale, max_random_contrast, max_random_illumination, verbose) Iterating on image RecordIO files .. note:: $ImageRecordIter_v1$ is deprecated. Use $ImageRecordIter$ instead. Read images batches from RecordIO files with a rich of data augmentation options. One can use $tools/im2rec.py$ to pack individual image files into RecordIO files. Defined in src/io/iter image recordio.cc:L352 Arguments: data_name::Symbol : keyword argument, default :data . The name of the data. label_name::Symbol : keyword argument, default :softmax_label . The name of the label. Could be nothing if no label is presented in this dataset. path_imglist::string, optional, default='' : Path to the image list (.lst) file. Generally created with tools/im2rec.py. Format (Tab separated): . path_imgrec::string, optional, default='' : Path to the image RecordIO (.rec) file or a directory path. Created with tools/im2rec.py. path_imgidx::string, optional, default='' : Path to the image RecordIO index (.idx) file. Created with tools/im2rec.py. aug_seq::string, optional, default='aug_default' : The augmenter names to represent sequence of augmenters to be applied, seperated by comma. Additional keyword parameters will be seen by these augmenters. label_width::int, optional, default='1' : The number of labels per image. data_shape::Shape(tuple), required : The shape of one output image in (channels, height, width) format. preprocess_threads::int, optional, default='4' : The number of threads to do preprocessing. verbose::boolean, optional, default=1 : If or not output verbose information. num_parts::int, optional, default='1' : Virtually partition the data into these many parts. part_index::int, optional, default='0' : The i -th virtual partition to be read. device_id::int, optional, default='0' : The device id used to create context for internal NDArray. Setting device id to -1 will create Context::CPU(0). Setting device id to valid positive device id will create Context::CPUPinned(device_id). Default is 0. shuffle_chunk_size::long (non-negative), optional, default=0 : The data shuffle buffer size in MB. Only valid if shuffle is true. shuffle_chunk_seed::int, optional, default='0' : The random seed for shuffling seed_aug::int or None, optional, default='None' : Random seed for augmentations. shuffle::boolean, optional, default=0 : Whether to shuffle data randomly or not. seed::int, optional, default='0' : The random seed. batch_size::int (non-negative), required : Batch size. round_batch::boolean, optional, default=1 : Whether to use round robin to handle overflow batch or not. prefetch_buffer::long (non-negative), optional, default=4 : Maximum number of batches to prefetch. ctx::{'cpu', 'gpu'},optional, default='gpu' : Context data loader optimized for. dtype::{None, 'float16', 'float32', 'float64', 'int32', 'int64', 'int8', 'uint8'},optional, default='None' : Output data type. $None$ means no change. resize::int, optional, default='-1' : Down scale the shorter edge to a new size before applying other augmentations. rand_crop::boolean, optional, default=0 : If or not randomly crop the image random_resized_crop::boolean, optional, default=0 : If or not perform random resized cropping on the image, as a standard preprocessing for resnet training on ImageNet data. max_rotate_angle::int, optional, default='0' : Rotate by a random degree in $[-v, v]$ max_aspect_ratio::float, optional, default=0 : Change the aspect (namely width/height) to a random value. If min aspect ratio is None then the aspect ratio ins sampled from [1 - max aspect ratio, 1 + max aspect ratio], else it is in $[min_aspect_ratio, max_aspect_ratio]$ min_aspect_ratio::float or None, optional, default=None : Change the aspect (namely width/height) to a random value in $[min_aspect_ratio, max_aspect_ratio]$ max_shear_ratio::float, optional, default=0 : Apply a shear transformation (namely $(x,y)- (x+my,y)$) with $m$ randomly chose from $[-max_shear_ratio, max_shear_ratio]$ max_crop_size::int, optional, default='-1' : Crop both width and height into a random size in $[min_crop_size, max_crop_size].$Ignored if $random_resized_crop$ is True. min_crop_size::int, optional, default='-1' : Crop both width and height into a random size in $[min_crop_size, max_crop_size].$Ignored if $random_resized_crop$ is True. max_random_scale::float, optional, default=1 : Resize into $[width s, height s]$ with $s$ randomly chosen from $[min_random_scale, max_random_scale]$. Ignored if $random_resized_crop$ is True. min_random_scale::float, optional, default=1 : Resize into $[width s, height s]$ with $s$ randomly chosen from $[min_random_scale, max_random_scale]$Ignored if $random_resized_crop$ is True. max_random_area::float, optional, default=1 : Change the area (namely width * height) to a random value in $[min_random_area, max_random_area]$. Ignored if $random_resized_crop$ is False. min_random_area::float, optional, default=1 : Change the area (namely width * height) to a random value in $[min_random_area, max_random_area]$. Ignored if $random_resized_crop$ is False. max_img_size::float, optional, default=1e+10 : Set the maximal width and height after all resize and rotate argumentation are applied min_img_size::float, optional, default=0 : Set the minimal width and height after all resize and rotate argumentation are applied brightness::float, optional, default=0 : Add a random value in $[-brightness, brightness]$ to the brightness of image. contrast::float, optional, default=0 : Add a random value in $[-contrast, contrast]$ to the contrast of image. saturation::float, optional, default=0 : Add a random value in $[-saturation, saturation]$ to the saturation of image. pca_noise::float, optional, default=0 : Add PCA based noise to the image. random_h::int, optional, default='0' : Add a random value in $[-random_h, random_h]$ to the H channel in HSL color space. random_s::int, optional, default='0' : Add a random value in $[-random_s, random_s]$ to the S channel in HSL color space. random_l::int, optional, default='0' : Add a random value in $[-random_l, random_l]$ to the L channel in HSL color space. rotate::int, optional, default='-1' : Rotate by an angle. If set, it overwrites the $max_rotate_angle$ option. fill_value::int, optional, default='255' : Set the padding pixels value to $fill_value$. inter_method::int, optional, default='1' : The interpolation method: 0-NN 1-bilinear 2-cubic 3-area 4-lanczos4 9-auto 10-rand. pad::int, optional, default='0' : Change size from $[width, height]$ into $[pad + width + pad, pad + height + pad]$ by padding pixes mirror::boolean, optional, default=0 : Whether to mirror the image or not. If true, images are flipped along the horizontal axis. rand_mirror::boolean, optional, default=0 : Whether to randomly mirror images or not. If true, 50% of the images will be randomly mirrored (flipped along the horizontal axis) mean_img::string, optional, default='' : Filename of the mean image. mean_r::float, optional, default=0 : The mean value to be subtracted on the R channel mean_g::float, optional, default=0 : The mean value to be subtracted on the G channel mean_b::float, optional, default=0 : The mean value to be subtracted on the B channel mean_a::float, optional, default=0 : The mean value to be subtracted on the alpha channel std_r::float, optional, default=1 : Augmentation Param: Standard deviation on R channel. std_g::float, optional, default=1 : Augmentation Param: Standard deviation on G channel. std_b::float, optional, default=1 : Augmentation Param: Standard deviation on B channel. std_a::float, optional, default=1 : Augmentation Param: Standard deviation on Alpha channel. scale::float, optional, default=1 : Multiply the image with a scale value. max_random_contrast::float, optional, default=0 : Change the contrast with a value randomly chosen from $[-max_random_contrast, max_random_contrast]$ max_random_illumination::float, optional, default=0 : Change the illumination with a value randomly chosen from $[-max_random_illumination, max_random_illumination]$ Returns the constructed MXDataProvider . source # MXNet.mx.ImageRecordUInt8Iter Method . ImageRecordUInt8Iter(path_imglist, path_imgrec, path_imgidx, aug_seq, label_width, data_shape, preprocess_threads, verbose, num_parts, part_index, device_id, shuffle_chunk_size, shuffle_chunk_seed, seed_aug, shuffle, seed, verbose, batch_size, round_batch, prefetch_buffer, ctx, dtype, resize, rand_crop, random_resized_crop, max_rotate_angle, max_aspect_ratio, min_aspect_ratio, max_shear_ratio, max_crop_size, min_crop_size, max_random_scale, min_random_scale, max_random_area, min_random_area, max_img_size, min_img_size, brightness, contrast, saturation, pca_noise, random_h, random_s, random_l, rotate, fill_value, data_shape, inter_method, pad) Can also be called with the alias ImageRecordUInt8Provider . Iterating on image RecordIO files .. note:: ImageRecordUInt8Iter is deprecated. Use ImageRecordIter(dtype='uint8') instead. This iterator is identical to $ImageRecordIter$ except for using $uint8$ as the data type instead of $float$. Defined in src/io/iter image recordio_2.cc:L916 Arguments: data_name::Symbol : keyword argument, default :data . The name of the data. label_name::Symbol : keyword argument, default :softmax_label . The name of the label. Could be nothing if no label is presented in this dataset. path_imglist::string, optional, default='' : Path to the image list (.lst) file. Generally created with tools/im2rec.py. Format (Tab separated): . path_imgrec::string, optional, default='' : Path to the image RecordIO (.rec) file or a directory path. Created with tools/im2rec.py. path_imgidx::string, optional, default='' : Path to the image RecordIO index (.idx) file. Created with tools/im2rec.py. aug_seq::string, optional, default='aug_default' : The augmenter names to represent sequence of augmenters to be applied, seperated by comma. Additional keyword parameters will be seen by these augmenters. label_width::int, optional, default='1' : The number of labels per image. data_shape::Shape(tuple), required : The shape of one output image in (channels, height, width) format. preprocess_threads::int, optional, default='4' : The number of threads to do preprocessing. verbose::boolean, optional, default=1 : If or not output verbose information. num_parts::int, optional, default='1' : Virtually partition the data into these many parts. part_index::int, optional, default='0' : The i -th virtual partition to be read. device_id::int, optional, default='0' : The device id used to create context for internal NDArray. Setting device id to -1 will create Context::CPU(0). Setting device id to valid positive device id will create Context::CPUPinned(device_id). Default is 0. shuffle_chunk_size::long (non-negative), optional, default=0 : The data shuffle buffer size in MB. Only valid if shuffle is true. shuffle_chunk_seed::int, optional, default='0' : The random seed for shuffling seed_aug::int or None, optional, default='None' : Random seed for augmentations. shuffle::boolean, optional, default=0 : Whether to shuffle data randomly or not. seed::int, optional, default='0' : The random seed. batch_size::int (non-negative), required : Batch size. round_batch::boolean, optional, default=1 : Whether to use round robin to handle overflow batch or not. prefetch_buffer::long (non-negative), optional, default=4 : Maximum number of batches to prefetch. ctx::{'cpu', 'gpu'},optional, default='gpu' : Context data loader optimized for. dtype::{None, 'float16', 'float32', 'float64', 'int32', 'int64', 'int8', 'uint8'},optional, default='None' : Output data type. $None$ means no change. resize::int, optional, default='-1' : Down scale the shorter edge to a new size before applying other augmentations. rand_crop::boolean, optional, default=0 : If or not randomly crop the image random_resized_crop::boolean, optional, default=0 : If or not perform random resized cropping on the image, as a standard preprocessing for resnet training on ImageNet data. max_rotate_angle::int, optional, default='0' : Rotate by a random degree in $[-v, v]$ max_aspect_ratio::float, optional, default=0 : Change the aspect (namely width/height) to a random value. If min aspect ratio is None then the aspect ratio ins sampled from [1 - max aspect ratio, 1 + max aspect ratio], else it is in $[min_aspect_ratio, max_aspect_ratio]$ min_aspect_ratio::float or None, optional, default=None : Change the aspect (namely width/height) to a random value in $[min_aspect_ratio, max_aspect_ratio]$ max_shear_ratio::float, optional, default=0 : Apply a shear transformation (namely $(x,y)- (x+my,y)$) with $m$ randomly chose from $[-max_shear_ratio, max_shear_ratio]$ max_crop_size::int, optional, default='-1' : Crop both width and height into a random size in $[min_crop_size, max_crop_size].$Ignored if $random_resized_crop$ is True. min_crop_size::int, optional, default='-1' : Crop both width and height into a random size in $[min_crop_size, max_crop_size].$Ignored if $random_resized_crop$ is True. max_random_scale::float, optional, default=1 : Resize into $[width s, height s]$ with $s$ randomly chosen from $[min_random_scale, max_random_scale]$. Ignored if $random_resized_crop$ is True. min_random_scale::float, optional, default=1 : Resize into $[width s, height s]$ with $s$ randomly chosen from $[min_random_scale, max_random_scale]$Ignored if $random_resized_crop$ is True. max_random_area::float, optional, default=1 : Change the area (namely width * height) to a random value in $[min_random_area, max_random_area]$. Ignored if $random_resized_crop$ is False. min_random_area::float, optional, default=1 : Change the area (namely width * height) to a random value in $[min_random_area, max_random_area]$. Ignored if $random_resized_crop$ is False. max_img_size::float, optional, default=1e+10 : Set the maximal width and height after all resize and rotate argumentation are applied min_img_size::float, optional, default=0 : Set the minimal width and height after all resize and rotate argumentation are applied brightness::float, optional, default=0 : Add a random value in $[-brightness, brightness]$ to the brightness of image. contrast::float, optional, default=0 : Add a random value in $[-contrast, contrast]$ to the contrast of image. saturation::float, optional, default=0 : Add a random value in $[-saturation, saturation]$ to the saturation of image. pca_noise::float, optional, default=0 : Add PCA based noise to the image. random_h::int, optional, default='0' : Add a random value in $[-random_h, random_h]$ to the H channel in HSL color space. random_s::int, optional, default='0' : Add a random value in $[-random_s, random_s]$ to the S channel in HSL color space. random_l::int, optional, default='0' : Add a random value in $[-random_l, random_l]$ to the L channel in HSL color space. rotate::int, optional, default='-1' : Rotate by an angle. If set, it overwrites the $max_rotate_angle$ option. fill_value::int, optional, default='255' : Set the padding pixels value to $fill_value$. inter_method::int, optional, default='1' : The interpolation method: 0-NN 1-bilinear 2-cubic 3-area 4-lanczos4 9-auto 10-rand. pad::int, optional, default='0' : Change size from $[width, height]$ into $[pad + width + pad, pad + height + pad]$ by padding pixes Returns the constructed MXDataProvider . source # MXNet.mx.ImageRecordUInt8Iter_v1 Method . ImageRecordUInt8Iter_v1(path_imglist, path_imgrec, path_imgidx, aug_seq, label_width, data_shape, preprocess_threads, verbose, num_parts, part_index, device_id, shuffle_chunk_size, shuffle_chunk_seed, seed_aug, shuffle, seed, verbose, batch_size, round_batch, prefetch_buffer, ctx, dtype, resize, rand_crop, random_resized_crop, max_rotate_angle, max_aspect_ratio, min_aspect_ratio, max_shear_ratio, max_crop_size, min_crop_size, max_random_scale, min_random_scale, max_random_area, min_random_area, max_img_size, min_img_size, brightness, contrast, saturation, pca_noise, random_h, random_s, random_l, rotate, fill_value, data_shape, inter_method, pad) Iterating on image RecordIO files .. note:: $ImageRecordUInt8Iter_v1$ is deprecated. Use $ImageRecordUInt8Iter$ instead. This iterator is identical to $ImageRecordIter$ except for using $uint8$ as the data type instead of $float$. Defined in src/io/iter image recordio.cc:L377 Arguments: data_name::Symbol : keyword argument, default :data . The name of the data. label_name::Symbol : keyword argument, default :softmax_label . The name of the label. Could be nothing if no label is presented in this dataset. path_imglist::string, optional, default='' : Path to the image list (.lst) file. Generally created with tools/im2rec.py. Format (Tab separated): . path_imgrec::string, optional, default='' : Path to the image RecordIO (.rec) file or a directory path. Created with tools/im2rec.py. path_imgidx::string, optional, default='' : Path to the image RecordIO index (.idx) file. Created with tools/im2rec.py. aug_seq::string, optional, default='aug_default' : The augmenter names to represent sequence of augmenters to be applied, seperated by comma. Additional keyword parameters will be seen by these augmenters. label_width::int, optional, default='1' : The number of labels per image. data_shape::Shape(tuple), required : The shape of one output image in (channels, height, width) format. preprocess_threads::int, optional, default='4' : The number of threads to do preprocessing. verbose::boolean, optional, default=1 : If or not output verbose information. num_parts::int, optional, default='1' : Virtually partition the data into these many parts. part_index::int, optional, default='0' : The i -th virtual partition to be read. device_id::int, optional, default='0' : The device id used to create context for internal NDArray. Setting device id to -1 will create Context::CPU(0). Setting device id to valid positive device id will create Context::CPUPinned(device_id). Default is 0. shuffle_chunk_size::long (non-negative), optional, default=0 : The data shuffle buffer size in MB. Only valid if shuffle is true. shuffle_chunk_seed::int, optional, default='0' : The random seed for shuffling seed_aug::int or None, optional, default='None' : Random seed for augmentations. shuffle::boolean, optional, default=0 : Whether to shuffle data randomly or not. seed::int, optional, default='0' : The random seed. batch_size::int (non-negative), required : Batch size. round_batch::boolean, optional, default=1 : Whether to use round robin to handle overflow batch or not. prefetch_buffer::long (non-negative), optional, default=4 : Maximum number of batches to prefetch. ctx::{'cpu', 'gpu'},optional, default='gpu' : Context data loader optimized for. dtype::{None, 'float16', 'float32', 'float64', 'int32', 'int64', 'int8', 'uint8'},optional, default='None' : Output data type. $None$ means no change. resize::int, optional, default='-1' : Down scale the shorter edge to a new size before applying other augmentations. rand_crop::boolean, optional, default=0 : If or not randomly crop the image random_resized_crop::boolean, optional, default=0 : If or not perform random resized cropping on the image, as a standard preprocessing for resnet training on ImageNet data. max_rotate_angle::int, optional, default='0' : Rotate by a random degree in $[-v, v]$ max_aspect_ratio::float, optional, default=0 : Change the aspect (namely width/height) to a random value. If min aspect ratio is None then the aspect ratio ins sampled from [1 - max aspect ratio, 1 + max aspect ratio], else it is in $[min_aspect_ratio, max_aspect_ratio]$ min_aspect_ratio::float or None, optional, default=None : Change the aspect (namely width/height) to a random value in $[min_aspect_ratio, max_aspect_ratio]$ max_shear_ratio::float, optional, default=0 : Apply a shear transformation (namely $(x,y)- (x+my,y)$) with $m$ randomly chose from $[-max_shear_ratio, max_shear_ratio]$ max_crop_size::int, optional, default='-1' : Crop both width and height into a random size in $[min_crop_size, max_crop_size].$Ignored if $random_resized_crop$ is True. min_crop_size::int, optional, default='-1' : Crop both width and height into a random size in $[min_crop_size, max_crop_size].$Ignored if $random_resized_crop$ is True. max_random_scale::float, optional, default=1 : Resize into $[width s, height s]$ with $s$ randomly chosen from $[min_random_scale, max_random_scale]$. Ignored if $random_resized_crop$ is True. min_random_scale::float, optional, default=1 : Resize into $[width s, height s]$ with $s$ randomly chosen from $[min_random_scale, max_random_scale]$Ignored if $random_resized_crop$ is True. max_random_area::float, optional, default=1 : Change the area (namely width * height) to a random value in $[min_random_area, max_random_area]$. Ignored if $random_resized_crop$ is False. min_random_area::float, optional, default=1 : Change the area (namely width * height) to a random value in $[min_random_area, max_random_area]$. Ignored if $random_resized_crop$ is False. max_img_size::float, optional, default=1e+10 : Set the maximal width and height after all resize and rotate argumentation are applied min_img_size::float, optional, default=0 : Set the minimal width and height after all resize and rotate argumentation are applied brightness::float, optional, default=0 : Add a random value in $[-brightness, brightness]$ to the brightness of image. contrast::float, optional, default=0 : Add a random value in $[-contrast, contrast]$ to the contrast of image. saturation::float, optional, default=0 : Add a random value in $[-saturation, saturation]$ to the saturation of image. pca_noise::float, optional, default=0 : Add PCA based noise to the image. random_h::int, optional, default='0' : Add a random value in $[-random_h, random_h]$ to the H channel in HSL color space. random_s::int, optional, default='0' : Add a random value in $[-random_s, random_s]$ to the S channel in HSL color space. random_l::int, optional, default='0' : Add a random value in $[-random_l, random_l]$ to the L channel in HSL color space. rotate::int, optional, default='-1' : Rotate by an angle. If set, it overwrites the $max_rotate_angle$ option. fill_value::int, optional, default='255' : Set the padding pixels value to $fill_value$. inter_method::int, optional, default='1' : The interpolation method: 0-NN 1-bilinear 2-cubic 3-area 4-lanczos4 9-auto 10-rand. pad::int, optional, default='0' : Change size from $[width, height]$ into $[pad + width + pad, pad + height + pad]$ by padding pixes Returns the constructed MXDataProvider . source # MXNet.mx.LibSVMIter Method . LibSVMIter(data_libsvm, data_shape, label_libsvm, label_shape, num_parts, part_index, batch_size, round_batch, prefetch_buffer, ctx, dtype) Can also be called with the alias LibSVMProvider . Returns the LibSVM iterator which returns data with csr storage type. This iterator is experimental and should be used with care. The input data is stored in a format similar to LibSVM file format, except that the indices are expected to be zero-based instead of one-based, and the column indices for each row are expected to be sorted in ascending order . Details of the LibSVM format are available here. https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/ _ The data_shape parameter is used to set the shape of each line of the data. The dimension of both data_shape and label_shape are expected to be 1. The data_libsvm parameter is used to set the path input LibSVM file. When it is set to a directory, all the files in the directory will be read. When label_libsvm is set to $NULL$, both data and label are read from the file specified by data_libsvm . In this case, the data is stored in csr storage type, while the label is a 1D dense array. The LibSVMIter only support round_batch parameter set to $True$. Therefore, if batch_size is 3 and there are 4 total rows in libsvm file, 2 more examples are consumed at the first round. When num_parts and part_index are provided, the data is split into num_parts partitions, and the iterator only reads the part_index -th partition. However, the partitions are not guaranteed to be even. $reset()$ is expected to be called only after a complete pass of data. Example:: Contents of libsvm file $data.t$. 1.0 0:0.5 2:1.2 -2.0 -3.0 0:0.6 1:2.4 2:1.2 4 2:-1.2 Creates a LibSVMIter with batch_size =3. data iter = mx.io.LibSVMIter(data libsvm = 'data.t', data shape = (3,), batch size = 3) The data of the first batch is stored in csr storage type batch = data_iter.next() csr = batch.data[0] csr.asnumpy() [[ 0.5 0. 1.2 ] [ 0. 0. 0. ] [ 0.6 2.4 1.2]] The label of first batch label = batch.label[0] label [ 1. -2. -3.] second batch = data iter.next() The data of the second batch second_batch.data[0].asnumpy() [[ 0. 0. -1.2 ] [ 0.5 0. 1.2 ] [ 0. 0. 0. ]] The label of the second batch second_batch.label[0].asnumpy() [ 4. 1. -2.] data_iter.reset() To restart the iterator for the second pass of the data When label_libsvm is set to the path to another LibSVM file, data is read from data_libsvm and label from label_libsvm . In this case, both data and label are stored in the csr format. If the label column in the data_libsvm file is ignored. Example:: Contents of libsvm file $label.t$ 1.0 -2.0 0:0.125 -3.0 2:1.2 4 1:1.0 2:-1.2 Creates a LibSVMIter with specified label file data iter = mx.io.LibSVMIter(data libsvm = 'data.t', data_shape = (3,), label_libsvm = 'label.t', label_shape = (3,), batch_size = 3) Both data and label are in csr storage type batch = data iter.next() csr data = batch.data[0] csr_data.asnumpy() [[ 0.5 0. 1.2 ] [ 0. 0. 0. ] [ 0.6 2.4 1.2 ]] csr_label = batch.label[0] csr_label.asnumpy() [[ 0. 0. 0. ] [ 0.125 0. 0. ] [ 0. 0. 1.2 ]] Defined in src/io/iter_libsvm.cc:L298 Arguments: data_name::Symbol : keyword argument, default :data . The name of the data. label_name::Symbol : keyword argument, default :softmax_label . The name of the label. Could be nothing if no label is presented in this dataset. data_libsvm::string, required : The input zero-base indexed LibSVM data file or a directory path. data_shape::Shape(tuple), required : The shape of one example. label_libsvm::string, optional, default='NULL' : The input LibSVM label file or a directory path. If NULL, all labels will be read from $data_libsvm$. label_shape::Shape(tuple), optional, default=[1] : The shape of one label. num_parts::int, optional, default='1' : partition the data into multiple parts part_index::int, optional, default='0' : the index of the part will read batch_size::int (non-negative), required : Batch size. round_batch::boolean, optional, default=1 : Whether to use round robin to handle overflow batch or not. prefetch_buffer::long (non-negative), optional, default=4 : Maximum number of batches to prefetch. ctx::{'cpu', 'gpu'},optional, default='gpu' : Context data loader optimized for. dtype::{None, 'float16', 'float32', 'float64', 'int32', 'int64', 'int8', 'uint8'},optional, default='None' : Output data type. $None$ means no change. Returns the constructed MXDataProvider . source # MXNet.mx.MNISTIter Method . MNISTIter(image, label, batch_size, shuffle, flat, seed, silent, num_parts, part_index, prefetch_buffer, ctx, dtype) Can also be called with the alias MNISTProvider . Iterating on the MNIST dataset. One can download the dataset from http://yann.lecun.com/exdb/mnist/ Defined in src/io/iter_mnist.cc:L265 Arguments: data_name::Symbol : keyword argument, default :data . The name of the data. label_name::Symbol : keyword argument, default :softmax_label . The name of the label. Could be nothing if no label is presented in this dataset. image::string, optional, default='./train-images-idx3-ubyte' : Dataset Param: Mnist image path. label::string, optional, default='./train-labels-idx1-ubyte' : Dataset Param: Mnist label path. batch_size::int, optional, default='128' : Batch Param: Batch Size. shuffle::boolean, optional, default=1 : Augmentation Param: Whether to shuffle data. flat::boolean, optional, default=0 : Augmentation Param: Whether to flat the data into 1D. seed::int, optional, default='0' : Augmentation Param: Random Seed. silent::boolean, optional, default=0 : Auxiliary Param: Whether to print out data info. num_parts::int, optional, default='1' : partition the data into multiple parts part_index::int, optional, default='0' : the index of the part will read prefetch_buffer::long (non-negative), optional, default=4 : Maximum number of batches to prefetch. ctx::{'cpu', 'gpu'},optional, default='gpu' : Context data loader optimized for. dtype::{None, 'float16', 'float32', 'float64', 'int32', 'int64', 'int8', 'uint8'},optional, default='None' : Output data type. $None$ means no change. Returns the constructed MXDataProvider . source # MXNet.mx.eachbatch Method . eachbatch(provider::AbstractDataProvider) Allows you to perform operations on data every epoch. This is especially useful when you need to perform real-time augmentation of the data. Arguments: provider : an instance of the custom DataProvider type. You must return this instance after modifying its fields. source # MXNet.mx.from_json Method . from_json(repr :: AbstractString, ::Type{SymbolicNode}) Load a SymbolicNode from a JSON string representation. source # MXNet.mx.is_shared Method . is_shared(j_arr, arr) Test whether j_arr is sharing data with arr . Arguments: j_arr::Array : the Julia Array. arr::NDArray : the NDArray . source # MXNet.mx.load Method . load(filename, ::Type{NDArray}) Load NDArrays from binary file. Arguments: filename::String : the path of the file to load. It could be S3 or HDFS address. Returns either Dict{Symbol, NDArray} or Vector{NDArray} . filename can point to s3 or hdfs resources if the libmxnet is built with the corresponding components enabled. Examples: s3://my-bucket/path/my-s3-ndarray hdfs://my-bucket/path/my-hdfs-ndarray /path-to/my-local-ndarray source # MXNet.mx.load Method . load(filename :: AbstractString, ::Type{SymbolicNode}) Load a SymbolicNode from a JSON file. source # MXNet.mx.load_data! Method . load_data!(provider, batch, targets) Arguments: provider::AbstractDataProvider : the data provider. batch::AbstractDataBatch : the data batch object. targets::Vector{Vector{SlicedNDArray}} : the targets to load data into. The targets is a list of the same length as number of data provided by this provider. Each element in the list is a list of SlicedNDArray . This list described a spliting scheme of this data batch into different slices, each slice is specified by a slice-ndarray pair, where slice specify the range of samples in the mini-batch that should be loaded into the corresponding ndarray . This utility function is used in data parallelization, where a mini-batch is splited and computed on several different devices. source # MXNet.mx.load_label! Method . load_label!(provider, batch, targets) provider::AbstractDataProvider provider : the data provider. batch::AbstractDataBatch batch : the data batch object. targets::Vector{Vector{SlicedNDArray}} : the targets to load label into. The same as load_data! , except that this is for loading labels. source # MXNet.mx.save Method . save(filename :: AbstractString, node :: SymbolicNode) Save a SymbolicNode to a JSON file. source # MXNet.mx.save Method . save(filename::AbstractString, data) Save NDarrays to binary file. Filename could be S3 or HDFS address, if libmxnet is built with corresponding support (see load ). filename::String : path to the binary file to write to. data : data to save to file. Data can be a NDArray , a Vector of NDArray , or a Dict{Symbol} contains NDArray s. source # MXNet.mx.to_json Method . to_json(s::SymbolicNode) Convert a SymbolicNode into a JSON string. source # MXNet.mx.try_get_shared Method . try_get_shared(arr; sync=:nop) Try to create a Julia array by sharing the data with the underlying NDArray . Arguments: arr::NDArray : the array to be shared. Note The returned array does not guarantee to share data with the underlying NDArray . In particular, data sharing is possible only when the NDArray lives on CPU. sync::Symbol : :nop , :write , :read On CPU, invoke _wait_to_read if :read ; invoke _wait_to_write if :write . source","title":"Implemented providers and other methods"},{"location":"api/kvstore/","text":"Key-Value Store # MXNet.mx.KVStore Type . KVStore(kv_type = :local) For single machine training, there are two commonly used types: local : Copies all gradients to CPU memory and updates weights there. device : Aggregates gradients and updates weights on GPU(s). With this setting, the KVStore also attempts to use GPU peer-to-peer communication, potentially accelerating the communication. For distributed training, KVStore also supports a number of types: dist_sync : Behaves similarly to local but with one major difference. With dist_sync , batch-size now means the batch size used on each machine. So if there are n machines and we use batch size $b$, then dist_sync behaves like local with batch size n * b . dist_device_sync : Identical to dist_sync with the difference similar to device vs local . dist_async : Performs asynchronous updates. The weights are updated whenever gradients are received from any machine. No two updates happen on the same weight at the same time. However, the order is not guaranteed. source # MXNet.mx.barrier Method . barrier(kv::KVStore) Invokes global barrier among all worker nodes. For example, assume there are n machines. We would like machine 0 to first init the values and then have all the workers pull the initialized value. Before pulling, we can place invoke barrier(kv) to guarantee that the initialization is finished. source # MXNet.mx.init! Method . init!(kv::KVStore, key::Int, val::NDArray) init!(kv::KVStore, keys, vals) Initializes a single or a sequence of key-value pairs into the store. For each key, one must init! it before calling push! or pull! . When multiple workers invoke init! for the same key, only the value supplied by worker with rank 0 is used. This function returns after data has been initialized successfully. julia kv = KVStore(:local) mx.KVStore @ local julia init!(kv, 42, mx.rand(2, 3)) source # MXNet.mx.pull! Method . Pulls a single value or a sequence of values from the store. This function returns immediately after adding an operator to the engine. Subsequent attempts to read from the out variable will be blocked until the pull operation completes. pull is executed asynchronously after all previous pull calls and only the last push call for the same input key(s) are finished. The returned values are guaranteed to be the latest values in the store. See pull! for more examples. source # MXNet.mx.setoptimizer! Method . setoptimizer!(kv::KVStore, opt) Registers an optimizer with the kvstore. When using a single machine, this function updates the local optimizer. If using multiple machines and this operation is invoked from a worker node, it will serialized the optimizer with pickle and send it to all servers. The function returns after all servers have been updated. julia kv = KVStore() mx.KVStore @ local julia W = mx.zeros(2, 3) # 2\u00d73 weight matrix 2\u00d73 mx.NDArray{Float32,2} @ CPU0: 0.0 0.0 0.0 0.0 0.0 0.0 julia init!(kv, 42, W) julia setoptimizer!(kv, SGD(\u03b7 = .2)) # SGD with .2 as learning rate julia \u2207W = mx.ones(2, 3) # assume it's the gradient 2\u00d73 mx.NDArray{Float32,2} @ CPU0: 1.0 1.0 1.0 1.0 1.0 1.0 julia push!(kv, 42, \u2207W) julia pull!(kv, 42, W) # fetch weight and write back to `W` julia W 2\u00d73 mx.NDArray{Float32,2} @ CPU0: -0.2 -0.2 -0.2 -0.2 -0.2 -0.2 source # MXNet.mx.setupdater! Method . setupdater!(kv, updater) Sets a push! updater into the store. This function only changes the local store. When running on multiple machines one must use set_optimizer . julia update(key, val, orig) = mx.@inplace orig += val .* .2 update (generic function with 1 method) julia kv = KVStore(:local) mx.KVStore @ local julia mx.setupdater!(kv, update) julia init!(kv, 42, mx.ones(2, 3)) julia push!(kv, 42, mx.ones(2, 3)) julia x = NDArray(undef, 2, 3); julia pull!(kv, 42, x) julia x 2\u00d73 mx.NDArray{Float32,2} @ CPU0: 1.2 1.2 1.2 1.2 1.2 1.2 source # Base.push! Method . push!(kv::KVStore, key, val; priority = 0) push!(kv::KVStore, key, vals; priority = 0) push!(kv::KVStore, keys, vals; priority = 0) Pushes a single or a sequence of key-value pairs into the store. This function returns immediately after adding an operator to the engine. The actual operation is executed asynchronously. If there are consecutive pushes to the same key, there is no guarantee on the serialization of pushes. The execution of a push does not guarantee that all previous pushes are finished. There is no synchronization between workers by default. One can use $barrier()$ to sync all workers. push! and pull! single NDArray : julia kv = KVStore(:local) mx.KVStore @ local julia x = NDArray(undef, 2, 3); julia init!(kv, 3, x) julia push!(kv, 3, mx.ones(2, 3) * 8) julia pull!(kv, 3, x) julia x 2\u00d73 mx.NDArray{Float32,2} @ CPU0: 8.0 8.0 8.0 8.0 8.0 8.0 Aggregate values and push! : julia vals = [mx.ones((2, 3), gpu(0)) * 3, mx.ones((2, 3), gpu(1)) * 4]; julia push!(kv, 3, vals) julia pull!(kv, 3, x) julia x 2\u00d73 mx.NDArray{Float32,2} @ CPU0: 7.0 7.0 7.0 7.0 7.0 7.0 push! a list of key to single device: julia keys = [4, 5]; julia init!(kv, keys, [NDArray(undef, 2, 3), NDArray(undef, 2, 3)]) julia push!(kv, keys, [x, x]) julia y, z = NDArray(undef, 2, 3), NDArray(undef, 2, 3); julia pull!(kv, keys, [y, z]) source","title":"Kvstore"},{"location":"api/kvstore/#key-value-store","text":"# MXNet.mx.KVStore Type . KVStore(kv_type = :local) For single machine training, there are two commonly used types: local : Copies all gradients to CPU memory and updates weights there. device : Aggregates gradients and updates weights on GPU(s). With this setting, the KVStore also attempts to use GPU peer-to-peer communication, potentially accelerating the communication. For distributed training, KVStore also supports a number of types: dist_sync : Behaves similarly to local but with one major difference. With dist_sync , batch-size now means the batch size used on each machine. So if there are n machines and we use batch size $b$, then dist_sync behaves like local with batch size n * b . dist_device_sync : Identical to dist_sync with the difference similar to device vs local . dist_async : Performs asynchronous updates. The weights are updated whenever gradients are received from any machine. No two updates happen on the same weight at the same time. However, the order is not guaranteed. source # MXNet.mx.barrier Method . barrier(kv::KVStore) Invokes global barrier among all worker nodes. For example, assume there are n machines. We would like machine 0 to first init the values and then have all the workers pull the initialized value. Before pulling, we can place invoke barrier(kv) to guarantee that the initialization is finished. source # MXNet.mx.init! Method . init!(kv::KVStore, key::Int, val::NDArray) init!(kv::KVStore, keys, vals) Initializes a single or a sequence of key-value pairs into the store. For each key, one must init! it before calling push! or pull! . When multiple workers invoke init! for the same key, only the value supplied by worker with rank 0 is used. This function returns after data has been initialized successfully. julia kv = KVStore(:local) mx.KVStore @ local julia init!(kv, 42, mx.rand(2, 3)) source # MXNet.mx.pull! Method . Pulls a single value or a sequence of values from the store. This function returns immediately after adding an operator to the engine. Subsequent attempts to read from the out variable will be blocked until the pull operation completes. pull is executed asynchronously after all previous pull calls and only the last push call for the same input key(s) are finished. The returned values are guaranteed to be the latest values in the store. See pull! for more examples. source # MXNet.mx.setoptimizer! Method . setoptimizer!(kv::KVStore, opt) Registers an optimizer with the kvstore. When using a single machine, this function updates the local optimizer. If using multiple machines and this operation is invoked from a worker node, it will serialized the optimizer with pickle and send it to all servers. The function returns after all servers have been updated. julia kv = KVStore() mx.KVStore @ local julia W = mx.zeros(2, 3) # 2\u00d73 weight matrix 2\u00d73 mx.NDArray{Float32,2} @ CPU0: 0.0 0.0 0.0 0.0 0.0 0.0 julia init!(kv, 42, W) julia setoptimizer!(kv, SGD(\u03b7 = .2)) # SGD with .2 as learning rate julia \u2207W = mx.ones(2, 3) # assume it's the gradient 2\u00d73 mx.NDArray{Float32,2} @ CPU0: 1.0 1.0 1.0 1.0 1.0 1.0 julia push!(kv, 42, \u2207W) julia pull!(kv, 42, W) # fetch weight and write back to `W` julia W 2\u00d73 mx.NDArray{Float32,2} @ CPU0: -0.2 -0.2 -0.2 -0.2 -0.2 -0.2 source # MXNet.mx.setupdater! Method . setupdater!(kv, updater) Sets a push! updater into the store. This function only changes the local store. When running on multiple machines one must use set_optimizer . julia update(key, val, orig) = mx.@inplace orig += val .* .2 update (generic function with 1 method) julia kv = KVStore(:local) mx.KVStore @ local julia mx.setupdater!(kv, update) julia init!(kv, 42, mx.ones(2, 3)) julia push!(kv, 42, mx.ones(2, 3)) julia x = NDArray(undef, 2, 3); julia pull!(kv, 42, x) julia x 2\u00d73 mx.NDArray{Float32,2} @ CPU0: 1.2 1.2 1.2 1.2 1.2 1.2 source # Base.push! Method . push!(kv::KVStore, key, val; priority = 0) push!(kv::KVStore, key, vals; priority = 0) push!(kv::KVStore, keys, vals; priority = 0) Pushes a single or a sequence of key-value pairs into the store. This function returns immediately after adding an operator to the engine. The actual operation is executed asynchronously. If there are consecutive pushes to the same key, there is no guarantee on the serialization of pushes. The execution of a push does not guarantee that all previous pushes are finished. There is no synchronization between workers by default. One can use $barrier()$ to sync all workers. push! and pull! single NDArray : julia kv = KVStore(:local) mx.KVStore @ local julia x = NDArray(undef, 2, 3); julia init!(kv, 3, x) julia push!(kv, 3, mx.ones(2, 3) * 8) julia pull!(kv, 3, x) julia x 2\u00d73 mx.NDArray{Float32,2} @ CPU0: 8.0 8.0 8.0 8.0 8.0 8.0 Aggregate values and push! : julia vals = [mx.ones((2, 3), gpu(0)) * 3, mx.ones((2, 3), gpu(1)) * 4]; julia push!(kv, 3, vals) julia pull!(kv, 3, x) julia x 2\u00d73 mx.NDArray{Float32,2} @ CPU0: 7.0 7.0 7.0 7.0 7.0 7.0 push! a list of key to single device: julia keys = [4, 5]; julia init!(kv, keys, [NDArray(undef, 2, 3), NDArray(undef, 2, 3)]) julia push!(kv, keys, [x, x]) julia y, z = NDArray(undef, 2, 3), NDArray(undef, 2, 3); julia pull!(kv, keys, [y, z]) source","title":"Key-Value Store"},{"location":"api/metric/","text":"Evaluation Metrics Evaluation metrics provide a way to evaluate the performance of a learned model. This is typically used during training to monitor performance on the validation set. # MXNet.mx.ACE Type . ACE Calculates the averaged cross-entropy (logloss) for classification. Arguments: eps::Float64 : Prevents returning Inf if p = 0 . source # MXNet.mx.AbstractEvalMetric Type . AbstractEvalMetric The base class for all evaluation metrics. The sub-types should implement the following interfaces: update! reset! get source # MXNet.mx.Accuracy Type . Accuracy Multiclass classification accuracy. Calculates the mean accuracy per sample for softmax in one dimension. For a multi-dimensional softmax the mean accuracy over all dimensions is calculated. source # MXNet.mx.MSE Type . MSE Mean Squared Error. Calculates the mean squared error regression loss. Requires that label and prediction have the same shape. source # MXNet.mx.MultiACE Type . MultiACE Calculates the averaged cross-entropy per class and overall (see ACE ). This can be used to quantify the influence of different classes on the overall loss. source # MXNet.mx.MultiMetric Type . MultiMetric(metrics::Vector{AbstractEvalMetric}) Combine multiple metrics in one and get a result for all of them. Usage To calculate both mean-squared error Accuracy and log-loss ACE : mx.fit(..., eval_metric = mx.MultiMetric([mx.Accuracy(), mx.ACE()])) source # MXNet.mx.NMSE Type . NMSE Normalized Mean Squared Error \\sum_i (\\frac{label_i - pred_i}{label_i})^2 Note that there are various ways to do the normalization . It depends on your own context. Please judge the problem setting you have first. If the current implementation do not suitable for you, feel free to file it on GitHub. Let me show you a use case of this kind of normalization: Bob is training a network for option pricing. The option pricing problem is a regression problem (pirce predicting). There are lots of option contracts on same target stock but different strike price. For example, there is a stock S ; it's market price is 1000. And, there are two call option contracts with different strike price. Assume Bob obtains the outcome as following table: +--------+----------------+----------------+--------------+ | | Strike Price | Market Price | Pred Price | +--------+----------------+----------------+--------------+ | Op 1 | 1500 | 100 | 80 | +--------+----------------+----------------+--------------+ | Op 2 | 500 | 10 | 8 | +--------+----------------+----------------+--------------+ Now, obviously, Bob will calculate the normalized MSE as: (\\frac{100 - 80}{100})^2 \\text{ vs } (\\frac{10 - 8}{10}) ^2 Both of the pred prices got the same degree of error. For more discussion about normalized MSE, please see #211 also. source # MXNet.mx.SeqMetric Type . SeqMetric(metrics::Vector{AbstractEvalMetric}) Apply a different metric to each output. This is especially useful for mx.Group . Usage Calculate accuracy Accuracy for the first output and log-loss ACE for the second output: mx.fit(..., eval_metric = mx.SeqMetric([mx.Accuracy(), mx.ACE()])) source # MXNet.mx.update! Method . update!(metric, labels, preds) Update and accumulate metrics. Arguments: metric::AbstractEvalMetric : the metric object. labels::Vector{NDArray} : the labels from the data provider. preds::Vector{NDArray} : the outputs (predictions) of the network. source # MXNet.mx.NullMetric Type . NullMetric() A metric that calculates nothing. Can be used to ignore an output during training. source # Base.get Method . get(metric) Get the accumulated metrics. Returns Vector{Tuple{Base.Symbol, Real}} , a list of name-value pairs. For example, [(:accuracy, 0.9)] . source # MXNet.mx.hasNDArraySupport Method . hasNDArraySupport(metric) - Val{true/false} Trait for _update_single_output should return Val{true}() if metric can handle NDArray directly and Val{false}() if requires Array`. Metric that work with NDArrays can be async, while native Julia arrays require that we copy the output of the network, which is a blocking operation. source # MXNet.mx.reset! Method . reset!(metric) Reset the accumulation counter. source","title":"Evaluation Metrics"},{"location":"api/metric/#evaluation-metrics","text":"Evaluation metrics provide a way to evaluate the performance of a learned model. This is typically used during training to monitor performance on the validation set. # MXNet.mx.ACE Type . ACE Calculates the averaged cross-entropy (logloss) for classification. Arguments: eps::Float64 : Prevents returning Inf if p = 0 . source # MXNet.mx.AbstractEvalMetric Type . AbstractEvalMetric The base class for all evaluation metrics. The sub-types should implement the following interfaces: update! reset! get source # MXNet.mx.Accuracy Type . Accuracy Multiclass classification accuracy. Calculates the mean accuracy per sample for softmax in one dimension. For a multi-dimensional softmax the mean accuracy over all dimensions is calculated. source # MXNet.mx.MSE Type . MSE Mean Squared Error. Calculates the mean squared error regression loss. Requires that label and prediction have the same shape. source # MXNet.mx.MultiACE Type . MultiACE Calculates the averaged cross-entropy per class and overall (see ACE ). This can be used to quantify the influence of different classes on the overall loss. source # MXNet.mx.MultiMetric Type . MultiMetric(metrics::Vector{AbstractEvalMetric}) Combine multiple metrics in one and get a result for all of them. Usage To calculate both mean-squared error Accuracy and log-loss ACE : mx.fit(..., eval_metric = mx.MultiMetric([mx.Accuracy(), mx.ACE()])) source # MXNet.mx.NMSE Type . NMSE Normalized Mean Squared Error \\sum_i (\\frac{label_i - pred_i}{label_i})^2 Note that there are various ways to do the normalization . It depends on your own context. Please judge the problem setting you have first. If the current implementation do not suitable for you, feel free to file it on GitHub. Let me show you a use case of this kind of normalization: Bob is training a network for option pricing. The option pricing problem is a regression problem (pirce predicting). There are lots of option contracts on same target stock but different strike price. For example, there is a stock S ; it's market price is 1000. And, there are two call option contracts with different strike price. Assume Bob obtains the outcome as following table: +--------+----------------+----------------+--------------+ | | Strike Price | Market Price | Pred Price | +--------+----------------+----------------+--------------+ | Op 1 | 1500 | 100 | 80 | +--------+----------------+----------------+--------------+ | Op 2 | 500 | 10 | 8 | +--------+----------------+----------------+--------------+ Now, obviously, Bob will calculate the normalized MSE as: (\\frac{100 - 80}{100})^2 \\text{ vs } (\\frac{10 - 8}{10}) ^2 Both of the pred prices got the same degree of error. For more discussion about normalized MSE, please see #211 also. source # MXNet.mx.SeqMetric Type . SeqMetric(metrics::Vector{AbstractEvalMetric}) Apply a different metric to each output. This is especially useful for mx.Group . Usage Calculate accuracy Accuracy for the first output and log-loss ACE for the second output: mx.fit(..., eval_metric = mx.SeqMetric([mx.Accuracy(), mx.ACE()])) source # MXNet.mx.update! Method . update!(metric, labels, preds) Update and accumulate metrics. Arguments: metric::AbstractEvalMetric : the metric object. labels::Vector{NDArray} : the labels from the data provider. preds::Vector{NDArray} : the outputs (predictions) of the network. source # MXNet.mx.NullMetric Type . NullMetric() A metric that calculates nothing. Can be used to ignore an output during training. source # Base.get Method . get(metric) Get the accumulated metrics. Returns Vector{Tuple{Base.Symbol, Real}} , a list of name-value pairs. For example, [(:accuracy, 0.9)] . source # MXNet.mx.hasNDArraySupport Method . hasNDArraySupport(metric) - Val{true/false} Trait for _update_single_output should return Val{true}() if metric can handle NDArray directly and Val{false}() if requires Array`. Metric that work with NDArrays can be async, while native Julia arrays require that we copy the output of the network, which is a blocking operation. source # MXNet.mx.reset! Method . reset!(metric) Reset the accumulation counter. source","title":"Evaluation Metrics"},{"location":"api/model/","text":"Model The model API provides convenient high-level interface to do training and predicting on a network described using the symbolic API. # MXNet.mx.AbstractModel Type . AbstractModel The abstract super type of all models in MXNet.jl. source # MXNet.mx.FeedForward Type . FeedForward The feedforward model provides convenient interface to train and predict on feedforward architectures like multi-layer MLP, ConvNets, etc. There is no explicitly handling of time index , but it is relatively easy to implement unrolled RNN / LSTM under this framework ( TODO : add example). For models that handles sequential data explicitly, please use TODO ... source # MXNet.mx.FeedForward Method . FeedForward(arch :: SymbolicNode, ctx) Arguments: arch : the architecture of the network constructed using the symbolic API. ctx : the devices on which this model should do computation. It could be a single Context or a list of Context objects. In the latter case, data parallelization will be used for training. If no context is provided, the default context cpu() will be used. source # MXNet.mx.predict Method . predict(self, data; overwrite=false, callback=nothing) Predict using an existing model. The model should be already initialized, or trained or loaded from a checkpoint. There is an overloaded function that allows to pass the callback as the first argument, so it is possible to do predict(model, data) do batch_output # consume or write batch_output to file end Arguments: self::FeedForward : the model. data::AbstractDataProvider : the data to perform prediction on. overwrite::Bool : an Executor is initialized the first time predict is called. The memory allocation of the Executor depends on the mini-batch size of the test data provider. If you call predict twice with data provider of the same batch-size, then the executor can be potentially be re-used. So, if overwrite is false, we will try to re-use, and raise an error if batch-size changed. If overwrite is true (the default), a new Executor will be created to replace the old one. verbosity::Integer : Determines the verbosity of the print messages. Higher numbers leads to more verbose printing. Acceptable values are - 0 : Do not print anything during prediction - 1 : Print allocation information during prediction Note Prediction is computationally much less costly than training, so the bottleneck sometimes becomes the IO for copying mini-batches of data. Since there is no concern about convergence in prediction, it is better to set the mini-batch size as large as possible (limited by your device memory) if prediction speed is a concern. For the same reason, currently prediction will only use the first device even if multiple devices are provided to construct the model. Note If you perform further after prediction. The weights are not automatically synchronized if overwrite is set to false and the old predictor is re-used. In this case setting overwrite to true (the default) will re-initialize the predictor the next time you call predict and synchronize the weights again. See also train , fit , init_model , and load_checkpoint source # MXNet.mx._split_inputs Method . Get a split of batch_size into n_split pieces for data parallelization. Returns a vector of length n_split , with each entry a UnitRange{Int} indicating the slice index for that piece. source # MXNet.mx.fit Method . fit(model::FeedForward, optimizer, data; kwargs...) Train the model on data with the optimizer . model::FeedForward : the model to be trained. optimizer::AbstractOptimizer : the optimization algorithm to use. data::AbstractDataProvider : the training data provider. n_epoch::Int : default 10, the number of full data-passes to run. eval_data::AbstractDataProvider : keyword argument, default nothing . The data provider for the validation set. eval_metric::AbstractEvalMetric : keyword argument, default Accuracy() . The metric used to evaluate the training performance. If eval_data is provided, the same metric is also calculated on the validation set. kvstore : keyword argument, default :local . The key-value store used to synchronize gradients and parameters when multiple devices are used for training. :type kvstore: KVStore or Symbol initializer::AbstractInitializer : keyword argument, default UniformInitializer(0.01) . force_init::Bool : keyword argument, default false. By default, the random initialization using the provided initializer will be skipped if the model weights already exists, maybe from a previous call to train or an explicit call to init_model or load_checkpoint . When this option is set, it will always do random initialization at the begining of training. callbacks::Vector{AbstractCallback} : keyword argument, default [] . Callbacks to be invoked at each epoch or mini-batch, see AbstractCallback . verbosity::Int : Determines the verbosity of the print messages. Higher numbers leads to more verbose printing. Acceptable values are - 0 : Do not print anything during training - 1 : Print starting and final messages - 2 : Print one time messages and a message at the start of each epoch - 3 : Print a summary of the training and validation accuracy for each epoch \u03b7_decay::Symbol : :epoch or :batch , decay learning rate on epoch or batch. source # MXNet.mx.init_model Method . init_model(self, initializer; overwrite=false, input_shapes...) Initialize the weights in the model. This method will be called automatically when training a model. So there is usually no need to call this method unless one needs to inspect a model with only randomly initialized weights. Arguments: self::FeedForward : the model to be initialized. initializer::AbstractInitializer : an initializer describing how the weights should be initialized. overwrite::Bool : keyword argument, force initialization even when weights already exists. input_shapes : the shape of all data and label inputs to this model, given as keyword arguments. For example, data=(28,28,1,100), label=(100,) . source # MXNet.mx.load_checkpoint Method . load_checkpoint(prefix, epoch, ::mx.FeedForward; context) Load a mx.FeedForward model from the checkpoint prefix , epoch and optionally provide a context. source # MXNet.mx.train Method . train(model :: FeedForward, ...) Alias to fit . source","title":"Models"},{"location":"api/model/#model","text":"The model API provides convenient high-level interface to do training and predicting on a network described using the symbolic API. # MXNet.mx.AbstractModel Type . AbstractModel The abstract super type of all models in MXNet.jl. source # MXNet.mx.FeedForward Type . FeedForward The feedforward model provides convenient interface to train and predict on feedforward architectures like multi-layer MLP, ConvNets, etc. There is no explicitly handling of time index , but it is relatively easy to implement unrolled RNN / LSTM under this framework ( TODO : add example). For models that handles sequential data explicitly, please use TODO ... source # MXNet.mx.FeedForward Method . FeedForward(arch :: SymbolicNode, ctx) Arguments: arch : the architecture of the network constructed using the symbolic API. ctx : the devices on which this model should do computation. It could be a single Context or a list of Context objects. In the latter case, data parallelization will be used for training. If no context is provided, the default context cpu() will be used. source # MXNet.mx.predict Method . predict(self, data; overwrite=false, callback=nothing) Predict using an existing model. The model should be already initialized, or trained or loaded from a checkpoint. There is an overloaded function that allows to pass the callback as the first argument, so it is possible to do predict(model, data) do batch_output # consume or write batch_output to file end Arguments: self::FeedForward : the model. data::AbstractDataProvider : the data to perform prediction on. overwrite::Bool : an Executor is initialized the first time predict is called. The memory allocation of the Executor depends on the mini-batch size of the test data provider. If you call predict twice with data provider of the same batch-size, then the executor can be potentially be re-used. So, if overwrite is false, we will try to re-use, and raise an error if batch-size changed. If overwrite is true (the default), a new Executor will be created to replace the old one. verbosity::Integer : Determines the verbosity of the print messages. Higher numbers leads to more verbose printing. Acceptable values are - 0 : Do not print anything during prediction - 1 : Print allocation information during prediction Note Prediction is computationally much less costly than training, so the bottleneck sometimes becomes the IO for copying mini-batches of data. Since there is no concern about convergence in prediction, it is better to set the mini-batch size as large as possible (limited by your device memory) if prediction speed is a concern. For the same reason, currently prediction will only use the first device even if multiple devices are provided to construct the model. Note If you perform further after prediction. The weights are not automatically synchronized if overwrite is set to false and the old predictor is re-used. In this case setting overwrite to true (the default) will re-initialize the predictor the next time you call predict and synchronize the weights again. See also train , fit , init_model , and load_checkpoint source # MXNet.mx._split_inputs Method . Get a split of batch_size into n_split pieces for data parallelization. Returns a vector of length n_split , with each entry a UnitRange{Int} indicating the slice index for that piece. source # MXNet.mx.fit Method . fit(model::FeedForward, optimizer, data; kwargs...) Train the model on data with the optimizer . model::FeedForward : the model to be trained. optimizer::AbstractOptimizer : the optimization algorithm to use. data::AbstractDataProvider : the training data provider. n_epoch::Int : default 10, the number of full data-passes to run. eval_data::AbstractDataProvider : keyword argument, default nothing . The data provider for the validation set. eval_metric::AbstractEvalMetric : keyword argument, default Accuracy() . The metric used to evaluate the training performance. If eval_data is provided, the same metric is also calculated on the validation set. kvstore : keyword argument, default :local . The key-value store used to synchronize gradients and parameters when multiple devices are used for training. :type kvstore: KVStore or Symbol initializer::AbstractInitializer : keyword argument, default UniformInitializer(0.01) . force_init::Bool : keyword argument, default false. By default, the random initialization using the provided initializer will be skipped if the model weights already exists, maybe from a previous call to train or an explicit call to init_model or load_checkpoint . When this option is set, it will always do random initialization at the begining of training. callbacks::Vector{AbstractCallback} : keyword argument, default [] . Callbacks to be invoked at each epoch or mini-batch, see AbstractCallback . verbosity::Int : Determines the verbosity of the print messages. Higher numbers leads to more verbose printing. Acceptable values are - 0 : Do not print anything during training - 1 : Print starting and final messages - 2 : Print one time messages and a message at the start of each epoch - 3 : Print a summary of the training and validation accuracy for each epoch \u03b7_decay::Symbol : :epoch or :batch , decay learning rate on epoch or batch. source # MXNet.mx.init_model Method . init_model(self, initializer; overwrite=false, input_shapes...) Initialize the weights in the model. This method will be called automatically when training a model. So there is usually no need to call this method unless one needs to inspect a model with only randomly initialized weights. Arguments: self::FeedForward : the model to be initialized. initializer::AbstractInitializer : an initializer describing how the weights should be initialized. overwrite::Bool : keyword argument, force initialization even when weights already exists. input_shapes : the shape of all data and label inputs to this model, given as keyword arguments. For example, data=(28,28,1,100), label=(100,) . source # MXNet.mx.load_checkpoint Method . load_checkpoint(prefix, epoch, ::mx.FeedForward; context) Load a mx.FeedForward model from the checkpoint prefix , epoch and optionally provide a context. source # MXNet.mx.train Method . train(model :: FeedForward, ...) Alias to fit . source","title":"Model"},{"location":"api/ndarray/","text":"NDArray API Arithmetic Operations In the following example y can be a Real value or another NDArray API Example + x .+ y Elementwise summation - x .- y Elementwise minus * x .* y Elementwise multiplication / x ./ y Elementwise division ^ x .^ y Elementwise power % x .% y Elementwise modulo Trigonometric Functions API Example sin sin.(x) Elementwise sine cos cos.(x) Elementwise cosine tan tan.(x) Elementwise tangent asin asin.(x) Elementwise inverse sine acos acos.(x) Elementwise inverse cosine atan atan.(x) Elementwise inverse tangent Hyperbolic Functions API Example sinh sinh.(x) Elementwise hyperbolic sine cosh cosh.(x) Elementwise hyperbolic cosine tanh tanh.(x) Elementwise hyperbolic tangent asinh asinh.(x) Elementwise inverse hyperbolic sine acosh acosh.(x) Elementwise inverse hyperbolic cosine atanh atanh.(x) Elementwise inverse hyperbolic tangent Activation Functions API Example \u03c3 \u03c3.(x) Sigmoid function sigmoid sigmoid.(x) Sigmoid function relu relu.(x) ReLU function softmax softmax.(x) Softmax function log_softmax log_softmax.(x) Softmax followed by log Reference","title":"NDArray API"},{"location":"api/ndarray/#ndarray-api","text":"","title":"NDArray API"},{"location":"api/ndarray/#arithmetic-operations","text":"In the following example y can be a Real value or another NDArray API Example + x .+ y Elementwise summation - x .- y Elementwise minus * x .* y Elementwise multiplication / x ./ y Elementwise division ^ x .^ y Elementwise power % x .% y Elementwise modulo","title":"Arithmetic Operations"},{"location":"api/ndarray/#trigonometric-functions","text":"API Example sin sin.(x) Elementwise sine cos cos.(x) Elementwise cosine tan tan.(x) Elementwise tangent asin asin.(x) Elementwise inverse sine acos acos.(x) Elementwise inverse cosine atan atan.(x) Elementwise inverse tangent","title":"Trigonometric Functions"},{"location":"api/ndarray/#hyperbolic-functions","text":"API Example sinh sinh.(x) Elementwise hyperbolic sine cosh cosh.(x) Elementwise hyperbolic cosine tanh tanh.(x) Elementwise hyperbolic tangent asinh asinh.(x) Elementwise inverse hyperbolic sine acosh acosh.(x) Elementwise inverse hyperbolic cosine atanh atanh.(x) Elementwise inverse hyperbolic tangent","title":"Hyperbolic Functions"},{"location":"api/ndarray/#activation-functions","text":"API Example \u03c3 \u03c3.(x) Sigmoid function sigmoid sigmoid.(x) Sigmoid function relu relu.(x) ReLU function softmax softmax.(x) Softmax function log_softmax log_softmax.(x) Softmax followed by log","title":"Activation Functions"},{"location":"api/ndarray/#reference","text":"","title":"Reference"},{"location":"api/nn-factory/","text":"Neural Network Factory Neural network factory provide convenient helper functions to define common neural networks. # MXNet.mx.MLP Method . MLP(input, spec; hidden_activation = :relu, prefix) Construct a multi-layer perceptron. A MLP is a multi-layer neural network with fully connected layers. Arguments: input::SymbolicNode : the input to the mlp. spec : the mlp specification, a list of hidden dimensions. For example, [128, (512, :sigmoid), 10] . The number in the list indicate the number of hidden units in each layer. A tuple could be used to specify the activation of each layer. Otherwise, the default activation will be used (except for the last layer). hidden_activation::Symbol : keyword argument, default :relu , indicating the default activation for hidden layers. The specification here could be overwritten by layer-wise specification in the spec argument. Also activation is not applied to the last, i.e. the prediction layer. See Activation for a list of supported activation types. prefix : keyword argument, default gensym() , used as the prefix to name the constructed layers. Returns the constructed MLP. source","title":"Neural Networks Factory"},{"location":"api/nn-factory/#neural-network-factory","text":"Neural network factory provide convenient helper functions to define common neural networks. # MXNet.mx.MLP Method . MLP(input, spec; hidden_activation = :relu, prefix) Construct a multi-layer perceptron. A MLP is a multi-layer neural network with fully connected layers. Arguments: input::SymbolicNode : the input to the mlp. spec : the mlp specification, a list of hidden dimensions. For example, [128, (512, :sigmoid), 10] . The number in the list indicate the number of hidden units in each layer. A tuple could be used to specify the activation of each layer. Otherwise, the default activation will be used (except for the last layer). hidden_activation::Symbol : keyword argument, default :relu , indicating the default activation for hidden layers. The specification here could be overwritten by layer-wise specification in the spec argument. Also activation is not applied to the last, i.e. the prediction layer. See Activation for a list of supported activation types. prefix : keyword argument, default gensym() , used as the prefix to name the constructed layers. Returns the constructed MLP. source","title":"Neural Network Factory"},{"location":"api/optimizer/","text":"Optimizers Says, you have the parameter W inited for your model and got its gradient stored as \u2207 (perhaps from AutoGrad APIs). Here is minimal snippet of getting your parameter W baked by SGD . julia using MXNet julia opt = SGD(\u03b7 = 10) SGD(10, 0.0, 0, 0, 0.0001, MXNet.mx.LearningRate.Fixed(10.0), MXNet.mx.Momentum.Null()) julia decend! = getupdater(opt) (::getfield(MXNet.mx, Symbol( #updater#5792 )){SGD,Dict{Int64,Any}}) (generic function with 1 method) julia W = NDArray(Float32[1, 2, 3, 4]); julia \u2207 = NDArray(Float32[.1, .2, .3, .4]); julia decend!(1, \u2207, W) 4-element NDArray{Float32,1} @ CPU0: -0.0010000467f0 -0.0020000935f0 -0.003000021f0 -0.004000187f0 # MXNet.mx.AbstractOptimizer Type . AbstractOptimizer Base type for all optimizers. source # MXNet.mx.getupdater Method . getupdater(optimizer) A utility function to create an updater function of KVStore , that uses its closure to store all the states needed for each weights. Ther returned function has following signature: decend!(index::Int, \u2207::NDArray, x::NDArray) If the optimizer is stateful and need access/store states during updating, index will be the key to access/store states. source # MXNet.mx.normgrad! Method . normgrad(optimizer, W, \u2207) Get the properly normalized gradient (re-scaled and clipped if necessary). optimizer : the optimizer, should contain the field scale , clip and \u03bb . W::NDArray : the trainable weights. \u2207::NDArray : the original gradient of the weights. source # MXNet.mx.AbstractLearningRateScheduler Type . AbstractLearningRateScheduler Base type for all learning rate scheduler. source # MXNet.mx.AbstractMomentumScheduler Type . AbstractMomentumScheduler Base type for all momentum scheduler. source # MXNet.mx.OptimizationState Type . OptimizationState Attributes batch_size : The size of the mini-batch used in stochastic training. curr_epoch : The current epoch count. Epoch 0 means no training yet, during the first pass through the data, the epoch will be 1; during the second pass, the epoch count will be 1, and so on. curr_batch : The current mini-batch count. The batch count is reset during every epoch. The batch count 0 means the beginning of each epoch, with no mini-batch seen yet. During the first mini-batch, the mini-batch count will be 1. curr_iter : The current iteration count. One iteration corresponds to one mini-batch, but unlike the mini-batch count, the iteration count does not reset in each epoch. So it track the total number of mini-batches seen so far. source # MXNet.mx.LearningRate.Exp Type . LearningRate.Exp(\u03b7\u2080; \u03b3 = 0.9) \\eta_t = \\eta_0\\gamma^t Where t is the epoch count, or the iteration count. source # MXNet.mx.LearningRate.Fixed Type . LearningRate.Fixed(\u03b7) Fixed learning rate scheduler always return the same learning rate. source # MXNet.mx.LearningRate.Inv Type . LearningRate.Inv(\u03b7\u2080; \u03b3 = 0.9, p = 0.5) \\eta_t = \\eta_0 (1 + \\gamma t)^{-p} Where t is the epoch count, or the iteration count. source # Base.get Method . get(sched::AbstractLearningRateScheduler) Returns the current learning rate. source # MXNet.mx.Momentum.Fixed Type . Momentum.Fixed Fixed momentum scheduler always returns the same value. source # MXNet.mx.Momentum.NadamScheduler Type . NadamScheduler(; \u03bc = 0.99, \u03b4 = 0.004, \u03b3 = 0.5, \u03b1 = 0.96) Nesterov-accelerated adaptive momentum scheduler. Description in Incorporating Nesterov Momentum into Adam . \\mu_t = \\mu_0 * (1 - \\gamma * \\alpha^{t * \\delta}) Where t : iteration count \u03bc : default 0.99 , \u03bc\u2080 \u03b4 : default 0.004 is scheduler decay. \u03b3 : default 0.5 \u03b1 : default 0.96 source # MXNet.mx.Momentum.Null Type . Momentum.Null The null momentum scheduler always returns 0 for momentum. It is also used to explicitly indicate momentum should not be used. source # Base.get Method . get(n::NadamScheduler, t) Where t is the iteration count. source Built-in optimizers Stochastic Gradient Descent # MXNet.mx.SGD Type . SGD(; kwargs...) Stochastic gradient descent optimizer. Vanilla SGD: \\theta \\leftarrow \\theta - \\eta \\nabla SGD with momentum:: \\begin{align*} \\nu & \\leftarrow \\mu \\nu_{t-1} - \\eta \\nabla \\\\ \\theta & \\leftarrow \\theta + \\nu_t \\end{align*} Arguments \u03b7 : default 0.01 , learning rate. \u03bc : default 0 , the momentum, usually set to 0.9 in this implementation. \u03bb : default 0.0001 , weight decay is equivalent to adding a global l2 regularizer to the parameters. clip : default 0 , gradient clipping. If positive, will clip the gradient into the bounded range [-clip, clip] . scale : default 0 , gradient rescaling. If != 0, multiply the gradient with scale before updating. Often choose to be 1.0 / batch_size . If leave it default, high-level API like fit! will set it to 1.0 / batch_size , since fit! knows the batch_size . \u03bc_sched::AbstractMomentumScheduler : default Momentum.Null() , a dynamic momentum scheduler. If set, will overwrite the momentum parameter. \u03b7_sched::AbstractLearningRateScheduler : default LearningRate.Fixed(\u03b7) , a dynamic learning rate scheduler. If set, will overwrite the \u03b7 parameter. source ADAM # MXNet.mx.ADAM Type . ADAM The solver described in Diederik Kingma, Jimmy Ba: Adam: A Method for Stochastic Optimization . arXiv:1412.6980 [cs.LG]. ADAM(; kwargs...) Arguments \u03b7 : default 0.001 , learning rate. \u03b21 : default 0.9 . \u03b22 : default 0.999 . \u03f5 : default 1e-8 . clip : default 0 , gradient clipping. If positive, will clip the gradient into the range [-clip, clip] . scale : default 0 , gradient rescaling. If != 0, multiply the gradient with scale before updating. Often choose to be 1.0 / batch_size . If leave it default, high-level API like fit! will set it to 1.0 / batch_size , since fit! knows the batch_size . \u03bb : default 0.00001 , weight decay is equivalent to adding a global l2 regularizer for all the parameters. \u03b7_sched::AbstractLearningRateScheduler : default LearningRate.Fixed(\u03b7) , a dynamic learning rate scheduler. If set, will overwrite the \u03b7 parameter. source AdaGrad # MXNet.mx.AdaGrad Type . AdaGrad(; kwargs...) Scale learning rates by dividing with the square root of accumulated squared gradients. See [1] for further description. Arguments \u03b7 : default 0.1 , learning rate. \u03f5 : default 1e-6 , small value added for numerical stability. clip : default 0 , gradient clipping. If positive, will clip the gradient into the range [-clip, clip] . scale : default 0 , gradient rescaling. If != 0, multiply the gradient with scale before updating. Often choose to be 1.0 / batch_size . If leave it default, high-level API like fit! will set it to 1.0 / batch_size , since fit! knows the batch_size . \u03bb : default 0.00001 , weight decay is equivalent to adding a global l2 regularizer for all the parameters. Notes Using step size \u03b7 AdaGrad calculates the learning rate for feature i at time step t as: \u03b7_{t,i} = \\frac{lr}{\\sqrt{\\sum^t_{t^\\prime} g^2_{t^\\prime,i} + \u03f5}} g_{t,i} as such the learning rate is monotonically decreasing. Epsilon is not included in the typical formula, see [2]. References Duchi, J., Hazan, E., Singer, Y. (2011): Adaptive subgradient methods for online learning and stochastic optimization. JMLR, 12:2121-2159. Chris Dyer: Notes on AdaGrad. http://www.ark.cs.cmu.edu/cdyer/adagrad.pdf source AdaDelta # MXNet.mx.AdaDelta Type . AdaDelta(; kwargs...) Scale learning rates by the ratio of accumulated gradients to accumulated updates, see [1] and notes for further description. Attributes \u03b7 : default 1.0 , learning rate. \u03c1 : default 0.95 , squared gradient moving average decay factor. \u03f5 : default 1e-6 , small value added for numerical stability. clip : default 0 , gradient clipping. If positive, will clip the gradient into the range [-clip, clip] . scale : default 0 , gradient rescaling. If != 0, multiply the gradient with scale before updating. Often choose to be 1.0 / batch_size . If leave it default, high-level API like fit! will set it to 1.0 / batch_size , since fit! knows the batch_size . \u03bb : default 0.00001 , weight decay is equivalent to adding a global l2 regularizer for all the parameters. Notes \u03c1 should be between 0 and 1. A value of \u03c1 close to 1 will decay the moving average slowly and a value close to 0 will decay the moving average fast. \u03c1 = 0.95 and \u03f5 = 1e-6 are suggested in the paper and reported to work for multiple datasets (MNIST, speech). In the paper, no learning rate is considered (so \u03b7 = 1.0 ). Probably best to keep it at this value. \u03f5 is important for the very first update (so the numerator does not become 0). Using the step size \u03b7 and a decay factor \u03c1 the learning rate is calculated as: \\begin{align*} r_t &= \u03c1 r_{t-1} + (1 - \u03c1) g^2 \\\\ \u03b7_t &= \u03b7 \\frac{\\sqrt{s_{t-1} + \u03f5}} {\\sqrt{r_t + \u03f5}} \\\\ s_t &= \u03c1 s_{t-1} + (1 - \u03c1) (\u03b7_t \\times g)^2 \\end{align*} References Zeiler, M. D. (2012): ADADELTA: An Adaptive Learning Rate Method. arXiv Preprint arXiv:1212.5701. source AdaMax # MXNet.mx.AdaMax Type . AdaMax(; kwargs...) This is a variant of of the Adam algorithm based on the infinity norm. See [1] for further description. Arguments \u03b7 : default 0.002 , learning rate. \u03b21 : default 0.9 , exponential decay rate for the first moment estimates. \u03b22 : default 0.999 , exponential decay rate for the weighted infinity norm estimates. \u03f5 : default 1e-8 , small value added for numerical stability. clip : default 0 , gradient clipping. If positive, will clip the gradient into the range [-clip, clip] . scale : default 0 , gradient rescaling. If != 0, multiply the gradient with scale before updating. Often choose to be 1.0 / batch_size . If leave it default, high-level API like fit! will set it to 1.0 / batch_size , since fit! knows the batch_size . \u03bb : default 0.00001 , weight decay is equivalent to adding a global l2 regularizer for all the parameters. References Kingma, Diederik, and Jimmy Ba (2014): Adam: A Method for Stochastic Optimization. Section 7. http://arxiv.org/abs/1412.6980 . source RMSProp # MXNet.mx.RMSProp Type . RMSProp(; kwargs...) Scale learning rates by dividing with the moving average of the root mean squared (RMS) gradients. See [1] for further description. Arguments \u03b7 : default 0.1 , learning rate. \u03c1 : default 0.9 , gradient moving average decay factor. \u03f5 : default 1e-8 , small value added for numerical stability. clip : default 0 , gradient clipping. If positive, will clip the gradient into the range [-clip, clip] . scale : default 0 , gradient rescaling. If != 0, multiply the gradient with scale before updating. Often choose to be 1.0 / batch_size . If leave it default, high-level API like fit! will set it to 1.0 / batch_size , since fit! knows the batch_size . \u03bb : default 0.00001 , weight decay is equivalent to adding a global l2 regularizer for all the parameters. Notes \u03c1 should be between 0 and 1. A value of \u03c1 close to 1 will decay the moving average slowly and a value close to 0 will decay the moving average fast. Using the step size \u03b7 and a decay factor \u03c1 the learning rate \u03b7\u209c` is calculated as: \\begin{align*} r_t &= \u03c1 r_{t-1} + (1 - \u03c1)g^2 \\\\ \u03b7_t &= \\frac{\u03b7}{\\sqrt{r_t + \u03f5}} \\end{align*} References Tieleman, T. and Hinton, G. (2012): Neural Networks for Machine Learning, Lecture 6.5 - rmsprop. Coursera. http://www.youtube.com/watch?v=O3sxAc4hxZU (formula @5:20) source Nadam # MXNet.mx.Nadam Type . Nadam(; kwargs...) Nesterov Adam optimizer: Adam RMSprop with Nesterov momentum, see [1] and notes for further description. Arguments \u03b7 : default 0.001 , learning rate. \u03b21 : default 0.99 . \u03b22 : default 0.999 . \u03f5 : default 1e-8 , small value added for numerical stability. clip : default 0 , gradient clipping. If positive, will clip the gradient into the range [-clip, clip] . scale : default 0 , gradient rescaling. If != 0, multiply the gradient with scale before updating. Often choose to be 1.0 / batch_size . If leave it default, high-level API like fit! will set it to 1.0 / batch_size , since fit! knows the batch_size . \u03bb : default 0.00001 , weight decay is equivalent to adding a global l2 regularizer for all the parameters. \u03b7_sched::AbstractLearningRateScheduler : default nothing , a dynamic learning rate scheduler. If set, will overwrite the \u03b7 parameter. \u03bc_sched::NadamScheduler default NadamScheduler() of the form. \\mu_t = \u03b2_1 (1 - 0.5 \\times 0.96^{t \\times 0.004}) Notes Default parameters follow those provided in the paper. It is recommended to leave the parameters of this optimizer at their default values. References Incorporating Nesterov Momentum into Adam . On the importance of initialization and momentum in deep learning . source","title":"Optimizers"},{"location":"api/optimizer/#optimizers","text":"Says, you have the parameter W inited for your model and got its gradient stored as \u2207 (perhaps from AutoGrad APIs). Here is minimal snippet of getting your parameter W baked by SGD . julia using MXNet julia opt = SGD(\u03b7 = 10) SGD(10, 0.0, 0, 0, 0.0001, MXNet.mx.LearningRate.Fixed(10.0), MXNet.mx.Momentum.Null()) julia decend! = getupdater(opt) (::getfield(MXNet.mx, Symbol( #updater#5792 )){SGD,Dict{Int64,Any}}) (generic function with 1 method) julia W = NDArray(Float32[1, 2, 3, 4]); julia \u2207 = NDArray(Float32[.1, .2, .3, .4]); julia decend!(1, \u2207, W) 4-element NDArray{Float32,1} @ CPU0: -0.0010000467f0 -0.0020000935f0 -0.003000021f0 -0.004000187f0 # MXNet.mx.AbstractOptimizer Type . AbstractOptimizer Base type for all optimizers. source # MXNet.mx.getupdater Method . getupdater(optimizer) A utility function to create an updater function of KVStore , that uses its closure to store all the states needed for each weights. Ther returned function has following signature: decend!(index::Int, \u2207::NDArray, x::NDArray) If the optimizer is stateful and need access/store states during updating, index will be the key to access/store states. source # MXNet.mx.normgrad! Method . normgrad(optimizer, W, \u2207) Get the properly normalized gradient (re-scaled and clipped if necessary). optimizer : the optimizer, should contain the field scale , clip and \u03bb . W::NDArray : the trainable weights. \u2207::NDArray : the original gradient of the weights. source # MXNet.mx.AbstractLearningRateScheduler Type . AbstractLearningRateScheduler Base type for all learning rate scheduler. source # MXNet.mx.AbstractMomentumScheduler Type . AbstractMomentumScheduler Base type for all momentum scheduler. source # MXNet.mx.OptimizationState Type . OptimizationState Attributes batch_size : The size of the mini-batch used in stochastic training. curr_epoch : The current epoch count. Epoch 0 means no training yet, during the first pass through the data, the epoch will be 1; during the second pass, the epoch count will be 1, and so on. curr_batch : The current mini-batch count. The batch count is reset during every epoch. The batch count 0 means the beginning of each epoch, with no mini-batch seen yet. During the first mini-batch, the mini-batch count will be 1. curr_iter : The current iteration count. One iteration corresponds to one mini-batch, but unlike the mini-batch count, the iteration count does not reset in each epoch. So it track the total number of mini-batches seen so far. source # MXNet.mx.LearningRate.Exp Type . LearningRate.Exp(\u03b7\u2080; \u03b3 = 0.9) \\eta_t = \\eta_0\\gamma^t Where t is the epoch count, or the iteration count. source # MXNet.mx.LearningRate.Fixed Type . LearningRate.Fixed(\u03b7) Fixed learning rate scheduler always return the same learning rate. source # MXNet.mx.LearningRate.Inv Type . LearningRate.Inv(\u03b7\u2080; \u03b3 = 0.9, p = 0.5) \\eta_t = \\eta_0 (1 + \\gamma t)^{-p} Where t is the epoch count, or the iteration count. source # Base.get Method . get(sched::AbstractLearningRateScheduler) Returns the current learning rate. source # MXNet.mx.Momentum.Fixed Type . Momentum.Fixed Fixed momentum scheduler always returns the same value. source # MXNet.mx.Momentum.NadamScheduler Type . NadamScheduler(; \u03bc = 0.99, \u03b4 = 0.004, \u03b3 = 0.5, \u03b1 = 0.96) Nesterov-accelerated adaptive momentum scheduler. Description in Incorporating Nesterov Momentum into Adam . \\mu_t = \\mu_0 * (1 - \\gamma * \\alpha^{t * \\delta}) Where t : iteration count \u03bc : default 0.99 , \u03bc\u2080 \u03b4 : default 0.004 is scheduler decay. \u03b3 : default 0.5 \u03b1 : default 0.96 source # MXNet.mx.Momentum.Null Type . Momentum.Null The null momentum scheduler always returns 0 for momentum. It is also used to explicitly indicate momentum should not be used. source # Base.get Method . get(n::NadamScheduler, t) Where t is the iteration count. source","title":"Optimizers"},{"location":"api/optimizer/#built-in-optimizers","text":"","title":"Built-in optimizers"},{"location":"api/optimizer/#stochastic-gradient-descent","text":"# MXNet.mx.SGD Type . SGD(; kwargs...) Stochastic gradient descent optimizer. Vanilla SGD: \\theta \\leftarrow \\theta - \\eta \\nabla SGD with momentum:: \\begin{align*} \\nu & \\leftarrow \\mu \\nu_{t-1} - \\eta \\nabla \\\\ \\theta & \\leftarrow \\theta + \\nu_t \\end{align*} Arguments \u03b7 : default 0.01 , learning rate. \u03bc : default 0 , the momentum, usually set to 0.9 in this implementation. \u03bb : default 0.0001 , weight decay is equivalent to adding a global l2 regularizer to the parameters. clip : default 0 , gradient clipping. If positive, will clip the gradient into the bounded range [-clip, clip] . scale : default 0 , gradient rescaling. If != 0, multiply the gradient with scale before updating. Often choose to be 1.0 / batch_size . If leave it default, high-level API like fit! will set it to 1.0 / batch_size , since fit! knows the batch_size . \u03bc_sched::AbstractMomentumScheduler : default Momentum.Null() , a dynamic momentum scheduler. If set, will overwrite the momentum parameter. \u03b7_sched::AbstractLearningRateScheduler : default LearningRate.Fixed(\u03b7) , a dynamic learning rate scheduler. If set, will overwrite the \u03b7 parameter. source","title":"Stochastic Gradient Descent"},{"location":"api/optimizer/#adam","text":"# MXNet.mx.ADAM Type . ADAM The solver described in Diederik Kingma, Jimmy Ba: Adam: A Method for Stochastic Optimization . arXiv:1412.6980 [cs.LG]. ADAM(; kwargs...) Arguments \u03b7 : default 0.001 , learning rate. \u03b21 : default 0.9 . \u03b22 : default 0.999 . \u03f5 : default 1e-8 . clip : default 0 , gradient clipping. If positive, will clip the gradient into the range [-clip, clip] . scale : default 0 , gradient rescaling. If != 0, multiply the gradient with scale before updating. Often choose to be 1.0 / batch_size . If leave it default, high-level API like fit! will set it to 1.0 / batch_size , since fit! knows the batch_size . \u03bb : default 0.00001 , weight decay is equivalent to adding a global l2 regularizer for all the parameters. \u03b7_sched::AbstractLearningRateScheduler : default LearningRate.Fixed(\u03b7) , a dynamic learning rate scheduler. If set, will overwrite the \u03b7 parameter. source","title":"ADAM"},{"location":"api/optimizer/#adagrad","text":"# MXNet.mx.AdaGrad Type . AdaGrad(; kwargs...) Scale learning rates by dividing with the square root of accumulated squared gradients. See [1] for further description. Arguments \u03b7 : default 0.1 , learning rate. \u03f5 : default 1e-6 , small value added for numerical stability. clip : default 0 , gradient clipping. If positive, will clip the gradient into the range [-clip, clip] . scale : default 0 , gradient rescaling. If != 0, multiply the gradient with scale before updating. Often choose to be 1.0 / batch_size . If leave it default, high-level API like fit! will set it to 1.0 / batch_size , since fit! knows the batch_size . \u03bb : default 0.00001 , weight decay is equivalent to adding a global l2 regularizer for all the parameters. Notes Using step size \u03b7 AdaGrad calculates the learning rate for feature i at time step t as: \u03b7_{t,i} = \\frac{lr}{\\sqrt{\\sum^t_{t^\\prime} g^2_{t^\\prime,i} + \u03f5}} g_{t,i} as such the learning rate is monotonically decreasing. Epsilon is not included in the typical formula, see [2]. References Duchi, J., Hazan, E., Singer, Y. (2011): Adaptive subgradient methods for online learning and stochastic optimization. JMLR, 12:2121-2159. Chris Dyer: Notes on AdaGrad. http://www.ark.cs.cmu.edu/cdyer/adagrad.pdf source","title":"AdaGrad"},{"location":"api/optimizer/#adadelta","text":"# MXNet.mx.AdaDelta Type . AdaDelta(; kwargs...) Scale learning rates by the ratio of accumulated gradients to accumulated updates, see [1] and notes for further description. Attributes \u03b7 : default 1.0 , learning rate. \u03c1 : default 0.95 , squared gradient moving average decay factor. \u03f5 : default 1e-6 , small value added for numerical stability. clip : default 0 , gradient clipping. If positive, will clip the gradient into the range [-clip, clip] . scale : default 0 , gradient rescaling. If != 0, multiply the gradient with scale before updating. Often choose to be 1.0 / batch_size . If leave it default, high-level API like fit! will set it to 1.0 / batch_size , since fit! knows the batch_size . \u03bb : default 0.00001 , weight decay is equivalent to adding a global l2 regularizer for all the parameters. Notes \u03c1 should be between 0 and 1. A value of \u03c1 close to 1 will decay the moving average slowly and a value close to 0 will decay the moving average fast. \u03c1 = 0.95 and \u03f5 = 1e-6 are suggested in the paper and reported to work for multiple datasets (MNIST, speech). In the paper, no learning rate is considered (so \u03b7 = 1.0 ). Probably best to keep it at this value. \u03f5 is important for the very first update (so the numerator does not become 0). Using the step size \u03b7 and a decay factor \u03c1 the learning rate is calculated as: \\begin{align*} r_t &= \u03c1 r_{t-1} + (1 - \u03c1) g^2 \\\\ \u03b7_t &= \u03b7 \\frac{\\sqrt{s_{t-1} + \u03f5}} {\\sqrt{r_t + \u03f5}} \\\\ s_t &= \u03c1 s_{t-1} + (1 - \u03c1) (\u03b7_t \\times g)^2 \\end{align*} References Zeiler, M. D. (2012): ADADELTA: An Adaptive Learning Rate Method. arXiv Preprint arXiv:1212.5701. source","title":"AdaDelta"},{"location":"api/optimizer/#adamax","text":"# MXNet.mx.AdaMax Type . AdaMax(; kwargs...) This is a variant of of the Adam algorithm based on the infinity norm. See [1] for further description. Arguments \u03b7 : default 0.002 , learning rate. \u03b21 : default 0.9 , exponential decay rate for the first moment estimates. \u03b22 : default 0.999 , exponential decay rate for the weighted infinity norm estimates. \u03f5 : default 1e-8 , small value added for numerical stability. clip : default 0 , gradient clipping. If positive, will clip the gradient into the range [-clip, clip] . scale : default 0 , gradient rescaling. If != 0, multiply the gradient with scale before updating. Often choose to be 1.0 / batch_size . If leave it default, high-level API like fit! will set it to 1.0 / batch_size , since fit! knows the batch_size . \u03bb : default 0.00001 , weight decay is equivalent to adding a global l2 regularizer for all the parameters. References Kingma, Diederik, and Jimmy Ba (2014): Adam: A Method for Stochastic Optimization. Section 7. http://arxiv.org/abs/1412.6980 . source","title":"AdaMax"},{"location":"api/optimizer/#rmsprop","text":"# MXNet.mx.RMSProp Type . RMSProp(; kwargs...) Scale learning rates by dividing with the moving average of the root mean squared (RMS) gradients. See [1] for further description. Arguments \u03b7 : default 0.1 , learning rate. \u03c1 : default 0.9 , gradient moving average decay factor. \u03f5 : default 1e-8 , small value added for numerical stability. clip : default 0 , gradient clipping. If positive, will clip the gradient into the range [-clip, clip] . scale : default 0 , gradient rescaling. If != 0, multiply the gradient with scale before updating. Often choose to be 1.0 / batch_size . If leave it default, high-level API like fit! will set it to 1.0 / batch_size , since fit! knows the batch_size . \u03bb : default 0.00001 , weight decay is equivalent to adding a global l2 regularizer for all the parameters. Notes \u03c1 should be between 0 and 1. A value of \u03c1 close to 1 will decay the moving average slowly and a value close to 0 will decay the moving average fast. Using the step size \u03b7 and a decay factor \u03c1 the learning rate \u03b7\u209c` is calculated as: \\begin{align*} r_t &= \u03c1 r_{t-1} + (1 - \u03c1)g^2 \\\\ \u03b7_t &= \\frac{\u03b7}{\\sqrt{r_t + \u03f5}} \\end{align*} References Tieleman, T. and Hinton, G. (2012): Neural Networks for Machine Learning, Lecture 6.5 - rmsprop. Coursera. http://www.youtube.com/watch?v=O3sxAc4hxZU (formula @5:20) source","title":"RMSProp"},{"location":"api/optimizer/#nadam","text":"# MXNet.mx.Nadam Type . Nadam(; kwargs...) Nesterov Adam optimizer: Adam RMSprop with Nesterov momentum, see [1] and notes for further description. Arguments \u03b7 : default 0.001 , learning rate. \u03b21 : default 0.99 . \u03b22 : default 0.999 . \u03f5 : default 1e-8 , small value added for numerical stability. clip : default 0 , gradient clipping. If positive, will clip the gradient into the range [-clip, clip] . scale : default 0 , gradient rescaling. If != 0, multiply the gradient with scale before updating. Often choose to be 1.0 / batch_size . If leave it default, high-level API like fit! will set it to 1.0 / batch_size , since fit! knows the batch_size . \u03bb : default 0.00001 , weight decay is equivalent to adding a global l2 regularizer for all the parameters. \u03b7_sched::AbstractLearningRateScheduler : default nothing , a dynamic learning rate scheduler. If set, will overwrite the \u03b7 parameter. \u03bc_sched::NadamScheduler default NadamScheduler() of the form. \\mu_t = \u03b2_1 (1 - 0.5 \\times 0.96^{t \\times 0.004}) Notes Default parameters follow those provided in the paper. It is recommended to leave the parameters of this optimizer at their default values. References Incorporating Nesterov Momentum into Adam . On the importance of initialization and momentum in deep learning . source","title":"Nadam"},{"location":"api/symbolic-node/","text":"Symbolic API","title":"Symbolic API"},{"location":"api/symbolic-node/#symbolic-api","text":"","title":"Symbolic API"},{"location":"api/visualize/","text":"Network Visualization # MXNet.mx.to_graphviz Method . to_graphviz(network) network::SymbolicNode : the network to visualize. title::AbstractString: keyword argument, default \"Network Visualization\", the title of the GraphViz graph. input_shapes : keyword argument, default nothing . If provided, will run shape inference and plot with the shape information. Should be either a dictionary of name-shape mapping or an array of shapes. Returns the graph description in GraphViz dot language. source","title":"Network Visualization"},{"location":"api/visualize/#network-visualization","text":"# MXNet.mx.to_graphviz Method . to_graphviz(network) network::SymbolicNode : the network to visualize. title::AbstractString: keyword argument, default \"Network Visualization\", the title of the GraphViz graph. input_shapes : keyword argument, default nothing . If provided, will run shape inference and plot with the shape information. Should be either a dictionary of name-shape mapping or an array of shapes. Returns the graph description in GraphViz dot language. source","title":"Network Visualization"},{"location":"tutorial/char-lstm/","text":"Generating Random Sentence with LSTM RNN This tutorial shows how to train a LSTM (Long short-term memory) RNN (recurrent neural network) to perform character-level sequence training and prediction. The original model, usually called char-rnn is described in Andrej Karpathy's blog , with a reference implementation in Torch available here . Because MXNet.jl does not have a specialized model for recurrent neural networks yet, the example shown here is an implementation of LSTM by using the default FeedForward model via explicitly unfolding over time. We will be using fixed-length input sequence for training. The code is adapted from the char-rnn example for MXNet's Python binding , which demonstrates how to use low-level Symbolic API to build customized neural network models directly. The most important code snippets of this example is shown and explained here. To see and run the complete code, please refer to the examples/char-lstm directory. You will need to install Iterators.jl and StatsBase.jl to run this example. LSTM Cells Christopher Olah has a great blog post about LSTM with beautiful and clear illustrations. So we will not repeat the definition and explanation of what an LSTM cell is here. Basically, an LSTM cell takes input x , as well as previous states (including c and h ), and produce the next states. We define a helper type to bundle the two state variables together: Because LSTM weights are shared at every time when we do explicit unfolding, so we also define a helper type to hold all the weights (and bias) for an LSTM cell for convenience. Note all the variables are of type SymbolicNode. We will construct the LSTM network as a symbolic computation graph, which is then instantiated with NDArray for actual computation. The following figure is stolen (permission requested) from Christopher Olah's blog , which illustrate exactly what the code snippet above is doing. In particular, instead of defining the four gates independently, we do the computation together and then use SliceChannel to split them into four outputs. The computation of gates are all done with the symbolic API. The return value is a LSTM state containing the output of a LSTM cell. Unfolding LSTM Using the LSTM cell defined above, we are now ready to define a function to unfold a LSTM network with L layers and T time steps. The first part of the function is just defining all the symbolic variables for the shared weights and states. The embed_W is the weights used for character embedding \u2013- i.e. mapping the one-hot encoded characters into real vectors. The pred_W and pred_b are weights and bias for the final prediction at each time step. Then we define the weights for each LSTM cell. Note there is one cell for each layer, and it will be replicated (unrolled) over time. The states are, however, not shared over time. Instead, here we define the initial states here at the beginning of a sequence, and we will update them with the output states at each time step as we explicitly unroll the LSTM. Unrolling over time is a straightforward procedure of stacking the embedding layer, and then LSTM cells, on top of which the prediction layer. During unrolling, we update the states and collect all the outputs. Note each time step takes data and label as inputs. If the LSTM is named as :ptb , the data and label at step t will be named :ptb_data_$t and :ptb_label_$t . Late on when we prepare the data, we will define the data provider to match those names. Note at each time step, the prediction is connected to a SoftmaxOutput operator, which could back propagate when corresponding labels are provided. The states are then connected to the next time step, which allows back propagate through time. However, at the end of the sequence, the final states are not connected to anything. This dangling outputs is problematic, so we explicitly connect each of them to a BlockGrad operator, which simply back propagates 0-gradient and closes the computation graph. In the end, we just group all the prediction outputs at each time step as a single SymbolicNode and return. Optionally we will also group the final states, this is used when we use the trained LSTM to sample sentences. Data Provider for Text Sequences Now we need to construct a data provider that takes a text file, divide the text into mini-batches of fixed-length character-sequences, and provide them as one-hot encoded vectors. Note the is no fancy feature extraction at all. Each character is simply encoded as a one-hot vector: a 0-1 vector of the size given by the vocabulary. Here we just construct the vocabulary by collecting all the unique characters in the training text \u2013 there are not too many of them (including punctuations and whitespace) for English text. Each input character is then encoded as a vector of 0s on all coordinates, and 1 on the coordinate corresponding to that character. The character-to-coordinate mapping is giving by the vocabulary. The text sequence data provider implements the Data Providers api. We define the CharSeqProvider as below: The provided data and labels follow the naming convention of inputs used when unrolling the LSTM. Note in the code below, apart from $name_data_$t and $name_label_$t , we also provides the initial c and h states for each layer. This is because we are using the high-level FeedForward API, which has no idea about time and states. So we will feed the initial states for each sequence from the data provider. Since the initial states is always zero, we just need to always provide constant zero blobs. Next we implement the eachbatch method from the mx.AbstractDataProvider interface for the provider. We start by defining the data and label arrays, and the DataBatch object we will provide in each iteration. The actual data providing iteration is implemented as a Julia coroutine . In this way, we can write the data loading logic as a simple coherent for loop, and do not need to implement the interface functions like Base.start, Base.next, etc. Basically, we partition the text into batches, each batch containing several contiguous text sequences. Note at each time step, the LSTM is trained to predict the next character, so the label is the same as the data, but shifted ahead by one index. Training the LSTM Now we have implemented all the supporting infrastructures for our char-lstm. To train the model, we just follow the standard high-level API. Firstly, we construct a LSTM symbolic architecture: Note all the parameters are defined in examples/char-lstm/config.jl . Now we load the text file and define the data provider. The data input.txt we used in this example is a tiny Shakespeare dataset . But you can try with other text files. The last step is to construct a model, an optimizer and fit the mode to the data. We are using the ADAM optimizer [Adam]_ in this example. Note we are also using a customized NLL evaluation metric, which calculate the negative log-likelihood during training. Here is an output sample at the end of the training process. ... INFO: Speed: 357.72 samples/sec INFO: == Epoch 020 ========== INFO: ## Training summary INFO: NLL = 1.4672 INFO: perplexity = 4.3373 INFO: time = 87.2631 seconds INFO: ## Validation summary INFO: NLL = 1.6374 INFO: perplexity = 5.1418 INFO: Saved checkpoint to 'char-lstm/checkpoints/ptb-0020.params' INFO: Speed: 368.74 samples/sec INFO: Speed: 361.04 samples/sec INFO: Speed: 360.02 samples/sec INFO: Speed: 362.34 samples/sec INFO: Speed: 360.80 samples/sec INFO: Speed: 362.77 samples/sec INFO: Speed: 357.18 samples/sec INFO: Speed: 355.30 samples/sec INFO: Speed: 362.33 samples/sec INFO: Speed: 359.23 samples/sec INFO: Speed: 358.09 samples/sec INFO: Speed: 356.89 samples/sec INFO: Speed: 371.91 samples/sec INFO: Speed: 372.24 samples/sec INFO: Speed: 356.59 samples/sec INFO: Speed: 356.64 samples/sec INFO: Speed: 360.24 samples/sec INFO: Speed: 360.32 samples/sec INFO: Speed: 362.38 samples/sec INFO: == Epoch 021 ========== INFO: ## Training summary INFO: NLL = 1.4655 INFO: perplexity = 4.3297 INFO: time = 86.9243 seconds INFO: ## Validation summary INFO: NLL = 1.6366 INFO: perplexity = 5.1378 INFO: Saved checkpoint to 'examples/char-lstm/checkpoints/ptb-0021.params' Sampling Random Sentences After training the LSTM, we can now sample random sentences from the trained model. The sampler works in the following way: Starting from some fixed character, take a for example, and feed it as input to the LSTM. The LSTM will produce an output distribution over the vocabulary and a state in the first time step. We sample a character from the output distribution, fix it as the second character. In the next time step, we feed the previously sampled character as input and continue running the LSTM by also taking the previous states (instead of the 0 initial states). Continue running until we sampled enough characters. Note we are running with mini-batches, so several sentences could be sampled simultaneously. Here are some sampled outputs from a network I trained for around half an hour on the Shakespeare dataset. Note all the line-breaks, punctuations and upper-lower case letters are produced by the sampler itself. I did not do any post-processing. ## Sample 1 all have sir, Away will fill'd in His time, I'll keep her, do not madam, if they here? Some more ha? ## Sample 2 am. CLAUDIO: Hone here, let her, the remedge, and I know not slept a likely, thou some soully free? ## Sample 3 arrel which noble thing The exchnachsureding worns: I ne'er drunken Biancas, fairer, than the lawfu? ## Sample 4 augh assalu, you'ld tell me corn; Farew. First, for me of a loved. Has thereat I knock you presents? ## Sample 5 ame the first answer. MARIZARINIO: Door of Angelo as her lord, shrield liken Here fellow the fool ? ## Sample 6 ad well. CLAUDIO: Soon him a fellows here; for her fine edge in a bogms' lord's wife. LUCENTIO: I? ## Sample 7 adrezilian measure. LUCENTIO: So, help'd you hath nes have a than dream's corn, beautio, I perchas? ## Sample 8 as eatter me; The girlly: and no other conciolation! BISTRUMIO: I have be rest girl. O, that I a h? ## Sample 9 and is intend you sort: What held her all 'clama's for maffice. Some servant.' what I say me the cu? ## Sample 10 an thoughts will said in our pleasue, Not scanin on him that you live; believaries she. ISABELLLLL? See Andrej Karpathy's blog post on more examples and links including Linux source codes, Algebraic Geometry Theorems, and even cooking recipes. The code for sampling can be found in examples/char-lstm/sampler.jl . Visualizing the LSTM Finally, you could visualize the LSTM by calling to_graphviz on the constructed LSTM symbolic architecture. We only show an example of 1-layer and 2-time-step LSTM below. The automatic layout produced by GraphViz is definitely much less clear than Christopher Olah's illustrations , but could otherwise be very useful for debugging. As we can see, the LSTM unfolded over time is just a (very) deep neural network. The complete code for producing this visualization can be found in examples/char-lstm/visualize.jl .","title":"Generating Random Sentence with LSTM RNN"},{"location":"tutorial/char-lstm/#generating-random-sentence-with-lstm-rnn","text":"This tutorial shows how to train a LSTM (Long short-term memory) RNN (recurrent neural network) to perform character-level sequence training and prediction. The original model, usually called char-rnn is described in Andrej Karpathy's blog , with a reference implementation in Torch available here . Because MXNet.jl does not have a specialized model for recurrent neural networks yet, the example shown here is an implementation of LSTM by using the default FeedForward model via explicitly unfolding over time. We will be using fixed-length input sequence for training. The code is adapted from the char-rnn example for MXNet's Python binding , which demonstrates how to use low-level Symbolic API to build customized neural network models directly. The most important code snippets of this example is shown and explained here. To see and run the complete code, please refer to the examples/char-lstm directory. You will need to install Iterators.jl and StatsBase.jl to run this example.","title":"Generating Random Sentence with LSTM RNN"},{"location":"tutorial/char-lstm/#lstm-cells","text":"Christopher Olah has a great blog post about LSTM with beautiful and clear illustrations. So we will not repeat the definition and explanation of what an LSTM cell is here. Basically, an LSTM cell takes input x , as well as previous states (including c and h ), and produce the next states. We define a helper type to bundle the two state variables together: Because LSTM weights are shared at every time when we do explicit unfolding, so we also define a helper type to hold all the weights (and bias) for an LSTM cell for convenience. Note all the variables are of type SymbolicNode. We will construct the LSTM network as a symbolic computation graph, which is then instantiated with NDArray for actual computation. The following figure is stolen (permission requested) from Christopher Olah's blog , which illustrate exactly what the code snippet above is doing. In particular, instead of defining the four gates independently, we do the computation together and then use SliceChannel to split them into four outputs. The computation of gates are all done with the symbolic API. The return value is a LSTM state containing the output of a LSTM cell.","title":"LSTM Cells"},{"location":"tutorial/char-lstm/#unfolding-lstm","text":"Using the LSTM cell defined above, we are now ready to define a function to unfold a LSTM network with L layers and T time steps. The first part of the function is just defining all the symbolic variables for the shared weights and states. The embed_W is the weights used for character embedding \u2013- i.e. mapping the one-hot encoded characters into real vectors. The pred_W and pred_b are weights and bias for the final prediction at each time step. Then we define the weights for each LSTM cell. Note there is one cell for each layer, and it will be replicated (unrolled) over time. The states are, however, not shared over time. Instead, here we define the initial states here at the beginning of a sequence, and we will update them with the output states at each time step as we explicitly unroll the LSTM. Unrolling over time is a straightforward procedure of stacking the embedding layer, and then LSTM cells, on top of which the prediction layer. During unrolling, we update the states and collect all the outputs. Note each time step takes data and label as inputs. If the LSTM is named as :ptb , the data and label at step t will be named :ptb_data_$t and :ptb_label_$t . Late on when we prepare the data, we will define the data provider to match those names. Note at each time step, the prediction is connected to a SoftmaxOutput operator, which could back propagate when corresponding labels are provided. The states are then connected to the next time step, which allows back propagate through time. However, at the end of the sequence, the final states are not connected to anything. This dangling outputs is problematic, so we explicitly connect each of them to a BlockGrad operator, which simply back propagates 0-gradient and closes the computation graph. In the end, we just group all the prediction outputs at each time step as a single SymbolicNode and return. Optionally we will also group the final states, this is used when we use the trained LSTM to sample sentences.","title":"Unfolding LSTM"},{"location":"tutorial/char-lstm/#data-provider-for-text-sequences","text":"Now we need to construct a data provider that takes a text file, divide the text into mini-batches of fixed-length character-sequences, and provide them as one-hot encoded vectors. Note the is no fancy feature extraction at all. Each character is simply encoded as a one-hot vector: a 0-1 vector of the size given by the vocabulary. Here we just construct the vocabulary by collecting all the unique characters in the training text \u2013 there are not too many of them (including punctuations and whitespace) for English text. Each input character is then encoded as a vector of 0s on all coordinates, and 1 on the coordinate corresponding to that character. The character-to-coordinate mapping is giving by the vocabulary. The text sequence data provider implements the Data Providers api. We define the CharSeqProvider as below: The provided data and labels follow the naming convention of inputs used when unrolling the LSTM. Note in the code below, apart from $name_data_$t and $name_label_$t , we also provides the initial c and h states for each layer. This is because we are using the high-level FeedForward API, which has no idea about time and states. So we will feed the initial states for each sequence from the data provider. Since the initial states is always zero, we just need to always provide constant zero blobs. Next we implement the eachbatch method from the mx.AbstractDataProvider interface for the provider. We start by defining the data and label arrays, and the DataBatch object we will provide in each iteration. The actual data providing iteration is implemented as a Julia coroutine . In this way, we can write the data loading logic as a simple coherent for loop, and do not need to implement the interface functions like Base.start, Base.next, etc. Basically, we partition the text into batches, each batch containing several contiguous text sequences. Note at each time step, the LSTM is trained to predict the next character, so the label is the same as the data, but shifted ahead by one index.","title":"Data Provider for Text Sequences"},{"location":"tutorial/char-lstm/#training-the-lstm","text":"Now we have implemented all the supporting infrastructures for our char-lstm. To train the model, we just follow the standard high-level API. Firstly, we construct a LSTM symbolic architecture: Note all the parameters are defined in examples/char-lstm/config.jl . Now we load the text file and define the data provider. The data input.txt we used in this example is a tiny Shakespeare dataset . But you can try with other text files. The last step is to construct a model, an optimizer and fit the mode to the data. We are using the ADAM optimizer [Adam]_ in this example. Note we are also using a customized NLL evaluation metric, which calculate the negative log-likelihood during training. Here is an output sample at the end of the training process. ... INFO: Speed: 357.72 samples/sec INFO: == Epoch 020 ========== INFO: ## Training summary INFO: NLL = 1.4672 INFO: perplexity = 4.3373 INFO: time = 87.2631 seconds INFO: ## Validation summary INFO: NLL = 1.6374 INFO: perplexity = 5.1418 INFO: Saved checkpoint to 'char-lstm/checkpoints/ptb-0020.params' INFO: Speed: 368.74 samples/sec INFO: Speed: 361.04 samples/sec INFO: Speed: 360.02 samples/sec INFO: Speed: 362.34 samples/sec INFO: Speed: 360.80 samples/sec INFO: Speed: 362.77 samples/sec INFO: Speed: 357.18 samples/sec INFO: Speed: 355.30 samples/sec INFO: Speed: 362.33 samples/sec INFO: Speed: 359.23 samples/sec INFO: Speed: 358.09 samples/sec INFO: Speed: 356.89 samples/sec INFO: Speed: 371.91 samples/sec INFO: Speed: 372.24 samples/sec INFO: Speed: 356.59 samples/sec INFO: Speed: 356.64 samples/sec INFO: Speed: 360.24 samples/sec INFO: Speed: 360.32 samples/sec INFO: Speed: 362.38 samples/sec INFO: == Epoch 021 ========== INFO: ## Training summary INFO: NLL = 1.4655 INFO: perplexity = 4.3297 INFO: time = 86.9243 seconds INFO: ## Validation summary INFO: NLL = 1.6366 INFO: perplexity = 5.1378 INFO: Saved checkpoint to 'examples/char-lstm/checkpoints/ptb-0021.params'","title":"Training the LSTM"},{"location":"tutorial/char-lstm/#sampling-random-sentences","text":"After training the LSTM, we can now sample random sentences from the trained model. The sampler works in the following way: Starting from some fixed character, take a for example, and feed it as input to the LSTM. The LSTM will produce an output distribution over the vocabulary and a state in the first time step. We sample a character from the output distribution, fix it as the second character. In the next time step, we feed the previously sampled character as input and continue running the LSTM by also taking the previous states (instead of the 0 initial states). Continue running until we sampled enough characters. Note we are running with mini-batches, so several sentences could be sampled simultaneously. Here are some sampled outputs from a network I trained for around half an hour on the Shakespeare dataset. Note all the line-breaks, punctuations and upper-lower case letters are produced by the sampler itself. I did not do any post-processing. ## Sample 1 all have sir, Away will fill'd in His time, I'll keep her, do not madam, if they here? Some more ha? ## Sample 2 am. CLAUDIO: Hone here, let her, the remedge, and I know not slept a likely, thou some soully free? ## Sample 3 arrel which noble thing The exchnachsureding worns: I ne'er drunken Biancas, fairer, than the lawfu? ## Sample 4 augh assalu, you'ld tell me corn; Farew. First, for me of a loved. Has thereat I knock you presents? ## Sample 5 ame the first answer. MARIZARINIO: Door of Angelo as her lord, shrield liken Here fellow the fool ? ## Sample 6 ad well. CLAUDIO: Soon him a fellows here; for her fine edge in a bogms' lord's wife. LUCENTIO: I? ## Sample 7 adrezilian measure. LUCENTIO: So, help'd you hath nes have a than dream's corn, beautio, I perchas? ## Sample 8 as eatter me; The girlly: and no other conciolation! BISTRUMIO: I have be rest girl. O, that I a h? ## Sample 9 and is intend you sort: What held her all 'clama's for maffice. Some servant.' what I say me the cu? ## Sample 10 an thoughts will said in our pleasue, Not scanin on him that you live; believaries she. ISABELLLLL? See Andrej Karpathy's blog post on more examples and links including Linux source codes, Algebraic Geometry Theorems, and even cooking recipes. The code for sampling can be found in examples/char-lstm/sampler.jl .","title":"Sampling Random Sentences"},{"location":"tutorial/char-lstm/#visualizing-the-lstm","text":"Finally, you could visualize the LSTM by calling to_graphviz on the constructed LSTM symbolic architecture. We only show an example of 1-layer and 2-time-step LSTM below. The automatic layout produced by GraphViz is definitely much less clear than Christopher Olah's illustrations , but could otherwise be very useful for debugging. As we can see, the LSTM unfolded over time is just a (very) deep neural network. The complete code for producing this visualization can be found in examples/char-lstm/visualize.jl .","title":"Visualizing the LSTM"},{"location":"tutorial/mnist/","text":"Digit Recognition on MNIST In this tutorial, we will work through examples of training a simple multi-layer perceptron and then a convolutional neural network (the LeNet architecture) on the MNIST handwritten digit dataset . The code for this tutorial could be found in examples/mnist . There are also two Jupyter notebooks that expand a little more on the MLP and the LeNet , using the more general ArrayDataProvider . Simple 3-layer MLP This is a tiny 3-layer MLP that could be easily trained on CPU. The script starts with using MXNet to load the MXNet module. Then we are ready to define the network architecture via the symbolic API . We start with a placeholder data symbol, data = mx.Variable(:data) and then cascading fully-connected layers and activation functions: fc1 = mx.FullyConnected(data, name=:fc1, num_hidden=128) act1 = mx.Activation(fc1, name=:relu1, act_type=:relu) fc2 = mx.FullyConnected(act1, name=:fc2, num_hidden=64) act2 = mx.Activation(fc2, name=:relu2, act_type=:relu) fc3 = mx.FullyConnected(act2, name=:fc3, num_hidden=10) Note each composition we take the previous symbol as the first argument, forming a feedforward chain. The architecture looks like Input -- 128 units (ReLU) -- 64 units (ReLU) -- 10 units where the last 10 units correspond to the 10 output classes (digits 0,...,9). We then add a final SoftmaxOutput operation to turn the 10-dimensional prediction to proper probability values for the 10 classes: mlp = mx.SoftmaxOutput(fc3, name=:softmax) As we can see, the MLP is just a chain of layers. For this case, we can also use the mx.chain macro. The same architecture above can be defined as mlp = @mx.chain mx.Variable(:data) = mx.FullyConnected(name=:fc1, num_hidden=128) = mx.Activation(name=:relu1, act_type=:relu) = mx.FullyConnected(name=:fc2, num_hidden=64) = mx.Activation(name=:relu2, act_type=:relu) = mx.FullyConnected(name=:fc3, num_hidden=10) = mx.SoftmaxOutput(name=:softmax) After defining the architecture, we are ready to load the MNIST data. MXNet.jl provide built-in data providers for the MNIST dataset, which could automatically download the dataset into Pkg.dir(\"MXNet\")/data/mnist if necessary. We wrap the code to construct the data provider into mnist-data.jl so that it could be shared by both the MLP example and the LeNet ConvNets example. batch_size = 100 include( mnist-data.jl ) train_provider, eval_provider = get_mnist_providers(batch_size) If you need to write your own data providers for customized data format, please refer to mx.AbstractDataProvider . Given the architecture and data, we can instantiate an model to do the actual training. mx.FeedForward is the built-in model that is suitable for most feed-forward architectures. When constructing the model, we also specify the context on which the computation should be carried out. Because this is a really tiny MLP, we will just run on a single CPU device. model = mx.FeedForward(mlp, context=mx.cpu()) You can use a mx.gpu() or if a list of devices (e.g. [mx.gpu(0), mx.gpu(1)] ) is provided, data-parallelization will be used automatically. But for this tiny example, using a GPU device might not help. The last thing we need to specify is the optimization algorithm (a.k.a. optimizer ) to use. We use the basic SGD with a fixed learning rate 0.1 , momentum 0.9 and weight decay 0.00001: optimizer = mx.SGD(\u03b7=0.1, \u03bc=0.9, \u03bb=0.00001) Now we can do the training. Here the n_epoch parameter specifies that we want to train for 20 epochs. We also supply a eval_data to monitor validation accuracy on the validation set. mx.fit(model, optimizer, train_provider, n_epoch=20, eval_data=eval_provider) Here is a sample output INFO: Start training on [CPU0] INFO: Initializing parameters... INFO: Creating KVStore... INFO: == Epoch 001 ========== INFO: ## Training summary INFO: :accuracy = 0.7554 INFO: time = 1.3165 seconds INFO: ## Validation summary INFO: :accuracy = 0.9502 ... INFO: == Epoch 020 ========== INFO: ## Training summary INFO: :accuracy = 0.9949 INFO: time = 0.9287 seconds INFO: ## Validation summary INFO: :accuracy = 0.9775 Convolutional Neural Networks In the second example, we show a slightly more complicated architecture that involves convolution and pooling. This architecture for the MNIST is usually called the [LeNet]_. The first part of the architecture is listed below: # input data = mx.Variable(:data) # first conv conv1 = @mx.chain mx.Convolution(data, kernel=(5,5), num_filter=20) = mx.Activation(act_type=:tanh) = mx.Pooling(pool_type=:max, kernel=(2,2), stride=(2,2)) # second conv conv2 = @mx.chain mx.Convolution(conv1, kernel=(5,5), num_filter=50) = mx.Activation(act_type=:tanh) = mx.Pooling(pool_type=:max, kernel=(2,2), stride=(2,2)) We basically defined two convolution modules. Each convolution module is actually a chain of Convolution , tanh activation and then max Pooling operations. Each sample in the MNIST dataset is a 28x28 single-channel grayscale image. In the tensor format used by NDArray , a batch of 100 samples is a tensor of shape (28,28,1,100) . The convolution and pooling operates in the spatial axis, so kernel=(5,5) indicate a square region of 5-width and 5-height. The rest of the architecture follows as: # first fully-connected fc1 = @mx.chain mx.Flatten(conv2) = mx.FullyConnected(num_hidden=500) = mx.Activation(act_type=:tanh) # second fully-connected fc2 = mx.FullyConnected(fc1, num_hidden=10) # softmax loss lenet = mx.Softmax(fc2, name=:softmax) Note a fully-connected operator expects the input to be a matrix. However, the results from spatial convolution and pooling are 4D tensors. So we explicitly used a Flatten operator to flat the tensor, before connecting it to the FullyConnected operator. The rest of the network is the same as the previous MLP example. As before, we can now load the MNIST dataset: batch_size = 100 include( mnist-data.jl ) train_provider, eval_provider = get_mnist_providers(batch_size; flat=false) Note we specified flat=false to tell the data provider to provide 4D tensors instead of 2D matrices because the convolution operators needs correct spatial shape information. We then construct a feedforward model on GPU, and train it. # fit model model = mx.FeedForward(lenet, context=mx.gpu()) # optimizer optimizer = mx.SGD(\u03b7=0.05, \u03bc=0.9, \u03bb=0.00001) # fit parameters mx.fit(model, optimizer, train_provider, n_epoch=20, eval_data=eval_provider) And here is a sample of running outputs: INFO: == Epoch 001 ========== INFO: ## Training summary INFO: :accuracy = 0.6750 INFO: time = 4.9814 seconds INFO: ## Validation summary INFO: :accuracy = 0.9712 ... INFO: == Epoch 020 ========== INFO: ## Training summary INFO: :accuracy = 1.0000 INFO: time = 4.0086 seconds INFO: ## Validation summary INFO: :accuracy = 0.9915 Predicting with a trained model Predicting with a trained model is very simple. By calling mx.predict with the model and a data provider, we get the model output as a Julia Array: probs = mx.predict(model, eval_provider) The following code shows a stupid way of getting all the labels from the data provider, and compute the prediction accuracy manually: # collect all labels from eval data labels = reduce( vcat, copy(mx.get(eval_provider, batch, :softmax_label)) for batch \u2208 eval_provider) # labels are 0...9 labels .= labels .+ 1 # Now we use compute the accuracy pred = map(i - argmax(probs[1:10, i]), 1:size(probs, 2)) correct = sum(pred .== labels) @printf Accuracy on eval set: %.2f%%\\n 100correct/length(labels) Alternatively, when the dataset is huge, one can provide a callback to mx.predict , then the callback function will be invoked with the outputs of each mini-batch. The callback could, for example, write the data to disk for future inspection. In this case, no value is returned from mx.predict . See also predict.","title":"Digit Recognition on MNIST"},{"location":"tutorial/mnist/#digit-recognition-on-mnist","text":"In this tutorial, we will work through examples of training a simple multi-layer perceptron and then a convolutional neural network (the LeNet architecture) on the MNIST handwritten digit dataset . The code for this tutorial could be found in examples/mnist . There are also two Jupyter notebooks that expand a little more on the MLP and the LeNet , using the more general ArrayDataProvider .","title":"Digit Recognition on MNIST"},{"location":"tutorial/mnist/#simple-3-layer-mlp","text":"This is a tiny 3-layer MLP that could be easily trained on CPU. The script starts with using MXNet to load the MXNet module. Then we are ready to define the network architecture via the symbolic API . We start with a placeholder data symbol, data = mx.Variable(:data) and then cascading fully-connected layers and activation functions: fc1 = mx.FullyConnected(data, name=:fc1, num_hidden=128) act1 = mx.Activation(fc1, name=:relu1, act_type=:relu) fc2 = mx.FullyConnected(act1, name=:fc2, num_hidden=64) act2 = mx.Activation(fc2, name=:relu2, act_type=:relu) fc3 = mx.FullyConnected(act2, name=:fc3, num_hidden=10) Note each composition we take the previous symbol as the first argument, forming a feedforward chain. The architecture looks like Input -- 128 units (ReLU) -- 64 units (ReLU) -- 10 units where the last 10 units correspond to the 10 output classes (digits 0,...,9). We then add a final SoftmaxOutput operation to turn the 10-dimensional prediction to proper probability values for the 10 classes: mlp = mx.SoftmaxOutput(fc3, name=:softmax) As we can see, the MLP is just a chain of layers. For this case, we can also use the mx.chain macro. The same architecture above can be defined as mlp = @mx.chain mx.Variable(:data) = mx.FullyConnected(name=:fc1, num_hidden=128) = mx.Activation(name=:relu1, act_type=:relu) = mx.FullyConnected(name=:fc2, num_hidden=64) = mx.Activation(name=:relu2, act_type=:relu) = mx.FullyConnected(name=:fc3, num_hidden=10) = mx.SoftmaxOutput(name=:softmax) After defining the architecture, we are ready to load the MNIST data. MXNet.jl provide built-in data providers for the MNIST dataset, which could automatically download the dataset into Pkg.dir(\"MXNet\")/data/mnist if necessary. We wrap the code to construct the data provider into mnist-data.jl so that it could be shared by both the MLP example and the LeNet ConvNets example. batch_size = 100 include( mnist-data.jl ) train_provider, eval_provider = get_mnist_providers(batch_size) If you need to write your own data providers for customized data format, please refer to mx.AbstractDataProvider . Given the architecture and data, we can instantiate an model to do the actual training. mx.FeedForward is the built-in model that is suitable for most feed-forward architectures. When constructing the model, we also specify the context on which the computation should be carried out. Because this is a really tiny MLP, we will just run on a single CPU device. model = mx.FeedForward(mlp, context=mx.cpu()) You can use a mx.gpu() or if a list of devices (e.g. [mx.gpu(0), mx.gpu(1)] ) is provided, data-parallelization will be used automatically. But for this tiny example, using a GPU device might not help. The last thing we need to specify is the optimization algorithm (a.k.a. optimizer ) to use. We use the basic SGD with a fixed learning rate 0.1 , momentum 0.9 and weight decay 0.00001: optimizer = mx.SGD(\u03b7=0.1, \u03bc=0.9, \u03bb=0.00001) Now we can do the training. Here the n_epoch parameter specifies that we want to train for 20 epochs. We also supply a eval_data to monitor validation accuracy on the validation set. mx.fit(model, optimizer, train_provider, n_epoch=20, eval_data=eval_provider) Here is a sample output INFO: Start training on [CPU0] INFO: Initializing parameters... INFO: Creating KVStore... INFO: == Epoch 001 ========== INFO: ## Training summary INFO: :accuracy = 0.7554 INFO: time = 1.3165 seconds INFO: ## Validation summary INFO: :accuracy = 0.9502 ... INFO: == Epoch 020 ========== INFO: ## Training summary INFO: :accuracy = 0.9949 INFO: time = 0.9287 seconds INFO: ## Validation summary INFO: :accuracy = 0.9775","title":"Simple 3-layer MLP"},{"location":"tutorial/mnist/#convolutional-neural-networks","text":"In the second example, we show a slightly more complicated architecture that involves convolution and pooling. This architecture for the MNIST is usually called the [LeNet]_. The first part of the architecture is listed below: # input data = mx.Variable(:data) # first conv conv1 = @mx.chain mx.Convolution(data, kernel=(5,5), num_filter=20) = mx.Activation(act_type=:tanh) = mx.Pooling(pool_type=:max, kernel=(2,2), stride=(2,2)) # second conv conv2 = @mx.chain mx.Convolution(conv1, kernel=(5,5), num_filter=50) = mx.Activation(act_type=:tanh) = mx.Pooling(pool_type=:max, kernel=(2,2), stride=(2,2)) We basically defined two convolution modules. Each convolution module is actually a chain of Convolution , tanh activation and then max Pooling operations. Each sample in the MNIST dataset is a 28x28 single-channel grayscale image. In the tensor format used by NDArray , a batch of 100 samples is a tensor of shape (28,28,1,100) . The convolution and pooling operates in the spatial axis, so kernel=(5,5) indicate a square region of 5-width and 5-height. The rest of the architecture follows as: # first fully-connected fc1 = @mx.chain mx.Flatten(conv2) = mx.FullyConnected(num_hidden=500) = mx.Activation(act_type=:tanh) # second fully-connected fc2 = mx.FullyConnected(fc1, num_hidden=10) # softmax loss lenet = mx.Softmax(fc2, name=:softmax) Note a fully-connected operator expects the input to be a matrix. However, the results from spatial convolution and pooling are 4D tensors. So we explicitly used a Flatten operator to flat the tensor, before connecting it to the FullyConnected operator. The rest of the network is the same as the previous MLP example. As before, we can now load the MNIST dataset: batch_size = 100 include( mnist-data.jl ) train_provider, eval_provider = get_mnist_providers(batch_size; flat=false) Note we specified flat=false to tell the data provider to provide 4D tensors instead of 2D matrices because the convolution operators needs correct spatial shape information. We then construct a feedforward model on GPU, and train it. # fit model model = mx.FeedForward(lenet, context=mx.gpu()) # optimizer optimizer = mx.SGD(\u03b7=0.05, \u03bc=0.9, \u03bb=0.00001) # fit parameters mx.fit(model, optimizer, train_provider, n_epoch=20, eval_data=eval_provider) And here is a sample of running outputs: INFO: == Epoch 001 ========== INFO: ## Training summary INFO: :accuracy = 0.6750 INFO: time = 4.9814 seconds INFO: ## Validation summary INFO: :accuracy = 0.9712 ... INFO: == Epoch 020 ========== INFO: ## Training summary INFO: :accuracy = 1.0000 INFO: time = 4.0086 seconds INFO: ## Validation summary INFO: :accuracy = 0.9915","title":"Convolutional Neural Networks"},{"location":"tutorial/mnist/#predicting-with-a-trained-model","text":"Predicting with a trained model is very simple. By calling mx.predict with the model and a data provider, we get the model output as a Julia Array: probs = mx.predict(model, eval_provider) The following code shows a stupid way of getting all the labels from the data provider, and compute the prediction accuracy manually: # collect all labels from eval data labels = reduce( vcat, copy(mx.get(eval_provider, batch, :softmax_label)) for batch \u2208 eval_provider) # labels are 0...9 labels .= labels .+ 1 # Now we use compute the accuracy pred = map(i - argmax(probs[1:10, i]), 1:size(probs, 2)) correct = sum(pred .== labels) @printf Accuracy on eval set: %.2f%%\\n 100correct/length(labels) Alternatively, when the dataset is huge, one can provide a callback to mx.predict , then the callback function will be invoked with the outputs of each mini-batch. The callback could, for example, write the data to disk for future inspection. In this case, no value is returned from mx.predict . See also predict.","title":"Predicting with a trained model"},{"location":"user-guide/faq/","text":"FAQ Running MXNet on AWS GPU instances See the discussions and notes here .","title":"FAQ"},{"location":"user-guide/faq/#faq","text":"","title":"FAQ"},{"location":"user-guide/faq/#running-mxnet-on-aws-gpu-instances","text":"See the discussions and notes here .","title":"Running MXNet on AWS GPU instances"},{"location":"user-guide/install/","text":"Installation Guide Automatic Installation To install MXNet.jl, simply type Pkg.add( MXNet ) In the Julia REPL. Or to use the latest git version of MXNet.jl, use the following command instead Pkg.checkout( MXNet ) MXNet.jl is built on top of libmxnet . Upon installation, Julia will try to automatically download and build libmxnet. There are several environment variables that change this behaviour. MXNET_HOME : If you already have a pre-installed version of mxnet you can use MXNET_HOME to point the build-process in the right direction. CUDA_HOME : If the automatic cuda detection fails you can also set CUDA_HOME to override the process. MXNET_COMMIT : To control which version of libmxnet will be compiled, you can use the MXNET_COMMIT variable to point to either a version tag (e.g. v0.10.0 ), a branch name (e.g. master ) or a specific commit hash (e.g. a0b1c2d3 ). CC : The path of C compiler. CXX : The path of C++ compiler. ADD_CFLAGS : Additional C flags. For instance, if you need to point non-standard include directory, please set it as ENV[\"ADD_CFLAGS\"] = \"-I'/path/to/include/dir'\" . ADD_LDFLAGS : Additional linker flags. USE_JEMALLOC : Default is enabled if jemalloc available. If you ran into segfault cause by jemalloc, Please try to disable it. ```julia first remove whole libmxnet source: Pkg.dir(\"MXNet\", \"deps\", \"src\") ENV[\"USE_JEMALLOC\"] = \"0\" Pkg.build(\"MXNet\") ``` The libmxnet source is downloaded to Pkg.dir(\"MXNet\", \"deps\", \"src\", \"mxnet\") . The automatic build is using default configurations, with OpenCV disabled. If the compilation failed due to unresolved dependency, or if you want to customize the build, you can compile and install libmxnet manually. Please see below for more details. Manual Compilation It is possible to compile libmxnet separately and point MXNet.jl to a existing library in case automatic compilation fails due to unresolved dependencies in an non-standard environment; Or when one want to work with a separate, maybe customized libmxnet. To build libmxnet, please refer to the installation guide of libmxnet . After successfully installing libmxnet, set the MXNET_HOME environment variable to the location of libmxnet. In other words, the compiled libmxnet.so should be found in $MXNET_HOME/lib . note The constant MXNET_HOME is pre-compiled in MXNet.jl package cache. If you updated the environment variable after installing MXNet.jl, make sure to update the pre-compilation cache by Base.compilecache(\"MXNet\") . When the MXNET_HOME environment variable is detected and the corresponding libmxnet.so could be loaded successfully, MXNet.jl will skip automatic building during installation and use the specified libmxnet instead. Basically, MXNet.jl will search libmxnet.so or libmxnet.dll in the following paths (and in that order): $MXNET_HOME/lib : customized libmxnet builds Pkg.dir(\"MXNet\", \"deps\", \"usr\", \"lib\") : automatic builds Any system wide library search path Note that MXNet.jl can not load libmxnet.so even if it is on one of the paths above in case a library it depends upon is missing from the LD_LIBRARY_PATH . Thus, if you are going to compile to add CUDA, the path to the CUDA libraries will have to be added to LD_LIBRARY_PATH .","title":"Installation Guide"},{"location":"user-guide/install/#installation-guide","text":"","title":"Installation Guide"},{"location":"user-guide/install/#automatic-installation","text":"To install MXNet.jl, simply type Pkg.add( MXNet ) In the Julia REPL. Or to use the latest git version of MXNet.jl, use the following command instead Pkg.checkout( MXNet ) MXNet.jl is built on top of libmxnet . Upon installation, Julia will try to automatically download and build libmxnet. There are several environment variables that change this behaviour. MXNET_HOME : If you already have a pre-installed version of mxnet you can use MXNET_HOME to point the build-process in the right direction. CUDA_HOME : If the automatic cuda detection fails you can also set CUDA_HOME to override the process. MXNET_COMMIT : To control which version of libmxnet will be compiled, you can use the MXNET_COMMIT variable to point to either a version tag (e.g. v0.10.0 ), a branch name (e.g. master ) or a specific commit hash (e.g. a0b1c2d3 ). CC : The path of C compiler. CXX : The path of C++ compiler. ADD_CFLAGS : Additional C flags. For instance, if you need to point non-standard include directory, please set it as ENV[\"ADD_CFLAGS\"] = \"-I'/path/to/include/dir'\" . ADD_LDFLAGS : Additional linker flags. USE_JEMALLOC : Default is enabled if jemalloc available. If you ran into segfault cause by jemalloc, Please try to disable it. ```julia","title":"Automatic Installation"},{"location":"user-guide/install/#first-remove-whole-libmxnet-source-pkgdirmxnet-deps-src","text":"ENV[\"USE_JEMALLOC\"] = \"0\" Pkg.build(\"MXNet\") ``` The libmxnet source is downloaded to Pkg.dir(\"MXNet\", \"deps\", \"src\", \"mxnet\") . The automatic build is using default configurations, with OpenCV disabled. If the compilation failed due to unresolved dependency, or if you want to customize the build, you can compile and install libmxnet manually. Please see below for more details.","title":"first remove whole libmxnet source: Pkg.dir(\"MXNet\", \"deps\", \"src\")"},{"location":"user-guide/install/#manual-compilation","text":"It is possible to compile libmxnet separately and point MXNet.jl to a existing library in case automatic compilation fails due to unresolved dependencies in an non-standard environment; Or when one want to work with a separate, maybe customized libmxnet. To build libmxnet, please refer to the installation guide of libmxnet . After successfully installing libmxnet, set the MXNET_HOME environment variable to the location of libmxnet. In other words, the compiled libmxnet.so should be found in $MXNET_HOME/lib . note The constant MXNET_HOME is pre-compiled in MXNet.jl package cache. If you updated the environment variable after installing MXNet.jl, make sure to update the pre-compilation cache by Base.compilecache(\"MXNet\") . When the MXNET_HOME environment variable is detected and the corresponding libmxnet.so could be loaded successfully, MXNet.jl will skip automatic building during installation and use the specified libmxnet instead. Basically, MXNet.jl will search libmxnet.so or libmxnet.dll in the following paths (and in that order): $MXNET_HOME/lib : customized libmxnet builds Pkg.dir(\"MXNet\", \"deps\", \"usr\", \"lib\") : automatic builds Any system wide library search path Note that MXNet.jl can not load libmxnet.so even if it is on one of the paths above in case a library it depends upon is missing from the LD_LIBRARY_PATH . Thus, if you are going to compile to add CUDA, the path to the CUDA libraries will have to be added to LD_LIBRARY_PATH .","title":"Manual Compilation"},{"location":"user-guide/overview/","text":"Overview MXNet.jl Namespace Most the functions and types in MXNet.jl are organized in a flat namespace. Because many some functions are conflicting with existing names in the Julia Base module, we wrap them all in a mx module. The convention of accessing the MXNet.jl interface is the to use the mx. prefix explicitly: julia using MXNet julia x = mx.zeros(2, 3) # MXNet NDArray 2\u00d73 mx.NDArray{Float32} @ CPU0: 0.0 0.0 0.0 0.0 0.0 0.0 julia y = zeros(eltype(x), size(x)) # Julia Array 2\u00d73 Array{Float32,2}: 0.0 0.0 0.0 0.0 0.0 0.0 julia copy!(y, x) # Overloaded function in Julia Base 2\u00d73 Array{Float32,2}: 0.0 0.0 0.0 0.0 0.0 0.0 julia z = mx.ones(size(x), mx.gpu()) # MXNet NDArray on GPU 2\u00d73 mx.NDArray{Float32} @ GPU0: 1.0 1.0 1.0 1.0 1.0 1.0 julia mx.copy!(z, y) # Same as copy!(z, y) 2\u00d73 mx.NDArray{Float32} @ GPU0: 0.0 0.0 0.0 0.0 0.0 0.0 Note functions like size , copy! that is extensively overloaded for various types works out of the box. But functions like zeros and ones will be ambiguous, so we always use the mx. prefix. If you prefer, the mx. prefix can be used explicitly for all MXNet.jl functions, including size and copy! as shown in the last line. Low Level Interface NDArray NDArray is the basic building blocks of the actual computations in MXNet. It is like a Julia Array object, with some important differences listed here: The actual data could live on different Context (e.g. GPUs). For some contexts, iterating into the elements one by one is very slow, thus indexing into NDArray is not recommanded in general. The easiest way to inspect the contents of an NDArray is to use the copy function to copy the contents as a Julia Array . Operations on NDArray (including basic arithmetics and neural network related operators) are executed in parallel with automatic dependency tracking to ensure correctness. There is no generics in NDArray , the eltype is always mx.MX_float . Because for applications in machine learning, single precision floating point numbers are typical a best choice balancing between precision, speed and portability. Also since libmxnet is designed to support multiple languages as front-ends, it is much simpler to implement with a fixed data type. While most of the computation is hidden in libmxnet by operators corresponding to various neural network layers. Getting familiar with the NDArray API is useful for implementing Optimizer or customized operators in Julia directly. The followings are common ways to create NDArray objects: NDArray(undef, shape...; ctx = context, writable = true) : create an uninitialized array of a given shape on a specific device. For example, NDArray(undef, 2, 3) , NDArray(undef, 2, 3, ctx = mx.gpu(2)) . NDArray(undef, shape; ctx = context, writable = true) NDArray{T}(undef, shape...; ctx = context, writable = true) : create an uninitialized with the given type T . mx.zeros(shape[, context]) and mx.ones(shape[, context]) : similar to the Julia's built-in zeros and ones . mx.copy(jl_arr, context) : copy the contents of a Julia Array to a specific device. Most of the convenient functions like size , length , ndims , eltype on array objects should work out-of-the-box. Although indexing is not supported, it is possible to take slices : julia using MXNet julia a = mx.ones(2, 3) 2\u00d73 NDArray{Float32,2} @ CPU0: 1.0f0 1.0f0 1.0f0 1.0f0 1.0f0 1.0f0 julia b = mx.slice(a, 1:2) 2\u00d72 NDArray{Float32,2} @ CPU0: 1.0f0 1.0f0 1.0f0 1.0f0 julia b[:] = 2 2 julia a 2\u00d73 NDArray{Float32,2} @ CPU0: 2.0f0 2.0f0 1.0f0 2.0f0 2.0f0 1.0f0 A slice is a sub-region sharing the same memory with the original NDArray object. A slice is always a contiguous piece of memory, so only slicing on the last dimension is supported. The example above also shows a way to set the contents of an NDArray . julia using MXNet julia mx.srand(42) \u250c Warning: `mx.srand` is deprecated, use `mx.seed!` instead. \u2514 @ MXNet.mx /work/mxnet/docs/build_version_doc/apache-mxnet/v1.5.x/julia/src/random.jl:86 julia a = NDArray(undef, 2, 3) 2\u00d73 NDArray{Float32,2} @ CPU0: 1.786631f25 5.201349f-8 1.03047764f21 6.891884f34 4.2426297f-8 1.8058751f28 julia a[:] = 0.5 # set all elements to a scalar 0.5 julia a[:] = rand(size(a)) # set contents with a Julia Array ERROR: rand(rng, dims) is discontinued; try rand(rng, Float64, dims) julia copy!(a, rand(size(a))) # set value by copying a Julia Array ERROR: rand(rng, dims) is discontinued; try rand(rng, Float64, dims) julia b = NDArray(undef, size(a)) 2\u00d73 NDArray{Float32,2} @ CPU0: 1.786631f25 5.201349f-8 1.03047764f21 6.891884f34 6.8627133f-7 1.8058751f28 julia b[:] = a # copying and assignment between NDArrays 2\u00d73 NDArray{Float32,2} @ CPU0: 0.5f0 0.5f0 0.5f0 0.5f0 0.5f0 0.5f0 Note due to the intrinsic design of the Julia language, a normal assignment a = b does not mean copying the contents of b to a . Instead, it just make the variable a pointing to a new object, which is b . Similarly, inplace arithmetics does not work as expected: julia using MXNet julia a = mx.ones(2) 2-element NDArray{Float32,1} @ CPU0: 1.0f0 1.0f0 julia r = a # keep a reference to a 2-element NDArray{Float32,1} @ CPU0: 1.0f0 1.0f0 julia b = mx.ones(2) 2-element NDArray{Float32,1} @ CPU0: 1.0f0 1.0f0 julia a += b # translates to a = a + b 2-element NDArray{Float32,1} @ CPU0: 2.0f0 2.0f0 julia a 2-element NDArray{Float32,1} @ CPU0: 2.0f0 2.0f0 julia r 2-element NDArray{Float32,1} @ CPU0: 1.0f0 1.0f0 As we can see, a has expected value, but instead of inplace updating, a new NDArray is created and a is set to point to this new object. If we look at r , which still reference to the old a , its content has not changed. There is currently no way in Julia to overload the operators like += to get customized behavior. Instead, you will need to write a[:] = a + b , or if you want real inplace += operation, MXNet.jl provides a simple macro @mx.inplace : julia @mx.inplace a += b 2-element NDArray{Float32,1} @ CPU0: 3.0f0 3.0f0 julia macroexpand(:(@mx.inplace a += b)) ERROR: MethodError: no method matching macroexpand(::Expr) Closest candidates are: macroexpand(!Matched::Module, !Matched::Any; recursive) at expr.jl:91 As we can see, it translate the += operator to an explicit add_to! function call, which invokes into libmxnet to add the contents of b into a directly. For example, the following is the update rule in the SGD Optimizer (both gradient \u2207 and weight W are NDArray objects): @inplace W .+= -\u03b7 .* (\u2207 + \u03bb .* W) Note there is no much magic in mx.inplace : it only does a shallow translation. In the SGD update rule example above, the computation like scaling the gradient by grad_scale and adding the weight decay all create temporary NDArray objects. To mitigate this issue, libmxnet has a customized memory allocator designed specifically to handle this kind of situations. The following snippet does a simple benchmark on allocating temp NDArray vs. pre-allocating: using Benchmark using MXNet N_REP = 1000 SHAPE = (128, 64) CTX = mx.cpu() LR = 0.1 function inplace_op() weight = mx.zeros(SHAPE, CTX) grad = mx.ones(SHAPE, CTX) # pre-allocate temp objects grad_lr = NDArray(undef, SHAPE, ctx = CTX) for i = 1:N_REP copy!(grad_lr, grad) @mx.inplace grad_lr .*= LR @mx.inplace weight -= grad_lr end return weight end function normal_op() weight = mx.zeros(SHAPE, CTX) grad = mx.ones(SHAPE, CTX) for i = 1:N_REP weight[:] -= LR * grad end return weight end # make sure the results are the same @assert(maximum(abs(copy(normal_op() - inplace_op()))) 1e-6) println(compare([inplace_op, normal_op], 100)) The comparison on my laptop shows that normal_op while allocating a lot of temp NDArray in the loop (the performance gets worse when increasing N_REP ), is only about twice slower than the pre-allocated one. Row Function Average Relative Replications 1 \"inplace_op\" 0.0074854 1.0 100 2 \"normal_op\" 0.0174202 2.32723 100 So it will usually not be a big problem unless you are at the bottleneck of the computation. Distributed Key-value Store The type KVStore and related methods are used for data sharing across different devices or machines. It provides a simple and efficient integer - NDArray key-value storage system that each device can pull or push. The following example shows how to create a local KVStore , initialize a value and then pull it back. kv = mx.KVStore(:local) shape = (2, 3) key = 3 mx.init!(kv, key, mx.ones(shape) * 2) a = NDArray(undef, shape) mx.pull!(kv, key, a) # pull value into a a 2\u00d73 NDArray{Float32,2} @ CPU0: 2.0f0 2.0f0 2.0f0 2.0f0 2.0f0 2.0f0 Intermediate Level Interface Symbols and Composition The way we build deep learning models in MXNet.jl is to use the powerful symbolic composition system. It is like Theano , except that we avoided long expression compilation time by providing larger neural network related building blocks to guarantee computation performance. See also this note for the design and trade-off of the MXNet symbolic composition system. The basic type is mx.SymbolicNode . The following is a trivial example of composing two symbols with the + operation. ```@example sym1 A = mx.Variable(:A) B = mx.Variable(:B) C = A + B print(C) # debug printing We get a new `SymbolicNode` by composing existing `SymbolicNode`s by some *operations*. A hierarchical architecture of a deep neural network could be realized by recursive composition. For example, the following code snippet shows a simple 2-layer MLP construction, using a hidden layer of 128 units and a `ReLU` activation function. ```@example fcnet net = mx.Variable(:data) net = mx.FullyConnected(net, name=:fc1, num_hidden=128) net = mx.Activation(net, name=:relu1, act_type=:relu) net = mx.FullyConnected(net, name=:fc2, num_hidden=64) net = mx.SoftmaxOutput(net, name=:out) print(net) # debug printing Each time we take the previous symbol, and compose with an operation. Unlike the simple + example above, the operations here are \"bigger\" ones, that correspond to common computation layers in deep neural networks. Each of those operation takes one or more input symbols for composition, with optional hyper-parameters (e.g. num_hidden , act_type ) to further customize the composition results. When applying those operations, we can also specify a name for the result symbol. This is convenient if we want to refer to this symbol later on. If not supplied, a name will be automatically generated. Each symbol takes some arguments. For example, in the + case above, to compute the value of C , we will need to know the values of the two inputs A and B . For neural networks, the arguments are primarily two categories: inputs and parameters . inputs are data and labels for the networks, while parameters are typically trainable weights , bias , filters . When composing symbols, their arguments accumulates. We can list all the arguments by mx.list_arguments(net) 6-element Array{Symbol,1}: :data :fc1_weight :fc1_bias :fc2_weight :fc2_bias :out_label Note the names of the arguments are generated according to the provided name for each layer. We can also specify those names explicitly: julia using MXNet julia net = mx.Variable(:data) SymbolicNode data julia w = mx.Variable(:myweight) SymbolicNode myweight julia net = mx.FullyConnected(net, weight=w, name=:fc1, num_hidden=128) SymbolicNode fc1 julia mx.list_arguments(net) 3-element Array{Symbol,1}: :data :myweight :fc1_bias The simple fact is that a Variable is just a placeholder mx.SymbolicNode . In composition, we can use arbitrary symbols for arguments. For example: julia using MXNet julia net = mx.Variable(:data) SymbolicNode data julia net = mx.FullyConnected(net, name=:fc1, num_hidden=128) SymbolicNode fc1 julia net2 = mx.Variable(:data2) SymbolicNode data2 julia net2 = mx.FullyConnected(net2, name=:net2, num_hidden=128) SymbolicNode net2 julia mx.list_arguments(net2) 3-element Array{Symbol,1}: :data2 :net2_weight :net2_bias julia composed_net = net2(data2=net, name=:composed) SymbolicNode composed julia mx.list_arguments(composed_net) 5-element Array{Symbol,1}: :data :fc1_weight :fc1_bias :net2_weight :net2_bias Note we use a composed symbol, net as the argument data2 for net2 to get a new symbol, which we named :composed . It also shows that a symbol itself is a call-able object, which can be invoked to fill in missing arguments and get more complicated symbol compositions. Shape Inference Given enough information, the shapes of all arguments in a composed symbol could be inferred automatically. For example, given the input shape, and some hyper-parameters like num_hidden , the shapes for the weights and bias in a neural network could be inferred. julia using MXNet julia net = mx.Variable(:data) SymbolicNode data julia net = mx.FullyConnected(net, name=:fc1, num_hidden=10) SymbolicNode fc1 julia arg_shapes, out_shapes, aux_shapes = mx.infer_shape(net, data=(10, 64)) (Tuple[(10, 64), (10, 10), (10,)], Tuple[(10, 64)], Tuple[]) The returned shapes corresponds to arguments with the same order as returned by mx.list_arguments . The out_shapes are shapes for outputs, and aux_shapes can be safely ignored for now. julia for (n, s) in zip(mx.list_arguments(net), arg_shapes) println( $n\\t= $s ) end data = (10, 64) fc1_weight = (10, 10) fc1_bias = (10,) julia for (n, s) in zip(mx.list_outputs(net), out_shapes) println( $n\\t= $s ) end fc1_output = (10, 64) Binding and Executing In order to execute the computation graph specified a composed symbol, we will bind the free variables to concrete values, specified as mx.NDArray . This will create an mx.Executor on a given mx.Context . A context describes the computation devices (CPUs, GPUs, etc.) and an executor will carry out the computation (forward/backward) specified in the corresponding symbolic composition. julia using MXNet julia A = mx.Variable(:A) SymbolicNode A julia B = mx.Variable(:B) SymbolicNode B julia C = A .* B SymbolicNode _mul0 julia a = mx.ones(3) * 4 3-element NDArray{Float32,1} @ CPU0: 4.0f0 4.0f0 4.0f0 julia b = mx.ones(3) * 2 3-element NDArray{Float32,1} @ CPU0: 2.0f0 2.0f0 2.0f0 julia c_exec = mx.bind(C, context=mx.cpu(), args=Dict(:A = a, :B = b)); julia mx.forward(c_exec) 1-element Array{NDArray{Float32,1},1}: NDArray(Float32[8.0, 8.0, 8.0]) julia c_exec.outputs[1] 3-element NDArray{Float32,1} @ CPU0: 8.0f0 8.0f0 8.0f0 julia copy(c_exec.outputs[1]) # copy turns NDArray into Julia Array 3-element Array{Float32,1}: 8.0 8.0 8.0 For neural networks, it is easier to use simple_bind . By providing the shape for input arguments, it will perform a shape inference for the rest of the arguments and create the NDArray automatically. In practice, the binding and executing steps are hidden under the Model interface. TODO Provide pointers to model tutorial and further details about binding and symbolic API. High Level Interface The high level interface include model training and prediction API, etc.","title":"Overview"},{"location":"user-guide/overview/#overview","text":"","title":"Overview"},{"location":"user-guide/overview/#mxnetjl-namespace","text":"Most the functions and types in MXNet.jl are organized in a flat namespace. Because many some functions are conflicting with existing names in the Julia Base module, we wrap them all in a mx module. The convention of accessing the MXNet.jl interface is the to use the mx. prefix explicitly: julia using MXNet julia x = mx.zeros(2, 3) # MXNet NDArray 2\u00d73 mx.NDArray{Float32} @ CPU0: 0.0 0.0 0.0 0.0 0.0 0.0 julia y = zeros(eltype(x), size(x)) # Julia Array 2\u00d73 Array{Float32,2}: 0.0 0.0 0.0 0.0 0.0 0.0 julia copy!(y, x) # Overloaded function in Julia Base 2\u00d73 Array{Float32,2}: 0.0 0.0 0.0 0.0 0.0 0.0 julia z = mx.ones(size(x), mx.gpu()) # MXNet NDArray on GPU 2\u00d73 mx.NDArray{Float32} @ GPU0: 1.0 1.0 1.0 1.0 1.0 1.0 julia mx.copy!(z, y) # Same as copy!(z, y) 2\u00d73 mx.NDArray{Float32} @ GPU0: 0.0 0.0 0.0 0.0 0.0 0.0 Note functions like size , copy! that is extensively overloaded for various types works out of the box. But functions like zeros and ones will be ambiguous, so we always use the mx. prefix. If you prefer, the mx. prefix can be used explicitly for all MXNet.jl functions, including size and copy! as shown in the last line.","title":"MXNet.jl Namespace"},{"location":"user-guide/overview/#low-level-interface","text":"","title":"Low Level Interface"},{"location":"user-guide/overview/#ndarray","text":"NDArray is the basic building blocks of the actual computations in MXNet. It is like a Julia Array object, with some important differences listed here: The actual data could live on different Context (e.g. GPUs). For some contexts, iterating into the elements one by one is very slow, thus indexing into NDArray is not recommanded in general. The easiest way to inspect the contents of an NDArray is to use the copy function to copy the contents as a Julia Array . Operations on NDArray (including basic arithmetics and neural network related operators) are executed in parallel with automatic dependency tracking to ensure correctness. There is no generics in NDArray , the eltype is always mx.MX_float . Because for applications in machine learning, single precision floating point numbers are typical a best choice balancing between precision, speed and portability. Also since libmxnet is designed to support multiple languages as front-ends, it is much simpler to implement with a fixed data type. While most of the computation is hidden in libmxnet by operators corresponding to various neural network layers. Getting familiar with the NDArray API is useful for implementing Optimizer or customized operators in Julia directly. The followings are common ways to create NDArray objects: NDArray(undef, shape...; ctx = context, writable = true) : create an uninitialized array of a given shape on a specific device. For example, NDArray(undef, 2, 3) , NDArray(undef, 2, 3, ctx = mx.gpu(2)) . NDArray(undef, shape; ctx = context, writable = true) NDArray{T}(undef, shape...; ctx = context, writable = true) : create an uninitialized with the given type T . mx.zeros(shape[, context]) and mx.ones(shape[, context]) : similar to the Julia's built-in zeros and ones . mx.copy(jl_arr, context) : copy the contents of a Julia Array to a specific device. Most of the convenient functions like size , length , ndims , eltype on array objects should work out-of-the-box. Although indexing is not supported, it is possible to take slices : julia using MXNet julia a = mx.ones(2, 3) 2\u00d73 NDArray{Float32,2} @ CPU0: 1.0f0 1.0f0 1.0f0 1.0f0 1.0f0 1.0f0 julia b = mx.slice(a, 1:2) 2\u00d72 NDArray{Float32,2} @ CPU0: 1.0f0 1.0f0 1.0f0 1.0f0 julia b[:] = 2 2 julia a 2\u00d73 NDArray{Float32,2} @ CPU0: 2.0f0 2.0f0 1.0f0 2.0f0 2.0f0 1.0f0 A slice is a sub-region sharing the same memory with the original NDArray object. A slice is always a contiguous piece of memory, so only slicing on the last dimension is supported. The example above also shows a way to set the contents of an NDArray . julia using MXNet julia mx.srand(42) \u250c Warning: `mx.srand` is deprecated, use `mx.seed!` instead. \u2514 @ MXNet.mx /work/mxnet/docs/build_version_doc/apache-mxnet/v1.5.x/julia/src/random.jl:86 julia a = NDArray(undef, 2, 3) 2\u00d73 NDArray{Float32,2} @ CPU0: 1.786631f25 5.201349f-8 1.03047764f21 6.891884f34 4.2426297f-8 1.8058751f28 julia a[:] = 0.5 # set all elements to a scalar 0.5 julia a[:] = rand(size(a)) # set contents with a Julia Array ERROR: rand(rng, dims) is discontinued; try rand(rng, Float64, dims) julia copy!(a, rand(size(a))) # set value by copying a Julia Array ERROR: rand(rng, dims) is discontinued; try rand(rng, Float64, dims) julia b = NDArray(undef, size(a)) 2\u00d73 NDArray{Float32,2} @ CPU0: 1.786631f25 5.201349f-8 1.03047764f21 6.891884f34 6.8627133f-7 1.8058751f28 julia b[:] = a # copying and assignment between NDArrays 2\u00d73 NDArray{Float32,2} @ CPU0: 0.5f0 0.5f0 0.5f0 0.5f0 0.5f0 0.5f0 Note due to the intrinsic design of the Julia language, a normal assignment a = b does not mean copying the contents of b to a . Instead, it just make the variable a pointing to a new object, which is b . Similarly, inplace arithmetics does not work as expected: julia using MXNet julia a = mx.ones(2) 2-element NDArray{Float32,1} @ CPU0: 1.0f0 1.0f0 julia r = a # keep a reference to a 2-element NDArray{Float32,1} @ CPU0: 1.0f0 1.0f0 julia b = mx.ones(2) 2-element NDArray{Float32,1} @ CPU0: 1.0f0 1.0f0 julia a += b # translates to a = a + b 2-element NDArray{Float32,1} @ CPU0: 2.0f0 2.0f0 julia a 2-element NDArray{Float32,1} @ CPU0: 2.0f0 2.0f0 julia r 2-element NDArray{Float32,1} @ CPU0: 1.0f0 1.0f0 As we can see, a has expected value, but instead of inplace updating, a new NDArray is created and a is set to point to this new object. If we look at r , which still reference to the old a , its content has not changed. There is currently no way in Julia to overload the operators like += to get customized behavior. Instead, you will need to write a[:] = a + b , or if you want real inplace += operation, MXNet.jl provides a simple macro @mx.inplace : julia @mx.inplace a += b 2-element NDArray{Float32,1} @ CPU0: 3.0f0 3.0f0 julia macroexpand(:(@mx.inplace a += b)) ERROR: MethodError: no method matching macroexpand(::Expr) Closest candidates are: macroexpand(!Matched::Module, !Matched::Any; recursive) at expr.jl:91 As we can see, it translate the += operator to an explicit add_to! function call, which invokes into libmxnet to add the contents of b into a directly. For example, the following is the update rule in the SGD Optimizer (both gradient \u2207 and weight W are NDArray objects): @inplace W .+= -\u03b7 .* (\u2207 + \u03bb .* W) Note there is no much magic in mx.inplace : it only does a shallow translation. In the SGD update rule example above, the computation like scaling the gradient by grad_scale and adding the weight decay all create temporary NDArray objects. To mitigate this issue, libmxnet has a customized memory allocator designed specifically to handle this kind of situations. The following snippet does a simple benchmark on allocating temp NDArray vs. pre-allocating: using Benchmark using MXNet N_REP = 1000 SHAPE = (128, 64) CTX = mx.cpu() LR = 0.1 function inplace_op() weight = mx.zeros(SHAPE, CTX) grad = mx.ones(SHAPE, CTX) # pre-allocate temp objects grad_lr = NDArray(undef, SHAPE, ctx = CTX) for i = 1:N_REP copy!(grad_lr, grad) @mx.inplace grad_lr .*= LR @mx.inplace weight -= grad_lr end return weight end function normal_op() weight = mx.zeros(SHAPE, CTX) grad = mx.ones(SHAPE, CTX) for i = 1:N_REP weight[:] -= LR * grad end return weight end # make sure the results are the same @assert(maximum(abs(copy(normal_op() - inplace_op()))) 1e-6) println(compare([inplace_op, normal_op], 100)) The comparison on my laptop shows that normal_op while allocating a lot of temp NDArray in the loop (the performance gets worse when increasing N_REP ), is only about twice slower than the pre-allocated one. Row Function Average Relative Replications 1 \"inplace_op\" 0.0074854 1.0 100 2 \"normal_op\" 0.0174202 2.32723 100 So it will usually not be a big problem unless you are at the bottleneck of the computation.","title":"NDArray"},{"location":"user-guide/overview/#distributed-key-value-store","text":"The type KVStore and related methods are used for data sharing across different devices or machines. It provides a simple and efficient integer - NDArray key-value storage system that each device can pull or push. The following example shows how to create a local KVStore , initialize a value and then pull it back. kv = mx.KVStore(:local) shape = (2, 3) key = 3 mx.init!(kv, key, mx.ones(shape) * 2) a = NDArray(undef, shape) mx.pull!(kv, key, a) # pull value into a a 2\u00d73 NDArray{Float32,2} @ CPU0: 2.0f0 2.0f0 2.0f0 2.0f0 2.0f0 2.0f0","title":"Distributed Key-value Store"},{"location":"user-guide/overview/#intermediate-level-interface","text":"","title":"Intermediate Level Interface"},{"location":"user-guide/overview/#symbols-and-composition","text":"The way we build deep learning models in MXNet.jl is to use the powerful symbolic composition system. It is like Theano , except that we avoided long expression compilation time by providing larger neural network related building blocks to guarantee computation performance. See also this note for the design and trade-off of the MXNet symbolic composition system. The basic type is mx.SymbolicNode . The following is a trivial example of composing two symbols with the + operation. ```@example sym1 A = mx.Variable(:A) B = mx.Variable(:B) C = A + B print(C) # debug printing We get a new `SymbolicNode` by composing existing `SymbolicNode`s by some *operations*. A hierarchical architecture of a deep neural network could be realized by recursive composition. For example, the following code snippet shows a simple 2-layer MLP construction, using a hidden layer of 128 units and a `ReLU` activation function. ```@example fcnet net = mx.Variable(:data) net = mx.FullyConnected(net, name=:fc1, num_hidden=128) net = mx.Activation(net, name=:relu1, act_type=:relu) net = mx.FullyConnected(net, name=:fc2, num_hidden=64) net = mx.SoftmaxOutput(net, name=:out) print(net) # debug printing Each time we take the previous symbol, and compose with an operation. Unlike the simple + example above, the operations here are \"bigger\" ones, that correspond to common computation layers in deep neural networks. Each of those operation takes one or more input symbols for composition, with optional hyper-parameters (e.g. num_hidden , act_type ) to further customize the composition results. When applying those operations, we can also specify a name for the result symbol. This is convenient if we want to refer to this symbol later on. If not supplied, a name will be automatically generated. Each symbol takes some arguments. For example, in the + case above, to compute the value of C , we will need to know the values of the two inputs A and B . For neural networks, the arguments are primarily two categories: inputs and parameters . inputs are data and labels for the networks, while parameters are typically trainable weights , bias , filters . When composing symbols, their arguments accumulates. We can list all the arguments by mx.list_arguments(net) 6-element Array{Symbol,1}: :data :fc1_weight :fc1_bias :fc2_weight :fc2_bias :out_label Note the names of the arguments are generated according to the provided name for each layer. We can also specify those names explicitly: julia using MXNet julia net = mx.Variable(:data) SymbolicNode data julia w = mx.Variable(:myweight) SymbolicNode myweight julia net = mx.FullyConnected(net, weight=w, name=:fc1, num_hidden=128) SymbolicNode fc1 julia mx.list_arguments(net) 3-element Array{Symbol,1}: :data :myweight :fc1_bias The simple fact is that a Variable is just a placeholder mx.SymbolicNode . In composition, we can use arbitrary symbols for arguments. For example: julia using MXNet julia net = mx.Variable(:data) SymbolicNode data julia net = mx.FullyConnected(net, name=:fc1, num_hidden=128) SymbolicNode fc1 julia net2 = mx.Variable(:data2) SymbolicNode data2 julia net2 = mx.FullyConnected(net2, name=:net2, num_hidden=128) SymbolicNode net2 julia mx.list_arguments(net2) 3-element Array{Symbol,1}: :data2 :net2_weight :net2_bias julia composed_net = net2(data2=net, name=:composed) SymbolicNode composed julia mx.list_arguments(composed_net) 5-element Array{Symbol,1}: :data :fc1_weight :fc1_bias :net2_weight :net2_bias Note we use a composed symbol, net as the argument data2 for net2 to get a new symbol, which we named :composed . It also shows that a symbol itself is a call-able object, which can be invoked to fill in missing arguments and get more complicated symbol compositions.","title":"Symbols and Composition"},{"location":"user-guide/overview/#shape-inference","text":"Given enough information, the shapes of all arguments in a composed symbol could be inferred automatically. For example, given the input shape, and some hyper-parameters like num_hidden , the shapes for the weights and bias in a neural network could be inferred. julia using MXNet julia net = mx.Variable(:data) SymbolicNode data julia net = mx.FullyConnected(net, name=:fc1, num_hidden=10) SymbolicNode fc1 julia arg_shapes, out_shapes, aux_shapes = mx.infer_shape(net, data=(10, 64)) (Tuple[(10, 64), (10, 10), (10,)], Tuple[(10, 64)], Tuple[]) The returned shapes corresponds to arguments with the same order as returned by mx.list_arguments . The out_shapes are shapes for outputs, and aux_shapes can be safely ignored for now. julia for (n, s) in zip(mx.list_arguments(net), arg_shapes) println( $n\\t= $s ) end data = (10, 64) fc1_weight = (10, 10) fc1_bias = (10,) julia for (n, s) in zip(mx.list_outputs(net), out_shapes) println( $n\\t= $s ) end fc1_output = (10, 64)","title":"Shape Inference"},{"location":"user-guide/overview/#binding-and-executing","text":"In order to execute the computation graph specified a composed symbol, we will bind the free variables to concrete values, specified as mx.NDArray . This will create an mx.Executor on a given mx.Context . A context describes the computation devices (CPUs, GPUs, etc.) and an executor will carry out the computation (forward/backward) specified in the corresponding symbolic composition. julia using MXNet julia A = mx.Variable(:A) SymbolicNode A julia B = mx.Variable(:B) SymbolicNode B julia C = A .* B SymbolicNode _mul0 julia a = mx.ones(3) * 4 3-element NDArray{Float32,1} @ CPU0: 4.0f0 4.0f0 4.0f0 julia b = mx.ones(3) * 2 3-element NDArray{Float32,1} @ CPU0: 2.0f0 2.0f0 2.0f0 julia c_exec = mx.bind(C, context=mx.cpu(), args=Dict(:A = a, :B = b)); julia mx.forward(c_exec) 1-element Array{NDArray{Float32,1},1}: NDArray(Float32[8.0, 8.0, 8.0]) julia c_exec.outputs[1] 3-element NDArray{Float32,1} @ CPU0: 8.0f0 8.0f0 8.0f0 julia copy(c_exec.outputs[1]) # copy turns NDArray into Julia Array 3-element Array{Float32,1}: 8.0 8.0 8.0 For neural networks, it is easier to use simple_bind . By providing the shape for input arguments, it will perform a shape inference for the rest of the arguments and create the NDArray automatically. In practice, the binding and executing steps are hidden under the Model interface. TODO Provide pointers to model tutorial and further details about binding and symbolic API.","title":"Binding and Executing"},{"location":"user-guide/overview/#high-level-interface","text":"The high level interface include model training and prediction API, etc.","title":"High Level Interface"}]}