<!DOCTYPE html>
<html lang=" en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link href="https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/image/mxnet-icon.png" rel="icon" type="image/png"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Using MXNet with Large Tensor Support | Apache MXNet</title>
<meta name="generator" content="Jekyll v3.8.6" />
<meta property="og:title" content="Using MXNet with Large Tensor Support" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="A flexible and efficient library for deep learning." />
<meta property="og:description" content="A flexible and efficient library for deep learning." />
<link rel="canonical" href="https://mxnet.apache.org/api/faq/large_tensor_support" />
<meta property="og:url" content="https://mxnet.apache.org/api/faq/large_tensor_support" />
<meta property="og:site_name" content="Apache MXNet" />
<script type="application/ld+json">
{"description":"A flexible and efficient library for deep learning.","@type":"WebPage","headline":"Using MXNet with Large Tensor Support","url":"https://mxnet.apache.org/api/faq/large_tensor_support","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<script src="https://medium-widget.pixelpoint.io/widget.js"></script>
  <link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="https://mxnet.apache.org/feed.xml" title="Apache MXNet" /><script>
if(!(window.doNotTrack === "1" || navigator.doNotTrack === "1" || navigator.doNotTrack === "yes" || navigator.msDoNotTrack === "1")) {
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-96378503-1', 'auto');
  ga('send', 'pageview');
}
</script>
  
<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>

  <script src="/assets/js/clipboard.js"></script>
  <script src="/assets/js/copycode.js"></script>
</head>
<body><header class="site-header" role="banner">

  <script>
    $(document).ready(function () {

      // HEADER OPACITY LOGIC

      function opacity_header() {
        var value = "rgba(4,140,204," + ($(window).scrollTop() / 300 + 0.4) + ")"
        $('.site-header').css("background-color", value)
      }

      $(window).scroll(function () {
        opacity_header()
      })
      opacity_header();

      // MENU SELECTOR LOGIC
      $('.page-link').each( function () {
        if (window.location.href.includes(this.href)) {
          $(this).addClass("page-current");
        }
      });
    })
  </script>
  <div class="wrapper">
    <a class="site-title" rel="author" href="/"><img
            src="/assets/img/mxnet_logo.png" class="site-header-logo"></a>
    <nav class="site-nav">
      <input type="checkbox" id="nav-trigger" class="nav-trigger"/>
      <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
      </label>

      <div class="trigger">
        <a class="page-link" href="/get_started">Get Started</a>
        <a class="page-link" href="/blog">Blog</a>
        <a class="page-link" href="/features">Features</a>
        <a class="page-link" href="/ecosystem">Ecosystem</a>
        <a class="page-link" href="/api">Docs & Tutorials</a>
        <a class="page-link" href="https://github.com/apache/incubator-mxnet">GitHub</a>
      </div>
    </nav>
  </div>
</header>
<main class="page-content" aria-label="Content">
    <script>

</script>
<article class="post">

    <header class="post-header wrapper">
        <h1 class="post-title">Using MXNet with Large Tensor Support</h1>
        <h3></h3></header>

    <div class="post-content">
        <div class="wrapper">
            <div class="row">
    <div class="col-3 docs-side-bar">
        <h3 style="text-transform: capitalize; padding-left:10px">faq</h3>
        <ul>
            
              <!-- page-category -->
            
            
            <li><a href="/api/faq/add_op_in_backend">A Beginner's Guide to Implementing Operators in MXNet Backend</a></li>
              <!-- page-category -->
            
              <!-- page-category -->
            
              <!-- page-category -->
            
              <!-- page-category -->
            
              <!-- page-category -->
            
              <!-- page-category -->
            
            
            <li><a href="/api/faq/caffe">Convert from Caffe to MXNet</a></li>
              <!-- page-category -->
            
              <!-- page-category -->
            
              <!-- page-category -->
            
              <!-- page-category -->
            
              <!-- page-category -->
            
              <!-- page-category -->
            
            
            <li><a href="/api/faq/cloud">MXNet on the Cloud</a></li>
              <!-- page-category -->
            
              <!-- page-category -->
            
              <!-- page-category -->
            
              <!-- page-category -->
            
            
            <li><a href="/api/faq/distributed_training">Distributed Training in MXNet</a></li>
              <!-- page-category -->
            
              <!-- page-category -->
            
              <!-- page-category -->
            
            
            <li><a href="/api/faq/env_var">Environment Variables</a></li>
              <!-- page-category -->
            
              <!-- page-category -->
            
              <!-- page-category -->
            
              <!-- page-category -->
            
            
            <li><a href="/api/faq/float16">Float16</a></li>
              <!-- page-category -->
            
              <!-- page-category -->
            
              <!-- page-category -->
            
              <!-- page-category -->
            
              <!-- page-category -->
            
              <!-- page-category -->
            
              <!-- page-category -->
            
              <!-- page-category -->
            
              <!-- page-category -->
            
              <!-- page-category -->
            
              <!-- page-category -->
            
              <!-- page-category -->
            
              <!-- page-category -->
            
              <!-- page-category -->
            
              <!-- page-category -->
            
              <!-- page-category -->
            
              <!-- page-category -->
            
              <!-- page-category -->
            
              <!-- page-category -->
            
              <!-- page-category -->
            
              <!-- page-category -->
            
              <!-- page-category -->
            
              <!-- page-category -->
            
              <!-- page-category -->
            
              <!-- page-category -->
            
              <!-- page-category -->
            
            
            <li><a href="/api/faq/large_tensor_support">Using MXNet with Large Tensor Support</a></li>
              <!-- page-category -->
            
              <!-- page-category -->
            
              <!-- page-category -->
            
              <!-- page-category -->
            
              <!-- page-category -->
            
            
            <li><a href="/api/faq/model_parallel_lstm">Model Parallel</a></li>
              <!-- page-category -->
            
              <!-- page-category -->
            
              <!-- page-category -->
            
              <!-- page-category -->
            
              <!-- page-category -->
            
              <!-- page-category -->
            
              <!-- page-category -->
            
              <!-- page-category -->
            
              <!-- page-category -->
            
              <!-- page-category -->
            
              <!-- page-category -->
            
              <!-- page-category -->
            
            
            <li><a href="/api/faq/new_op">Create New Operators</a></li>
              <!-- page-category -->
            
            
            <li><a href="/api/faq/nnpack">NNPACK for Multi-Core CPU Support in MXNet</a></li>
              <!-- page-category -->
            
              <!-- page-category -->
            
              <!-- page-category -->
            
              <!-- page-category -->
            
              <!-- page-category -->
            
              <!-- page-category -->
            
            
            <li><a href="/api/faq/perf">Some Tips for Improving MXNet Performance</a></li>
              <!-- page-category -->
            
              <!-- page-category -->
            
            
            <li><a href="/api/faq/recordio">Create a Dataset Using RecordIO</a></li>
              <!-- page-category -->
            
            
            <li><a href="/api/faq/s3_integration">Use data from S3 for training</a></li>
              <!-- page-category -->
            
              <!-- page-category -->
            
            
            <li><a href="/api/faq/security">MXNet Security Best Practices</a></li>
              <!-- page-category -->
            
            
            <li><a href="/api/faq/smart_device">Deep Learning at the Edge</a></li>
              <!-- page-category -->
            
              <!-- page-category -->
            
              <!-- page-category -->
            
              <!-- page-category -->
            
              <!-- page-category -->
            
              <!-- page-category -->
            
              <!-- page-category -->
            
              <!-- page-category -->
            
              <!-- page-category -->
            
              <!-- page-category -->
            
              <!-- page-category -->
            
            
            <li><a href="/api/faq/visualize_graph">Visualize Neural Networks</a></li>
              <!-- page-category -->
            
            
            <li><a href="/api/faq/why_mxnet">Why MXNet came to be?</a></li>
              <!-- page-category -->
            
              <!-- page-category -->
            
              <!-- page-category -->
               <!-- resource-p -->
        </ul>
    </div>
    <div class="col-9">
        <!--- Licensed to the Apache Software Foundation (ASF) under one -->

<!--- or more contributor license agreements.  See the NOTICE file -->

<!--- distributed with this work for additional information -->

<!--- regarding copyright ownership.  The ASF licenses this file -->

<!--- to you under the Apache License, Version 2.0 (the -->

<!--- "License"); you may not use this file except in compliance -->

<!--- with the License.  You may obtain a copy of the License at -->

<!---   http://www.apache.org/licenses/LICENSE-2.0 -->

<!--- Unless required by applicable law or agreed to in writing, -->

<!--- software distributed under the License is distributed on an -->

<!--- "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY -->

<!--- KIND, either express or implied.  See the License for the -->

<!--- specific language governing permissions and limitations -->

<!--- under the License. -->

<h1 id="using-mxnet-with-large-tensor-support">Using MXNet with Large Tensor Support</h1>

<h2 id="what-is-large-tensor-support">What is large tensor support?</h2>

<p>When creating a network that uses large amounts of data, as in a deep graph problem, you may need large tensor support. This is a relatively new feature as tensors are indexed in MXNet using INT32 indices by default. Now MXNet build with Large Tensor supports INT64 indices.</p>

<p>It is MXNet built with an additional flag <em>USE_INT64_TENSOR_SIZE=1</em>
in CMAKE it is built using <em>USE_INT64_TENSOR_SIZE:“ON”</em></p>

<h2 id="when-do-you-need-it">When do you need it?</h2>

<ol>
<li>When you are creating NDArrays of size larger than 2^31 elements.</li>
<li>When the input to your model requires tensors that have inputs larger than 2^31 (when you load them all at once in your code) or attributes greater than 2^31.</li>
</ol>

<h2 id="how-to-identify-that-you-need-to-use-large-tensors">How to identify that you need to use large tensors ?</h2>

<p>When you see one of the following errors:</p>

<ol>
<li>OverflowError: unsigned int is greater than maximum</li>
<li>Check failed: inp-&gt;shape().Size() &lt; 1 &gt;&gt; 31 (4300000000 vs. 0) : Size of tensor you are trying to allocate is larger than 2^32 elements. Please build with flag USE_INT64_TENSOR_SIZE=1</li>
<li>Invalid Parameter format for end expect int or None but value=&#39;2150000000&#39;, in operator slice_axis(name=&quot;&quot;, end=&quot;2150000000&quot;, begin=&quot;0&quot;, axis=&quot;0&quot;). <em><em>Basically input attribute was expected to be int32, which is less than 2^31 and the received value is larger than that so, operator&#39;s parmeter inference treats that as a string which becomes unexpected input.`</em></em></li>
</ol>

<h2 id="how-to-use-it">How to use it ?</h2>

<p>You can create a large NDArray that requires large tensor enabled build to run as follows:</p>
<div class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">LARGE_X</span><span class="o">=</span><span class="mi">4300000000</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">mx</span><span class="o">.</span><span class="n">nd</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">LARGE_X</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="err">“</span><span class="n">int64</span><span class="err">”</span><span class="p">)</span>
<span class="ow">or</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">nd</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">LARGE_X</span><span class="p">)</span>
<span class="ow">or</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">nd</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">LARGE_X</span><span class="p">)</span>
<span class="ow">or</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">nd</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">exponential</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">LARGE_X</span><span class="p">)</span>
<span class="ow">or</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">nd</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">gamma</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">LARGE_X</span><span class="p">)</span>
<span class="ow">or</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">nd</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">LARGE_X</span><span class="p">)</span>
</code></pre></div>
<h2 id="caveats">Caveats</h2>

<ol>
<li>Use <code>int64</code> as <code>dtype</code> whenever attempting to slice an NDArray when range is over maximum <code>int32</code> value</li>
<li>Use <code>int64</code> as <code>dtype</code> when passing indices as parameters or expecting output as parameters to and from operators</li>
</ol>

<p>The following are the cases for large tensor usage where you must specify <code>dtype</code> as <code>int64</code>:</p>

<ul>
<li><em>randint():</em>
<code>python
low_large_value = 2*32*
*high_large_value = 2*34
# dtype is explicitly specified since default type is int32 for randint
a = nd.random.randint(low_large_value, high_large_value, dtype=np.int64)
</code></li>
<li><em>ravel_multi_index()</em> and <em>unravel_index()</em>:
<code>python
x1, y1 = rand_coord_2d((LARGE_X - 100), LARGE_X, 10, SMALL_Y)
x2, y2 = rand_coord_2d((LARGE_X - 200), LARGE_X, 9, SMALL_Y)
x3, y3 = rand_coord_2d((LARGE_X - 300), LARGE_X, 8, SMALL_Y)
indices_2d = [[x1, x2, x3], [y1, y2, y3]]
# dtype is explicitly specified for indices else they will default to float32
idx = mx.nd.ravel_multi_index(mx.nd.array(indices_2d, dtype=np.int64),
                              shape=(LARGE_X, SMALL_Y))
indices_2d = mx.nd.unravel_index(mx.nd.array(idx_numpy, dtype=np.int64),
                              shape=(LARGE_X, SMALL_Y))
</code></li>
<li><em>argsort()</em> and <em>topk()</em></li>
</ul>

<p>They both return indices which are specified by <code>dtype=np.int64</code>.
```python
b = create_2d_tensor(rows=LARGE_X, columns=SMALL_Y)</p>

<h1 id="argsort">argsort</h1>

<p>s = nd.argsort(b, axis=0, is_ascend=False, dtype=np.int64)</p>

<h1 id="topk">topk</h1>

<p>k = nd.topk(b, k=10, axis=0, dtype=np.int64)
```
* <em>index_copy()</em></p>

<p>Again whenever we are passing indices as arguments and using large tensor, the <code>dtype</code> of indices must be <code>int64</code>.
```python
x = mx.nd.zeros((LARGE_X, SMALL_Y))
t = mx.nd.arange(1, SMALL_Y + 1).reshape((1, SMALL_Y))</p>

<h1 id="explicitly-specifying-dtype-of-indices-to-np-int64">explicitly specifying dtype of indices to np.int64</h1>

<p>index = mx.nd.array([LARGE_X - 1], dtype=&quot;int64&quot;)
x = mx.nd.contrib.index_copy(x, index, t)
```
* <em>one_hot()</em></p>

<p>Here again array is used as indices that act as location of bits inside the large vector that need to be activated.
```python</p>

<h1 id="a-is-the-index-array-here-whose-dtype-should-be-int64">a is the index array here whose dtype should be int64.</h1>

<p>a = nd.array([1, (VLARGE_X - 1)], dtype=np.int64)
b = nd.one_hot(a, VLARGE_X)
```</p>

<h2 id="what-platforms-and-version-of-mxnet-are-supported">What platforms and version of MXNet are supported ?</h2>

<p>You can use MXNet with large tensor support in the following configuration:</p>

<p><em>MXNet built for CPU on Linux (Ubuntu or Amazon Linux), and only for python bindings.</em>
<em>Custom wheels are provided with this configuration.</em></p>

<p>These flavors of MXNet are currently built with large tensor support:</p>

<ol>
<li>MXNet for linux-cpu</li>
<li>MXNet for linux_cu100</li>
</ol>

<p>Large tensor support only works for <em>forward pass</em>. 
Backward pass is partially supported and not completely tested, so it is considered experimental at best.</p>

<p>Not supported:</p>

<ul>
<li>GPU and MKLDNN. </li>
<li>Windows, ARM or any operating system other than Ubuntu</li>
<li>Any permutation of MXNet wheel that contains MKLDNN. </li>
<li>Other language bindings like Scala, Java, R,  and Julia.</li>
</ul>

<h2 id="other-known-issues">Other known Issues:</h2>

<p>Randint operator is flaky: <a href="https://github.com/apache/incubator-mxnet/issues/16172">https://github.com/apache/incubator-mxnet/issues/16172</a>
dgemm operations using BLAS libraries currently don’t support int64.
linspace() is not supported.
```python
a = mx.sym.Variable(&#39;a&#39;)
b = mx.sym.Variable(&#39;b&#39;)
c = 2 * a + b
texec = c.bind(mx.cpu(), {&#39;a&#39;: nd.arange(0, LARGE_X * 2, dtype=&#39;int64&#39;).reshape(2, LARGE_X), &#39;b&#39; : nd.arange(0, LARGE_X * 2, dtype=&#39;int64&#39;).reshape(2, LARGE_X)})
new_shape = {&#39;a&#39;: (1, 2*LARGE_X), &#39;b&#39;: (1, 2*LARGE_X)}
texec.reshape(allow_up_sizing=True, **new_shape)</p>

<p>Traceback (most recent call last):
  File &quot;<stdin>&quot;, line 1, in <module>
  File &quot;/home/ubuntu/incubator-mxnet/python/mxnet/executor.py&quot;, line 449, in reshape
    py_array(&#39;i&#39;, provided_arg_shape_data)),
OverflowError: signed integer is greater than maximum}
<code>
Symbolic reshape is not supported. Please see the following example.
</code>python
a = mx.sym.Variable(&#39;a&#39;)
b = mx.sym.Variable(&#39;b&#39;)
c = 2 * a + b
texec = c.bind(mx.cpu(), {&#39;a&#39;: nd.arange(0, LARGE_X * 2, dtype=&#39;int64&#39;).reshape(2, LARGE_X), &#39;b&#39; : nd.arange(0, LARGE_X * 2, dtype=&#39;int64&#39;).reshape(2, LARGE_X)})
new_shape = {&#39;a&#39;: (1, 2 * LARGE_X), &#39;b&#39;: (1, 2 * LARGE_X)}
texec.reshape(allow_up_sizing=True, **new_shape)</p>

<p>Traceback (most recent call last):
  File &quot;<stdin>&quot;, line 1, in <module>
  File &quot;/home/ubuntu/incubator-mxnet/python/mxnet/executor.py&quot;, line 449, in reshape
    py_array(&#39;i&#39;, provided_arg_shape_data)),
OverflowError: signed integer is greater than maximum
```</p>

<h2 id="working-dgl-example-dgl-ai">Working DGL Example(dgl.ai)</h2>

<p>The following is a sample running code for DGL which works with int64 but not with int32.
```python
import mxnet as mx
from mxnet import gluon
import dgl
import dgl.function as fn
import numpy as np
from scipy import sparse as spsp</p>

<p>num_nodes = 10000000
num_edges = 100000000</p>

<p>col1 = np.random.randint(0, num_nodes, size=(num_edges,))
print(&#39;create col1&#39;)
col2 = np.random.randint(0, num_nodes, size=(num_edges,))
print(&#39;create col2&#39;)
data = np.ones((num_edges,))
print(&#39;create data&#39;)
spm = spsp.coo_matrix((data, (col1, col2)), shape=(num_nodes, num_nodes))
print(&#39;create coo&#39;)
labels = mx.nd.random.randint(0, 10, shape=(num_nodes,))</p>

<p>g = dgl.DGLGraph(spm, readonly=True)
print(&#39;create DGLGraph&#39;)
g.ndata[&#39;h&#39;] = mx.nd.random.uniform(shape=(num_nodes, 200))
print(&#39;create node data&#39;)</p>

<p>class node_update(gluon.Block):
    def <strong>init</strong>(self, out_feats):
        super(node_update, self).<strong>init</strong>()
        self.dense = gluon.nn.Dense(out_feats, &#39;relu&#39;)
        self.dropout = 0.5</p>
<div class="highlight"><pre><code class="language-" data-lang="">def forward(self, nodes):
    h = mx.nd.concat(nodes.data['h'], nodes.data['accum'], dim=1)
    h = self.dense(h)
    return {'h': mx.nd.Dropout(h, p=self.dropout)}
</code></pre></div>
<p>update_fn = node_update(200)
update_fn.initialize(ctx=mx.cpu())</p>

<p>g.update_all(fn.copy_src(src=&#39;h&#39;, out=&#39;m&#39;), fn.sum(msg=&#39;m&#39;, out=&#39;accum&#39;), update_fn)
print(&#39;update all&#39;)</p>

<p>loss_fcn = gluon.loss.SoftmaxCELoss()
loss = loss_fcn(g.ndata[&#39;h&#39;], labels)
print(&#39;loss&#39;)
loss = loss.sum()
print(loss)
```</p>

<h2 id="performance-regression">Performance Regression:</h2>

<p>Roughly 40 operators have shown performance regression in our preliminary analysis: Large Tensor Performance as shown in table below.</p>

<table><thead>
<tr>
<th>Operator</th>
<th>int32(msec)</th>
<th>int64(msec)</th>
<th>int64/int32</th>
<th>int32+mkl(msec)</th>
<th>int64+mkl(msec)</th>
<th>int64+mkl/int32+mkl</th>
</tr>
</thead><tbody>
<tr>
<td>topk</td>
<td>12.81245198</td>
<td>42.2472195</td>
<td>329.74%</td>
<td>12.728027</td>
<td>43.462353</td>
<td>341.47%</td>
</tr>
<tr>
<td>argsort</td>
<td>16.43896801</td>
<td>46.2231455</td>
<td>281.18%</td>
<td>17.200311</td>
<td>46.7779985</td>
<td>271.96%</td>
</tr>
<tr>
<td>sort</td>
<td>16.57822751</td>
<td>46.5644815</td>
<td>280.88%</td>
<td>16.401236</td>
<td>46.263803</td>
<td>282.08%</td>
</tr>
<tr>
<td>flip</td>
<td>0.221817521</td>
<td>0.535838</td>
<td>241.57%</td>
<td>0.2123705</td>
<td>0.7950055</td>
<td>374.35%</td>
</tr>
<tr>
<td>depth_to_space</td>
<td>0.250976998</td>
<td>0.534083</td>
<td>212.80%</td>
<td>0.2338155</td>
<td>0.631252</td>
<td>269.98%</td>
</tr>
<tr>
<td>space_to_depth</td>
<td>0.254336512</td>
<td>0.5368935</td>
<td>211.10%</td>
<td>0.2334405</td>
<td>0.6343175</td>
<td>271.73%</td>
</tr>
<tr>
<td>min_axis</td>
<td>0.685826526</td>
<td>1.4393255</td>
<td>209.87%</td>
<td>0.6266175</td>
<td>1.3538925</td>
<td>216.06%</td>
</tr>
<tr>
<td>sum_axis</td>
<td>0.720809505</td>
<td>1.5110635</td>
<td>209.63%</td>
<td>0.6566265</td>
<td>0.8290575</td>
<td>126.26%</td>
</tr>
<tr>
<td>nansum</td>
<td>1.279337012</td>
<td>2.635434</td>
<td>206.00%</td>
<td>1.227156</td>
<td>2.4305255</td>
<td>198.06%</td>
</tr>
<tr>
<td>argmax</td>
<td>4.765146994</td>
<td>9.682672</td>
<td>203.20%</td>
<td>4.6576605</td>
<td>9.394067</td>
<td>201.69%</td>
</tr>
<tr>
<td>swapaxes</td>
<td>0.667943008</td>
<td>1.3544455</td>
<td>202.78%</td>
<td>0.649036</td>
<td>1.8293235</td>
<td>281.85%</td>
</tr>
<tr>
<td>argmin</td>
<td>4.774890491</td>
<td>9.545651</td>
<td>199.91%</td>
<td>4.666858</td>
<td>9.5194385</td>
<td>203.98%</td>
</tr>
<tr>
<td>sum_axis</td>
<td>0.540210982</td>
<td>1.0550705</td>
<td>195.31%</td>
<td>0.500895</td>
<td>0.616179</td>
<td>123.02%</td>
</tr>
<tr>
<td>max_axis</td>
<td>0.117824005</td>
<td>0.226481</td>
<td>192.22%</td>
<td>0.149085</td>
<td>0.224334</td>
<td>150.47%</td>
</tr>
<tr>
<td>argmax_channel</td>
<td>0.261897018</td>
<td>0.49573</td>
<td>189.28%</td>
<td>0.251171</td>
<td>0.4814885</td>
<td>191.70%</td>
</tr>
<tr>
<td>min_axis</td>
<td>0.147698505</td>
<td>0.2675355</td>
<td>181.14%</td>
<td>0.148424</td>
<td>0.2874105</td>
<td>193.64%</td>
</tr>
<tr>
<td>nansum</td>
<td>1.142132009</td>
<td>2.058077</td>
<td>180.20%</td>
<td>1.042387</td>
<td>1.263102</td>
<td>121.17%</td>
</tr>
<tr>
<td>min_axis</td>
<td>0.56951947</td>
<td>1.020972</td>
<td>179.27%</td>
<td>0.4722595</td>
<td>0.998179</td>
<td>211.36%</td>
</tr>
<tr>
<td>min</td>
<td>1.154684491</td>
<td>2.0446045</td>
<td>177.07%</td>
<td>1.0534145</td>
<td>1.9723065</td>
<td>187.23%</td>
</tr>
<tr>
<td>sum</td>
<td>1.121753477</td>
<td>1.959272</td>
<td>174.66%</td>
<td>0.9984095</td>
<td>1.213339</td>
<td>121.53%</td>
</tr>
<tr>
<td>sum_axis</td>
<td>0.158632494</td>
<td>0.2744115</td>
<td>172.99%</td>
<td>0.1573735</td>
<td>0.2266315</td>
<td>144.01%</td>
</tr>
<tr>
<td>nansum</td>
<td>0.21418152</td>
<td>0.3661335</td>
<td>170.95%</td>
<td>0.2162935</td>
<td>0.269517</td>
<td>124.61%</td>
</tr>
<tr>
<td>random_normal</td>
<td>1.229072484</td>
<td>2.093057</td>
<td>170.30%</td>
<td>1.222785</td>
<td>2.095916</td>
<td>171.41%</td>
</tr>
<tr>
<td>LeakyReLU</td>
<td>0.344101485</td>
<td>0.582337</td>
<td>169.23%</td>
<td>0.389167</td>
<td>0.7003465</td>
<td>179.96%</td>
</tr>
<tr>
<td>nanprod</td>
<td>1.273265516</td>
<td>2.095068</td>
<td>164.54%</td>
<td>1.0906815</td>
<td>2.054369</td>
<td>188.36%</td>
</tr>
<tr>
<td>nanprod</td>
<td>0.203272473</td>
<td>0.32792</td>
<td>161.32%</td>
<td>0.202548</td>
<td>0.3288335</td>
<td>162.35%</td>
</tr>
<tr>
<td>sample_gamma</td>
<td>8.079962019</td>
<td>12.7266385</td>
<td>157.51%</td>
<td>12.4216245</td>
<td>12.7957475</td>
<td>103.01%</td>
</tr>
<tr>
<td>sum</td>
<td>0.21571602</td>
<td>0.3396875</td>
<td>157.47%</td>
<td>0.1939995</td>
<td>0.262942</td>
<td>135.54%</td>
</tr>
<tr>
<td>argmin</td>
<td>0.086381478</td>
<td>0.1354795</td>
<td>156.84%</td>
<td>0.0826235</td>
<td>0.134886</td>
<td>163.25%</td>
</tr>
<tr>
<td>argmax</td>
<td>0.08664903</td>
<td>0.135826</td>
<td>156.75%</td>
<td>0.082693</td>
<td>0.1269225</td>
<td>153.49%</td>
</tr>
<tr>
<td>sample_gamma</td>
<td>7.712843508</td>
<td>12.0266355</td>
<td>155.93%</td>
<td>11.8900915</td>
<td>12.143009</td>
<td>102.13%</td>
</tr>
<tr>
<td>sample_exponential</td>
<td>2.312778</td>
<td>3.5953945</td>
<td>155.46%</td>
<td>3.0935085</td>
<td>3.5656265</td>
<td>115.26%</td>
</tr>
<tr>
<td>prod</td>
<td>0.203170988</td>
<td>0.3113865</td>
<td>153.26%</td>
<td>0.180757</td>
<td>0.264523</td>
<td>146.34%</td>
</tr>
<tr>
<td>random_uniform</td>
<td>0.40893798</td>
<td>0.6240795</td>
<td>152.61%</td>
<td>0.244613</td>
<td>0.6319695</td>
<td>258.35%</td>
</tr>
<tr>
<td>min</td>
<td>0.205482502</td>
<td>0.3122025</td>
<td>151.94%</td>
<td>0.2023835</td>
<td>0.33234</td>
<td>164.21%</td>
</tr>
<tr>
<td>random_negative_binomial</td>
<td>3.919228504</td>
<td>5.919488</td>
<td>151.04%</td>
<td>5.685851</td>
<td>6.0220735</td>
<td>105.91%</td>
</tr>
<tr>
<td>max</td>
<td>0.212521001</td>
<td>0.3130105</td>
<td>147.28%</td>
<td>0.2039755</td>
<td>0.2956105</td>
<td>144.92%</td>
</tr>
<tr>
<td>LeakyReLU</td>
<td>2.813424013</td>
<td>4.1121625</td>
<td>146.16%</td>
<td>2.719118</td>
<td>5.613753</td>
<td>206.45%</td>
</tr>
<tr>
<td>mean</td>
<td>0.242281501</td>
<td>0.344385</td>
<td>142.14%</td>
<td>0.209396</td>
<td>0.313411</td>
<td>149.67%</td>
</tr>
<tr>
<td>Deconvolution</td>
<td>7.43279251</td>
<td>10.4240845</td>
<td>140.24%</td>
<td>2.9548925</td>
<td>5.812926</td>
<td>196.72%</td>
</tr>
<tr>
<td>abs</td>
<td>0.273286481</td>
<td>0.38319</td>
<td>140.22%</td>
<td>0.3711615</td>
<td>0.338064</td>
<td>91.08%</td>
</tr>
<tr>
<td>arcsinh</td>
<td>0.155792513</td>
<td>0.2090985</td>
<td>134.22%</td>
<td>0.113365</td>
<td>0.1702855</td>
<td>150.21%</td>
</tr>
<tr>
<td>sample_gamma</td>
<td>0.137634983</td>
<td>0.1842455</td>
<td>133.87%</td>
<td>0.1792825</td>
<td>0.172175</td>
<td>96.04%</td>
</tr>
<tr>
<td>sort</td>
<td>0.864107016</td>
<td>1.1560165</td>
<td>133.78%</td>
<td>0.8239285</td>
<td>1.1454645</td>
<td>139.02%</td>
</tr>
<tr>
<td>argsort</td>
<td>0.847259507</td>
<td>1.1320885</td>
<td>133.62%</td>
<td>0.842302</td>
<td>1.1179105</td>
<td>132.72%</td>
</tr>
<tr>
<td>cosh</td>
<td>0.129947497</td>
<td>0.1727415</td>
<td>132.93%</td>
<td>0.1192565</td>
<td>0.1217325</td>
<td>102.08%</td>
</tr>
<tr>
<td>random_randint</td>
<td>0.822044531</td>
<td>1.085645</td>
<td>132.07%</td>
<td>0.6036805</td>
<td>1.0953995</td>
<td>181.45%</td>
</tr>
<tr>
<td>arctanh</td>
<td>0.119817996</td>
<td>0.1576315</td>
<td>131.56%</td>
<td>0.115616</td>
<td>0.111907</td>
<td>96.79%</td>
</tr>
<tr>
<td>arccos</td>
<td>0.185662502</td>
<td>0.2423095</td>
<td>130.51%</td>
<td>0.238534</td>
<td>0.2351415</td>
<td>98.58%</td>
</tr>
<tr>
<td>mean</td>
<td>1.758513477</td>
<td>2.2908485</td>
<td>130.27%</td>
<td>1.5868465</td>
<td>2.530801</td>
<td>159.49%</td>
</tr>
<tr>
<td>erfinv</td>
<td>0.142498524</td>
<td>0.184796</td>
<td>129.68%</td>
<td>0.1529025</td>
<td>0.1538225</td>
<td>100.60%</td>
</tr>
<tr>
<td>degrees</td>
<td>0.12517249</td>
<td>0.1576175</td>
<td>125.92%</td>
<td>0.1166425</td>
<td>0.1199775</td>
<td>102.86%</td>
</tr>
<tr>
<td>sample_exponential</td>
<td>0.07651851</td>
<td>0.0960485</td>
<td>125.52%</td>
<td>0.0885775</td>
<td>0.095597</td>
<td>107.92%</td>
</tr>
<tr>
<td>arctan</td>
<td>0.120863522</td>
<td>0.1496115</td>
<td>123.79%</td>
<td>0.1161245</td>
<td>0.17206</td>
<td>148.17%</td>
</tr>
<tr>
<td>prod</td>
<td>1.147695002</td>
<td>1.408007</td>
<td>122.68%</td>
<td>1.0491025</td>
<td>1.4065515</td>
<td>134.07%</td>
</tr>
<tr>
<td>fix</td>
<td>0.073436997</td>
<td>0.089991</td>
<td>122.54%</td>
<td>0.0390455</td>
<td>0.099307</td>
<td>254.34%</td>
</tr>
<tr>
<td>exp</td>
<td>0.047701993</td>
<td>0.058272</td>
<td>122.16%</td>
<td>0.0397295</td>
<td>0.0506725</td>
<td>127.54%</td>
</tr>
</tbody></table>

    </div>
</div>

        </div>
    </div>

</article>

</main><footer class="site-footer h-card">
    <div class="wrapper">
        <div class="row">
            <div class="col-4">
                <h4 class="footer-category-title">Resources</h4>
                <ul class="contact-list">
                    <li><a href="/community/contribute#mxnet-dev-communications">Mailing lists</a></li>
                    <li><a href="https://cwiki.apache.org/confluence/display/MXNET/Apache+MXNet+Home">Developer Wiki</a></li>
                    <li><a href="https://issues.apache.org/jira/projects/MXNET/issues">Jira Tracker</a></li>
                    <li><a href="https://github.com/apache/incubator-mxnet/labels/Roadmap">Github Roadmap</a></li>
                    <li><a href="https://discuss.mxnet.io">MXNet Discuss forum</a></li>
                    <li><a href="/community/contribute">Contribute To MXNet</a></li>

                </ul>
            </div>

            <div class="col-4"><ul class="social-media-list"><li><a href="https://github.com/apache/incubator-mxnet"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg> <span class="username">apache/incubator-mxnet</span></a></li><li><a href="https://www.twitter.com/apachemxnet"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg> <span class="username">apachemxnet</span></a></li><li><a href="https://youtube.com/apachemxnet"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#youtube"></use></svg> <span class="username">apachemxnet</span></a></li></ul>
</div>

            <div class="col-4 footer-text">
                <p>A flexible and efficient library for deep learning.</p>
            </div>
        </div>
    </div>
</footer>
<footer class="site-footer2">
    <div class="wrapper">
        <div class="row">
            <div class="col-3">
                <img src="/assets/img/apache_incubator_logo.png" class="footer-logo col-2">
            </div>
            <div class="footer-bottom-warning col-9">
                <p>Apache MXNet is an effort undergoing incubation at The Apache Software Foundation (ASF), <span
                        style="font-weight:bold">sponsored by the <i>Apache Incubator</i></span>. Incubation is required
                    of all newly accepted projects until a further review indicates that the infrastructure,
                    communications, and decision making process have stabilized in a manner consistent with other
                    successful ASF projects. While incubation status is not necessarily a reflection of the completeness
                    or stability of the code, it does indicate that the project has yet to be fully endorsed by the ASF.
                </p><p>"Copyright © 2017-2018, The Apache Software Foundation Apache MXNet, MXNet, Apache, the Apache
                    feather, and the Apache MXNet project logo are either registered trademarks or trademarks of the
                    Apache Software Foundation."</p>
            </div>
        </div>
    </div>
</footer>




</body>

</html>
