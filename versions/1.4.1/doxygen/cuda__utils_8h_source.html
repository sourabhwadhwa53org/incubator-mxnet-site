<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta content="text/xhtml;charset=utf-8" http-equiv="Content-Type"/>
<meta content="IE=9" http-equiv="X-UA-Compatible"/>
<meta content="Doxygen 1.8.11" name="generator"/>
<title>mxnet: src/common/cuda_utils.h Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script src="jquery.js" type="text/javascript"></script>
<script src="dynsections.js" type="text/javascript"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script src="search/searchdata.js" type="text/javascript"></script>
<script src="search/search.js" type="text/javascript"></script>
<script type="text/javascript">
  $(document).ready(function() { init_search(); });
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellpadding="0" cellspacing="0">
<tbody>
<tr style="height: 56px;">
<td id="projectalign" style="padding-left: 0.5em;">
<div id="projectname">mxnet
   </div>
</td>
</tr>
</tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.11 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<div class="tabs" id="navrow1">
<ul class="tablist">
<li><a href="index.html"><span>Main Page</span></a></li>
<li><a href="namespaces.html"><span>Namespaces</span></a></li>
<li><a href="annotated.html"><span>Classes</span></a></li>
<li class="current"><a href="files.html"><span>Files</span></a></li>
<li>
<div class="MSearchBoxInactive" id="MSearchBox">
<span class="left">
<img alt="" id="MSearchSelect" onmouseout="return searchBox.OnSearchSelectHide()" onmouseover="return searchBox.OnSearchSelectShow()" src="search/mag_sel.png"/>
<input accesskey="S" id="MSearchField" onblur="searchBox.OnSearchFieldFocus(false)" onfocus="searchBox.OnSearchFieldFocus(true)" onkeyup="searchBox.OnSearchFieldChange(event)" type="text" value="Search"/>
</span><span class="right">
<a href="javascript:searchBox.CloseResultsWindow()" id="MSearchClose"><img alt="" border="0" id="MSearchCloseImg" src="search/close.png"/></a>
</span>
</div>
</li>
</ul>
</div>
<div class="tabs2" id="navrow2">
<ul class="tablist">
<li><a href="files.html"><span>File List</span></a></li>
<li><a href="globals.html"><span>File Members</span></a></li>
</ul>
</div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow" onkeydown="return searchBox.OnSearchSelectKey(event)" onmouseout="return searchBox.OnSearchSelectHide()" onmouseover="return searchBox.OnSearchSelectShow()">
</div>
<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe frameborder="0" id="MSearchResults" name="MSearchResults" src="javascript:void(0)">
</iframe>
</div>
<div class="navpath" id="nav-path">
<ul>
<li class="navelem"><a class="el" href="dir_68267d1309a1af8e8297ef4c3efbcdba.html">src</a></li><li class="navelem"><a class="el" href="dir_fdedb0aba14d44ce9d99bc100e026e6a.html">common</a></li> </ul>
</div>
</div><!-- top -->
<div class="header">
<div class="headertitle">
<div class="title">cuda_utils.h</div> </div>
</div><!--header-->
<div class="contents">
<a href="cuda__utils_8h.html">Go to the documentation of this file.</a><div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span> <span class="comment">/*</span></div><div class="line"><a name="l00002"></a><span class="lineno">    2</span> <span class="comment"> * Licensed to the Apache Software Foundation (ASF) under one</span></div><div class="line"><a name="l00003"></a><span class="lineno">    3</span> <span class="comment"> * or more contributor license agreements.  See the NOTICE file</span></div><div class="line"><a name="l00004"></a><span class="lineno">    4</span> <span class="comment"> * distributed with this work for additional information</span></div><div class="line"><a name="l00005"></a><span class="lineno">    5</span> <span class="comment"> * regarding copyright ownership.  The ASF licenses this file</span></div><div class="line"><a name="l00006"></a><span class="lineno">    6</span> <span class="comment"> * to you under the Apache License, Version 2.0 (the</span></div><div class="line"><a name="l00007"></a><span class="lineno">    7</span> <span class="comment"> * "License"); you may not use this file except in compliance</span></div><div class="line"><a name="l00008"></a><span class="lineno">    8</span> <span class="comment"> * with the License.  You may obtain a copy of the License at</span></div><div class="line"><a name="l00009"></a><span class="lineno">    9</span> <span class="comment"> *</span></div><div class="line"><a name="l00010"></a><span class="lineno">   10</span> <span class="comment"> *   http://www.apache.org/licenses/LICENSE-2.0</span></div><div class="line"><a name="l00011"></a><span class="lineno">   11</span> <span class="comment"> *</span></div><div class="line"><a name="l00012"></a><span class="lineno">   12</span> <span class="comment"> * Unless required by applicable law or agreed to in writing,</span></div><div class="line"><a name="l00013"></a><span class="lineno">   13</span> <span class="comment"> * software distributed under the License is distributed on an</span></div><div class="line"><a name="l00014"></a><span class="lineno">   14</span> <span class="comment"> * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY</span></div><div class="line"><a name="l00015"></a><span class="lineno">   15</span> <span class="comment"> * KIND, either express or implied.  See the License for the</span></div><div class="line"><a name="l00016"></a><span class="lineno">   16</span> <span class="comment"> * specific language governing permissions and limitations</span></div><div class="line"><a name="l00017"></a><span class="lineno">   17</span> <span class="comment"> * under the License.</span></div><div class="line"><a name="l00018"></a><span class="lineno">   18</span> <span class="comment"> */</span></div><div class="line"><a name="l00019"></a><span class="lineno">   19</span> </div><div class="line"><a name="l00025"></a><span class="lineno">   25</span> <span class="preprocessor">#ifndef MXNET_COMMON_CUDA_UTILS_H_</span></div><div class="line"><a name="l00026"></a><span class="lineno">   26</span> <span class="preprocessor">#define MXNET_COMMON_CUDA_UTILS_H_</span></div><div class="line"><a name="l00027"></a><span class="lineno">   27</span> </div><div class="line"><a name="l00028"></a><span class="lineno">   28</span> <span class="preprocessor">#include &lt;dmlc/logging.h&gt;</span></div><div class="line"><a name="l00029"></a><span class="lineno">   29</span> <span class="preprocessor">#include &lt;dmlc/parameter.h&gt;</span></div><div class="line"><a name="l00030"></a><span class="lineno">   30</span> <span class="preprocessor">#include &lt;dmlc/optional.h&gt;</span></div><div class="line"><a name="l00031"></a><span class="lineno">   31</span> <span class="preprocessor">#include &lt;mshadow/base.h&gt;</span></div><div class="line"><a name="l00032"></a><span class="lineno">   32</span> </div><div class="line"><a name="l00034"></a><span class="lineno">   34</span> <span class="preprocessor">#ifdef __JETBRAINS_IDE__</span></div><div class="line"><a name="l00035"></a><span class="lineno">   35</span> <span class="preprocessor">#define __CUDACC__ 1</span></div><div class="line"><a name="l00036"></a><span class="lineno">   36</span> <span class="preprocessor">#define __host__</span></div><div class="line"><a name="l00037"></a><span class="lineno">   37</span> <span class="preprocessor">#define __device__</span></div><div class="line"><a name="l00038"></a><span class="lineno">   38</span> <span class="preprocessor">#define __global__</span></div><div class="line"><a name="l00039"></a><span class="lineno">   39</span> <span class="preprocessor">#define __forceinline__</span></div><div class="line"><a name="l00040"></a><span class="lineno">   40</span> <span class="preprocessor">#define __shared__</span></div><div class="line"><a name="l00041"></a><span class="lineno">   41</span> <span class="keyword">inline</span> <span class="keywordtype">void</span> __syncthreads() {}</div><div class="line"><a name="l00042"></a><span class="lineno">   42</span> <span class="keyword">inline</span> <span class="keywordtype">void</span> __threadfence_block() {}</div><div class="line"><a name="l00043"></a><span class="lineno">   43</span> <span class="keyword">template</span>&lt;<span class="keyword">class</span> T&gt; <span class="keyword">inline</span> T __clz(<span class="keyword">const</span> T val) { <span class="keywordflow">return</span> val; }</div><div class="line"><a name="l00044"></a><span class="lineno">   44</span> <span class="keyword">struct </span>__cuda_fake_struct { <span class="keywordtype">int</span> x; <span class="keywordtype">int</span> y; <span class="keywordtype">int</span> z; };</div><div class="line"><a name="l00045"></a><span class="lineno">   45</span> <span class="keyword">extern</span> __cuda_fake_struct blockDim;</div><div class="line"><a name="l00046"></a><span class="lineno">   46</span> <span class="keyword">extern</span> __cuda_fake_struct threadIdx;</div><div class="line"><a name="l00047"></a><span class="lineno">   47</span> <span class="keyword">extern</span> __cuda_fake_struct blockIdx;</div><div class="line"><a name="l00048"></a><span class="lineno">   48</span> <span class="preprocessor">#endif</span></div><div class="line"><a name="l00049"></a><span class="lineno">   49</span> </div><div class="line"><a name="l00050"></a><span class="lineno">   50</span> <span class="preprocessor">#if MXNET_USE_CUDA</span></div><div class="line"><a name="l00051"></a><span class="lineno">   51</span> </div><div class="line"><a name="l00052"></a><span class="lineno">   52</span> <span class="preprocessor">#include &lt;cuda_runtime.h&gt;</span></div><div class="line"><a name="l00053"></a><span class="lineno">   53</span> <span class="preprocessor">#include &lt;cublas_v2.h&gt;</span></div><div class="line"><a name="l00054"></a><span class="lineno">   54</span> <span class="preprocessor">#include &lt;curand.h&gt;</span></div><div class="line"><a name="l00055"></a><span class="lineno">   55</span> </div><div class="line"><a name="l00060"></a><span class="lineno">   60</span> <span class="preprocessor">#ifdef __CUDACC__</span></div><div class="line"><a name="l00061"></a><span class="lineno">   61</span> <span class="keyword">inline</span> __device__ <span class="keywordtype">bool</span> __is_supported_cuda_architecture() {</div><div class="line"><a name="l00062"></a><span class="lineno">   62</span> <span class="preprocessor">#if defined(__CUDA_ARCH__) &amp;&amp; __CUDA_ARCH__ &lt; 300</span></div><div class="line"><a name="l00063"></a><span class="lineno">   63</span> <span class="preprocessor">#error "Fermi and earlier GPU architectures are not supported (architecture versions less than 3.0)"</span></div><div class="line"><a name="l00064"></a><span class="lineno">   64</span>   <span class="keywordflow">return</span> <span class="keyword">false</span>;</div><div class="line"><a name="l00065"></a><span class="lineno">   65</span> <span class="preprocessor">#else</span></div><div class="line"><a name="l00066"></a><span class="lineno">   66</span>   <span class="keywordflow">return</span> <span class="keyword">true</span>;</div><div class="line"><a name="l00067"></a><span class="lineno">   67</span> <span class="preprocessor">#endif  // __CUDA_ARCH__ &lt; 300</span></div><div class="line"><a name="l00068"></a><span class="lineno">   68</span> }</div><div class="line"><a name="l00069"></a><span class="lineno">   69</span> <span class="preprocessor">#endif  // __CUDACC__</span></div><div class="line"><a name="l00070"></a><span class="lineno">   70</span> </div><div class="line"><a name="l00075"></a><span class="lineno"><a class="line" href="cuda__utils_8h.html#afc69a418242c5b851993bc2307b1c897">   75</a></span> <span class="preprocessor">#define CHECK_CUDA_ERROR(msg)                                                \</span></div><div class="line"><a name="l00076"></a><span class="lineno">   76</span> <span class="preprocessor">  {                                                                          \</span></div><div class="line"><a name="l00077"></a><span class="lineno">   77</span> <span class="preprocessor">    cudaError_t e = cudaGetLastError();                                      \</span></div><div class="line"><a name="l00078"></a><span class="lineno">   78</span> <span class="preprocessor">    CHECK_EQ(e, cudaSuccess) &lt;&lt; (msg) &lt;&lt; " CUDA: " &lt;&lt; cudaGetErrorString(e); \</span></div><div class="line"><a name="l00079"></a><span class="lineno">   79</span> <span class="preprocessor">  }</span></div><div class="line"><a name="l00080"></a><span class="lineno">   80</span> </div><div class="line"><a name="l00087"></a><span class="lineno"><a class="line" href="cuda__utils_8h.html#a06cc7d24ca66505e69f5ad40009f5e8d">   87</a></span> <span class="preprocessor">#define CUDA_CALL(func)                                            \</span></div><div class="line"><a name="l00088"></a><span class="lineno">   88</span> <span class="preprocessor">  {                                                                \</span></div><div class="line"><a name="l00089"></a><span class="lineno">   89</span> <span class="preprocessor">    cudaError_t e = (func);                                        \</span></div><div class="line"><a name="l00090"></a><span class="lineno">   90</span> <span class="preprocessor">    CHECK(e == cudaSuccess || e == cudaErrorCudartUnloading)       \</span></div><div class="line"><a name="l00091"></a><span class="lineno">   91</span> <span class="preprocessor">        &lt;&lt; "CUDA: " &lt;&lt; cudaGetErrorString(e);                      \</span></div><div class="line"><a name="l00092"></a><span class="lineno">   92</span> <span class="preprocessor">  }</span></div><div class="line"><a name="l00093"></a><span class="lineno">   93</span> </div><div class="line"><a name="l00100"></a><span class="lineno"><a class="line" href="cuda__utils_8h.html#a685d7ca3c9370ff471665abcacdeb381">  100</a></span> <span class="preprocessor">#define CUBLAS_CALL(func)                                       \</span></div><div class="line"><a name="l00101"></a><span class="lineno">  101</span> <span class="preprocessor">  {                                                             \</span></div><div class="line"><a name="l00102"></a><span class="lineno">  102</span> <span class="preprocessor">    cublasStatus_t e = (func);                                  \</span></div><div class="line"><a name="l00103"></a><span class="lineno">  103</span> <span class="preprocessor">    CHECK_EQ(e, CUBLAS_STATUS_SUCCESS)                          \</span></div><div class="line"><a name="l00104"></a><span class="lineno">  104</span> <span class="preprocessor">        &lt;&lt; "cuBLAS: " &lt;&lt; mxnet::common::cuda::CublasGetErrorString(e); \</span></div><div class="line"><a name="l00105"></a><span class="lineno">  105</span> <span class="preprocessor">  }</span></div><div class="line"><a name="l00106"></a><span class="lineno">  106</span> </div><div class="line"><a name="l00113"></a><span class="lineno"><a class="line" href="cuda__utils_8h.html#ab38940ff6950f84102baa4573675b670">  113</a></span> <span class="preprocessor">#define CUSOLVER_CALL(func)                                         \</span></div><div class="line"><a name="l00114"></a><span class="lineno">  114</span> <span class="preprocessor">  {                                                                 \</span></div><div class="line"><a name="l00115"></a><span class="lineno">  115</span> <span class="preprocessor">    cusolverStatus_t e = (func);                                    \</span></div><div class="line"><a name="l00116"></a><span class="lineno">  116</span> <span class="preprocessor">    CHECK_EQ(e, CUSOLVER_STATUS_SUCCESS)                            \</span></div><div class="line"><a name="l00117"></a><span class="lineno">  117</span> <span class="preprocessor">        &lt;&lt; "cuSolver: " &lt;&lt; mxnet::common::cuda::CusolverGetErrorString(e); \</span></div><div class="line"><a name="l00118"></a><span class="lineno">  118</span> <span class="preprocessor">  }</span></div><div class="line"><a name="l00119"></a><span class="lineno">  119</span> </div><div class="line"><a name="l00126"></a><span class="lineno"><a class="line" href="cuda__utils_8h.html#a82d7233550780a8c186e79c24aed8406">  126</a></span> <span class="preprocessor">#define CURAND_CALL(func)                                       \</span></div><div class="line"><a name="l00127"></a><span class="lineno">  127</span> <span class="preprocessor">  {                                                             \</span></div><div class="line"><a name="l00128"></a><span class="lineno">  128</span> <span class="preprocessor">    curandStatus_t e = (func);                                  \</span></div><div class="line"><a name="l00129"></a><span class="lineno">  129</span> <span class="preprocessor">    CHECK_EQ(e, CURAND_STATUS_SUCCESS)                          \</span></div><div class="line"><a name="l00130"></a><span class="lineno">  130</span> <span class="preprocessor">        &lt;&lt; "cuRAND: " &lt;&lt; mxnet::common::cuda::CurandGetErrorString(e); \</span></div><div class="line"><a name="l00131"></a><span class="lineno">  131</span> <span class="preprocessor">  }</span></div><div class="line"><a name="l00132"></a><span class="lineno">  132</span> </div><div class="line"><a name="l00139"></a><span class="lineno"><a class="line" href="cuda__utils_8h.html#a63b6d263b94df9e33474894ad02b792d">  139</a></span> <span class="preprocessor">#define NVRTC_CALL(x)                                   \</span></div><div class="line"><a name="l00140"></a><span class="lineno">  140</span> <span class="preprocessor">  {                                                     \</span></div><div class="line"><a name="l00141"></a><span class="lineno">  141</span> <span class="preprocessor">    nvrtcResult result = x;                             \</span></div><div class="line"><a name="l00142"></a><span class="lineno">  142</span> <span class="preprocessor">    CHECK_EQ(result, NVRTC_SUCCESS)                     \</span></div><div class="line"><a name="l00143"></a><span class="lineno">  143</span> <span class="preprocessor">      &lt;&lt; #x " failed with error "                       \</span></div><div class="line"><a name="l00144"></a><span class="lineno">  144</span> <span class="preprocessor">      &lt;&lt; nvrtcGetErrorString(result);                   \</span></div><div class="line"><a name="l00145"></a><span class="lineno">  145</span> <span class="preprocessor">  }</span></div><div class="line"><a name="l00146"></a><span class="lineno">  146</span> </div><div class="line"><a name="l00153"></a><span class="lineno"><a class="line" href="cuda__utils_8h.html#a0d9b08b9ef45122c54bf5a121aeab5c3">  153</a></span> <span class="preprocessor">#define CUDA_DRIVER_CALL(func)                                          \</span></div><div class="line"><a name="l00154"></a><span class="lineno">  154</span> <span class="preprocessor">  {                                                                     \</span></div><div class="line"><a name="l00155"></a><span class="lineno">  155</span> <span class="preprocessor">    CUresult e = (func);                                                \</span></div><div class="line"><a name="l00156"></a><span class="lineno">  156</span> <span class="preprocessor">    if (e != CUDA_SUCCESS) {                                            \</span></div><div class="line"><a name="l00157"></a><span class="lineno">  157</span> <span class="preprocessor">      char const * err_msg = nullptr;                                         \</span></div><div class="line"><a name="l00158"></a><span class="lineno">  158</span> <span class="preprocessor">      if (cuGetErrorString(e, &amp;err_msg) == CUDA_ERROR_INVALID_VALUE) {  \</span></div><div class="line"><a name="l00159"></a><span class="lineno">  159</span> <span class="preprocessor">        LOG(FATAL) &lt;&lt; "CUDA Driver: Unknown error " &lt;&lt; e;               \</span></div><div class="line"><a name="l00160"></a><span class="lineno">  160</span> <span class="preprocessor">      } else {                                                          \</span></div><div class="line"><a name="l00161"></a><span class="lineno">  161</span> <span class="preprocessor">        LOG(FATAL) &lt;&lt; "CUDA Driver: " &lt;&lt; err_msg;                       \</span></div><div class="line"><a name="l00162"></a><span class="lineno">  162</span> <span class="preprocessor">      }                                                                 \</span></div><div class="line"><a name="l00163"></a><span class="lineno">  163</span> <span class="preprocessor">    }                                                                   \</span></div><div class="line"><a name="l00164"></a><span class="lineno">  164</span> <span class="preprocessor">  }</span></div><div class="line"><a name="l00165"></a><span class="lineno">  165</span> </div><div class="line"><a name="l00166"></a><span class="lineno">  166</span> </div><div class="line"><a name="l00167"></a><span class="lineno">  167</span> <span class="preprocessor">#if !defined(_MSC_VER)</span></div><div class="line"><a name="l00168"></a><span class="lineno"><a class="line" href="cuda__utils_8h.html#a685e3713856baaafb1d4edea43725c83">  168</a></span> <span class="preprocessor">#define CUDA_UNROLL _Pragma("unroll")</span></div><div class="line"><a name="l00169"></a><span class="lineno"><a class="line" href="cuda__utils_8h.html#addb314f15d765a2ba72ae37dab23c03b">  169</a></span> <span class="preprocessor">#define CUDA_NOUNROLL _Pragma("nounroll")</span></div><div class="line"><a name="l00170"></a><span class="lineno">  170</span> <span class="preprocessor">#else</span></div><div class="line"><a name="l00171"></a><span class="lineno">  171</span> <span class="preprocessor">#define CUDA_UNROLL</span></div><div class="line"><a name="l00172"></a><span class="lineno">  172</span> <span class="preprocessor">#define CUDA_NOUNROLL</span></div><div class="line"><a name="l00173"></a><span class="lineno">  173</span> <span class="preprocessor">#endif</span></div><div class="line"><a name="l00174"></a><span class="lineno">  174</span> </div><div class="line"><a name="l00175"></a><span class="lineno">  175</span> <span class="keyword">namespace </span><a class="code" href="namespacemxnet.html">mxnet</a> {</div><div class="line"><a name="l00176"></a><span class="lineno">  176</span> <span class="keyword">namespace </span>common {</div><div class="line"><a name="l00178"></a><span class="lineno"><a class="line" href="namespacemxnet_1_1common_1_1cuda.html">  178</a></span> <span class="keyword">namespace </span>cuda {</div><div class="line"><a name="l00184"></a><span class="lineno"><a class="line" href="namespacemxnet_1_1common_1_1cuda.html#a9feee613a4f16a954dd68e55345a72ac">  184</a></span> <span class="keyword">inline</span> <span class="keyword">const</span> <span class="keywordtype">char</span>* <a class="code" href="namespacemxnet_1_1common_1_1cuda.html#a9feee613a4f16a954dd68e55345a72ac">CublasGetErrorString</a>(cublasStatus_t error) {</div><div class="line"><a name="l00185"></a><span class="lineno">  185</span>   <span class="keywordflow">switch</span> (error) {</div><div class="line"><a name="l00186"></a><span class="lineno">  186</span>   <span class="keywordflow">case</span> CUBLAS_STATUS_SUCCESS:</div><div class="line"><a name="l00187"></a><span class="lineno">  187</span>     <span class="keywordflow">return</span> <span class="stringliteral">"CUBLAS_STATUS_SUCCESS"</span>;</div><div class="line"><a name="l00188"></a><span class="lineno">  188</span>   <span class="keywordflow">case</span> CUBLAS_STATUS_NOT_INITIALIZED:</div><div class="line"><a name="l00189"></a><span class="lineno">  189</span>     <span class="keywordflow">return</span> <span class="stringliteral">"CUBLAS_STATUS_NOT_INITIALIZED"</span>;</div><div class="line"><a name="l00190"></a><span class="lineno">  190</span>   <span class="keywordflow">case</span> CUBLAS_STATUS_ALLOC_FAILED:</div><div class="line"><a name="l00191"></a><span class="lineno">  191</span>     <span class="keywordflow">return</span> <span class="stringliteral">"CUBLAS_STATUS_ALLOC_FAILED"</span>;</div><div class="line"><a name="l00192"></a><span class="lineno">  192</span>   <span class="keywordflow">case</span> CUBLAS_STATUS_INVALID_VALUE:</div><div class="line"><a name="l00193"></a><span class="lineno">  193</span>     <span class="keywordflow">return</span> <span class="stringliteral">"CUBLAS_STATUS_INVALID_VALUE"</span>;</div><div class="line"><a name="l00194"></a><span class="lineno">  194</span>   <span class="keywordflow">case</span> CUBLAS_STATUS_ARCH_MISMATCH:</div><div class="line"><a name="l00195"></a><span class="lineno">  195</span>     <span class="keywordflow">return</span> <span class="stringliteral">"CUBLAS_STATUS_ARCH_MISMATCH"</span>;</div><div class="line"><a name="l00196"></a><span class="lineno">  196</span>   <span class="keywordflow">case</span> CUBLAS_STATUS_MAPPING_ERROR:</div><div class="line"><a name="l00197"></a><span class="lineno">  197</span>     <span class="keywordflow">return</span> <span class="stringliteral">"CUBLAS_STATUS_MAPPING_ERROR"</span>;</div><div class="line"><a name="l00198"></a><span class="lineno">  198</span>   <span class="keywordflow">case</span> CUBLAS_STATUS_EXECUTION_FAILED:</div><div class="line"><a name="l00199"></a><span class="lineno">  199</span>     <span class="keywordflow">return</span> <span class="stringliteral">"CUBLAS_STATUS_EXECUTION_FAILED"</span>;</div><div class="line"><a name="l00200"></a><span class="lineno">  200</span>   <span class="keywordflow">case</span> CUBLAS_STATUS_INTERNAL_ERROR:</div><div class="line"><a name="l00201"></a><span class="lineno">  201</span>     <span class="keywordflow">return</span> <span class="stringliteral">"CUBLAS_STATUS_INTERNAL_ERROR"</span>;</div><div class="line"><a name="l00202"></a><span class="lineno">  202</span>   <span class="keywordflow">case</span> CUBLAS_STATUS_NOT_SUPPORTED:</div><div class="line"><a name="l00203"></a><span class="lineno">  203</span>     <span class="keywordflow">return</span> <span class="stringliteral">"CUBLAS_STATUS_NOT_SUPPORTED"</span>;</div><div class="line"><a name="l00204"></a><span class="lineno">  204</span>   <span class="keywordflow">default</span>:</div><div class="line"><a name="l00205"></a><span class="lineno">  205</span>     <span class="keywordflow">break</span>;</div><div class="line"><a name="l00206"></a><span class="lineno">  206</span>   }</div><div class="line"><a name="l00207"></a><span class="lineno">  207</span>   <span class="keywordflow">return</span> <span class="stringliteral">"Unknown cuBLAS status"</span>;</div><div class="line"><a name="l00208"></a><span class="lineno">  208</span> }</div><div class="line"><a name="l00209"></a><span class="lineno">  209</span> </div><div class="line"><a name="l00215"></a><span class="lineno"><a class="line" href="namespacemxnet_1_1common_1_1cuda.html#abf9bcb4cb696e9ae61b818510dac39c8">  215</a></span> <span class="keyword">inline</span> <span class="keyword">const</span> <span class="keywordtype">char</span>* <a class="code" href="namespacemxnet_1_1common_1_1cuda.html#abf9bcb4cb696e9ae61b818510dac39c8">CusolverGetErrorString</a>(cusolverStatus_t error) {</div><div class="line"><a name="l00216"></a><span class="lineno">  216</span>   <span class="keywordflow">switch</span> (error) {</div><div class="line"><a name="l00217"></a><span class="lineno">  217</span>   <span class="keywordflow">case</span> CUSOLVER_STATUS_SUCCESS:</div><div class="line"><a name="l00218"></a><span class="lineno">  218</span>     <span class="keywordflow">return</span> <span class="stringliteral">"CUSOLVER_STATUS_SUCCESS"</span>;</div><div class="line"><a name="l00219"></a><span class="lineno">  219</span>   <span class="keywordflow">case</span> CUSOLVER_STATUS_NOT_INITIALIZED:</div><div class="line"><a name="l00220"></a><span class="lineno">  220</span>     <span class="keywordflow">return</span> <span class="stringliteral">"CUSOLVER_STATUS_NOT_INITIALIZED"</span>;</div><div class="line"><a name="l00221"></a><span class="lineno">  221</span>   <span class="keywordflow">case</span> CUSOLVER_STATUS_ALLOC_FAILED:</div><div class="line"><a name="l00222"></a><span class="lineno">  222</span>     <span class="keywordflow">return</span> <span class="stringliteral">"CUSOLVER_STATUS_ALLOC_FAILED"</span>;</div><div class="line"><a name="l00223"></a><span class="lineno">  223</span>   <span class="keywordflow">case</span> CUSOLVER_STATUS_INVALID_VALUE:</div><div class="line"><a name="l00224"></a><span class="lineno">  224</span>     <span class="keywordflow">return</span> <span class="stringliteral">"CUSOLVER_STATUS_INVALID_VALUE"</span>;</div><div class="line"><a name="l00225"></a><span class="lineno">  225</span>   <span class="keywordflow">case</span> CUSOLVER_STATUS_ARCH_MISMATCH:</div><div class="line"><a name="l00226"></a><span class="lineno">  226</span>     <span class="keywordflow">return</span> <span class="stringliteral">"CUSOLVER_STATUS_ARCH_MISMATCH"</span>;</div><div class="line"><a name="l00227"></a><span class="lineno">  227</span>   <span class="keywordflow">case</span> CUSOLVER_STATUS_EXECUTION_FAILED:</div><div class="line"><a name="l00228"></a><span class="lineno">  228</span>     <span class="keywordflow">return</span> <span class="stringliteral">"CUSOLVER_STATUS_EXECUTION_FAILED"</span>;</div><div class="line"><a name="l00229"></a><span class="lineno">  229</span>   <span class="keywordflow">case</span> CUSOLVER_STATUS_INTERNAL_ERROR:</div><div class="line"><a name="l00230"></a><span class="lineno">  230</span>     <span class="keywordflow">return</span> <span class="stringliteral">"CUSOLVER_STATUS_INTERNAL_ERROR"</span>;</div><div class="line"><a name="l00231"></a><span class="lineno">  231</span>   <span class="keywordflow">case</span> CUSOLVER_STATUS_MATRIX_TYPE_NOT_SUPPORTED:</div><div class="line"><a name="l00232"></a><span class="lineno">  232</span>     <span class="keywordflow">return</span> <span class="stringliteral">"CUSOLVER_STATUS_MATRIX_TYPE_NOT_SUPPORTED"</span>;</div><div class="line"><a name="l00233"></a><span class="lineno">  233</span>   <span class="keywordflow">default</span>:</div><div class="line"><a name="l00234"></a><span class="lineno">  234</span>     <span class="keywordflow">break</span>;</div><div class="line"><a name="l00235"></a><span class="lineno">  235</span>   }</div><div class="line"><a name="l00236"></a><span class="lineno">  236</span>   <span class="keywordflow">return</span> <span class="stringliteral">"Unknown cuSOLVER status"</span>;</div><div class="line"><a name="l00237"></a><span class="lineno">  237</span> }</div><div class="line"><a name="l00238"></a><span class="lineno">  238</span> </div><div class="line"><a name="l00244"></a><span class="lineno"><a class="line" href="namespacemxnet_1_1common_1_1cuda.html#a97c06b2f4d26445a7386b0f54fae1feb">  244</a></span> <span class="keyword">inline</span> <span class="keyword">const</span> <span class="keywordtype">char</span>* <a class="code" href="namespacemxnet_1_1common_1_1cuda.html#a97c06b2f4d26445a7386b0f54fae1feb">CurandGetErrorString</a>(curandStatus_t status) {</div><div class="line"><a name="l00245"></a><span class="lineno">  245</span>   <span class="keywordflow">switch</span> (status) {</div><div class="line"><a name="l00246"></a><span class="lineno">  246</span>   <span class="keywordflow">case</span> CURAND_STATUS_SUCCESS:</div><div class="line"><a name="l00247"></a><span class="lineno">  247</span>     <span class="keywordflow">return</span> <span class="stringliteral">"CURAND_STATUS_SUCCESS"</span>;</div><div class="line"><a name="l00248"></a><span class="lineno">  248</span>   <span class="keywordflow">case</span> CURAND_STATUS_VERSION_MISMATCH:</div><div class="line"><a name="l00249"></a><span class="lineno">  249</span>     <span class="keywordflow">return</span> <span class="stringliteral">"CURAND_STATUS_VERSION_MISMATCH"</span>;</div><div class="line"><a name="l00250"></a><span class="lineno">  250</span>   <span class="keywordflow">case</span> CURAND_STATUS_NOT_INITIALIZED:</div><div class="line"><a name="l00251"></a><span class="lineno">  251</span>     <span class="keywordflow">return</span> <span class="stringliteral">"CURAND_STATUS_NOT_INITIALIZED"</span>;</div><div class="line"><a name="l00252"></a><span class="lineno">  252</span>   <span class="keywordflow">case</span> CURAND_STATUS_ALLOCATION_FAILED:</div><div class="line"><a name="l00253"></a><span class="lineno">  253</span>     <span class="keywordflow">return</span> <span class="stringliteral">"CURAND_STATUS_ALLOCATION_FAILED"</span>;</div><div class="line"><a name="l00254"></a><span class="lineno">  254</span>   <span class="keywordflow">case</span> CURAND_STATUS_TYPE_ERROR:</div><div class="line"><a name="l00255"></a><span class="lineno">  255</span>     <span class="keywordflow">return</span> <span class="stringliteral">"CURAND_STATUS_TYPE_ERROR"</span>;</div><div class="line"><a name="l00256"></a><span class="lineno">  256</span>   <span class="keywordflow">case</span> CURAND_STATUS_OUT_OF_RANGE:</div><div class="line"><a name="l00257"></a><span class="lineno">  257</span>     <span class="keywordflow">return</span> <span class="stringliteral">"CURAND_STATUS_OUT_OF_RANGE"</span>;</div><div class="line"><a name="l00258"></a><span class="lineno">  258</span>   <span class="keywordflow">case</span> CURAND_STATUS_LENGTH_NOT_MULTIPLE:</div><div class="line"><a name="l00259"></a><span class="lineno">  259</span>     <span class="keywordflow">return</span> <span class="stringliteral">"CURAND_STATUS_LENGTH_NOT_MULTIPLE"</span>;</div><div class="line"><a name="l00260"></a><span class="lineno">  260</span>   <span class="keywordflow">case</span> CURAND_STATUS_DOUBLE_PRECISION_REQUIRED:</div><div class="line"><a name="l00261"></a><span class="lineno">  261</span>     <span class="keywordflow">return</span> <span class="stringliteral">"CURAND_STATUS_DOUBLE_PRECISION_REQUIRED"</span>;</div><div class="line"><a name="l00262"></a><span class="lineno">  262</span>   <span class="keywordflow">case</span> CURAND_STATUS_LAUNCH_FAILURE:</div><div class="line"><a name="l00263"></a><span class="lineno">  263</span>     <span class="keywordflow">return</span> <span class="stringliteral">"CURAND_STATUS_LAUNCH_FAILURE"</span>;</div><div class="line"><a name="l00264"></a><span class="lineno">  264</span>   <span class="keywordflow">case</span> CURAND_STATUS_PREEXISTING_FAILURE:</div><div class="line"><a name="l00265"></a><span class="lineno">  265</span>     <span class="keywordflow">return</span> <span class="stringliteral">"CURAND_STATUS_PREEXISTING_FAILURE"</span>;</div><div class="line"><a name="l00266"></a><span class="lineno">  266</span>   <span class="keywordflow">case</span> CURAND_STATUS_INITIALIZATION_FAILED:</div><div class="line"><a name="l00267"></a><span class="lineno">  267</span>     <span class="keywordflow">return</span> <span class="stringliteral">"CURAND_STATUS_INITIALIZATION_FAILED"</span>;</div><div class="line"><a name="l00268"></a><span class="lineno">  268</span>   <span class="keywordflow">case</span> CURAND_STATUS_ARCH_MISMATCH:</div><div class="line"><a name="l00269"></a><span class="lineno">  269</span>     <span class="keywordflow">return</span> <span class="stringliteral">"CURAND_STATUS_ARCH_MISMATCH"</span>;</div><div class="line"><a name="l00270"></a><span class="lineno">  270</span>   <span class="keywordflow">case</span> CURAND_STATUS_INTERNAL_ERROR:</div><div class="line"><a name="l00271"></a><span class="lineno">  271</span>     <span class="keywordflow">return</span> <span class="stringliteral">"CURAND_STATUS_INTERNAL_ERROR"</span>;</div><div class="line"><a name="l00272"></a><span class="lineno">  272</span>   }</div><div class="line"><a name="l00273"></a><span class="lineno">  273</span>   <span class="keywordflow">return</span> <span class="stringliteral">"Unknown cuRAND status"</span>;</div><div class="line"><a name="l00274"></a><span class="lineno">  274</span> }</div><div class="line"><a name="l00275"></a><span class="lineno">  275</span> </div><div class="line"><a name="l00276"></a><span class="lineno">  276</span> <span class="keyword">template</span> &lt;<span class="keyword">typename</span> DType&gt;</div><div class="line"><a name="l00277"></a><span class="lineno"><a class="line" href="namespacemxnet_1_1common_1_1cuda.html#a6f3ee04eb382c57e10916108db3efd80">  277</a></span> <span class="keyword">inline</span> DType __device__ <a class="code" href="namespacemxnet_1_1common_1_1cuda.html#a6f3ee04eb382c57e10916108db3efd80">CudaMax</a>(DType a, DType b) {</div><div class="line"><a name="l00278"></a><span class="lineno">  278</span>     <span class="keywordflow">return</span> a &gt; b ? a : b;</div><div class="line"><a name="l00279"></a><span class="lineno">  279</span> }</div><div class="line"><a name="l00280"></a><span class="lineno">  280</span> </div><div class="line"><a name="l00281"></a><span class="lineno">  281</span> <span class="keyword">template</span> &lt;<span class="keyword">typename</span> DType&gt;</div><div class="line"><a name="l00282"></a><span class="lineno"><a class="line" href="namespacemxnet_1_1common_1_1cuda.html#a03888f252f813f6d052ae84bf8801498">  282</a></span> <span class="keyword">inline</span> DType __device__ <a class="code" href="namespacemxnet_1_1common_1_1cuda.html#a03888f252f813f6d052ae84bf8801498">CudaMin</a>(DType a, DType b) {</div><div class="line"><a name="l00283"></a><span class="lineno">  283</span>     <span class="keywordflow">return</span> a &lt; b ? a : b;</div><div class="line"><a name="l00284"></a><span class="lineno">  284</span> }</div><div class="line"><a name="l00285"></a><span class="lineno">  285</span> </div><div class="line"><a name="l00286"></a><span class="lineno"><a class="line" href="classmxnet_1_1common_1_1cuda_1_1DeviceStore.html">  286</a></span> <span class="keyword">class </span><a class="code" href="classmxnet_1_1common_1_1cuda_1_1DeviceStore.html">DeviceStore</a> {</div><div class="line"><a name="l00287"></a><span class="lineno">  287</span>  <span class="keyword">public</span>:</div><div class="line"><a name="l00289"></a><span class="lineno"><a class="line" href="classmxnet_1_1common_1_1cuda_1_1DeviceStore.html#ad9878a09a93d4fcaf9d0639b3613d9f7">  289</a></span>   <span class="keyword">explicit</span> <a class="code" href="classmxnet_1_1common_1_1cuda_1_1DeviceStore.html#ad9878a09a93d4fcaf9d0639b3613d9f7">DeviceStore</a>(<span class="keywordtype">int</span> requested_device = -1, <span class="keywordtype">bool</span> restore = <span class="keyword">true</span>) :</div><div class="line"><a name="l00290"></a><span class="lineno">  290</span>     restore_device_(-1),</div><div class="line"><a name="l00291"></a><span class="lineno">  291</span>     current_device_(requested_device),</div><div class="line"><a name="l00292"></a><span class="lineno">  292</span>     restore_(restore) {</div><div class="line"><a name="l00293"></a><span class="lineno">  293</span>     <span class="keywordflow">if</span> (restore_)</div><div class="line"><a name="l00294"></a><span class="lineno">  294</span>       <a class="code" href="cuda__utils_8h.html#a06cc7d24ca66505e69f5ad40009f5e8d">CUDA_CALL</a>(cudaGetDevice(&amp;restore_device_));</div><div class="line"><a name="l00295"></a><span class="lineno">  295</span>     <span class="keywordflow">if</span> (requested_device != restore_device_) {</div><div class="line"><a name="l00296"></a><span class="lineno">  296</span>       SetDevice(requested_device);</div><div class="line"><a name="l00297"></a><span class="lineno">  297</span>     }</div><div class="line"><a name="l00298"></a><span class="lineno">  298</span>   }</div><div class="line"><a name="l00299"></a><span class="lineno">  299</span> </div><div class="line"><a name="l00300"></a><span class="lineno"><a class="line" href="classmxnet_1_1common_1_1cuda_1_1DeviceStore.html#a701d38ae493688ee2136995fe8611aa0">  300</a></span>   <a class="code" href="classmxnet_1_1common_1_1cuda_1_1DeviceStore.html#a701d38ae493688ee2136995fe8611aa0">~DeviceStore</a>() {</div><div class="line"><a name="l00301"></a><span class="lineno">  301</span>     <span class="keywordflow">if</span> (restore_ &amp;&amp;</div><div class="line"><a name="l00302"></a><span class="lineno">  302</span>         current_device_ != restore_device_ &amp;&amp;</div><div class="line"><a name="l00303"></a><span class="lineno">  303</span>         current_device_ != -1 &amp;&amp;</div><div class="line"><a name="l00304"></a><span class="lineno">  304</span>         restore_device_ != -1)</div><div class="line"><a name="l00305"></a><span class="lineno">  305</span>       <a class="code" href="cuda__utils_8h.html#a06cc7d24ca66505e69f5ad40009f5e8d">CUDA_CALL</a>(cudaSetDevice(restore_device_));</div><div class="line"><a name="l00306"></a><span class="lineno">  306</span>   }</div><div class="line"><a name="l00307"></a><span class="lineno">  307</span> </div><div class="line"><a name="l00308"></a><span class="lineno"><a class="line" href="classmxnet_1_1common_1_1cuda_1_1DeviceStore.html#a01163fd4915e74bdd81dd7305917f0e4">  308</a></span>   <span class="keywordtype">void</span> <a class="code" href="classmxnet_1_1common_1_1cuda_1_1DeviceStore.html#a01163fd4915e74bdd81dd7305917f0e4">SetDevice</a>(<span class="keywordtype">int</span> device) {</div><div class="line"><a name="l00309"></a><span class="lineno">  309</span>     <span class="keywordflow">if</span> (device != -1) {</div><div class="line"><a name="l00310"></a><span class="lineno">  310</span>       <a class="code" href="cuda__utils_8h.html#a06cc7d24ca66505e69f5ad40009f5e8d">CUDA_CALL</a>(cudaSetDevice(device));</div><div class="line"><a name="l00311"></a><span class="lineno">  311</span>       current_device_ = device;</div><div class="line"><a name="l00312"></a><span class="lineno">  312</span>     }</div><div class="line"><a name="l00313"></a><span class="lineno">  313</span>   }</div><div class="line"><a name="l00314"></a><span class="lineno">  314</span> </div><div class="line"><a name="l00315"></a><span class="lineno">  315</span>  <span class="keyword">private</span>:</div><div class="line"><a name="l00316"></a><span class="lineno">  316</span>   <span class="keywordtype">int</span> restore_device_;</div><div class="line"><a name="l00317"></a><span class="lineno">  317</span>   <span class="keywordtype">int</span> current_device_;</div><div class="line"><a name="l00318"></a><span class="lineno">  318</span>   <span class="keywordtype">bool</span> restore_;</div><div class="line"><a name="l00319"></a><span class="lineno">  319</span> };</div><div class="line"><a name="l00320"></a><span class="lineno">  320</span> </div><div class="line"><a name="l00321"></a><span class="lineno">  321</span> }  <span class="comment">// namespace cuda</span></div><div class="line"><a name="l00322"></a><span class="lineno">  322</span> }  <span class="comment">// namespace common</span></div><div class="line"><a name="l00323"></a><span class="lineno">  323</span> }  <span class="comment">// namespace mxnet</span></div><div class="line"><a name="l00324"></a><span class="lineno">  324</span> </div><div class="line"><a name="l00330"></a><span class="lineno"><a class="line" href="cuda__utils_8h.html#aa79f548df23452162de37663f171e99d">  330</a></span> <span class="keyword">inline</span> <span class="keywordtype">int</span> <a class="code" href="cuda__utils_8h.html#aa79f548df23452162de37663f171e99d">ComputeCapabilityMajor</a>(<span class="keywordtype">int</span> device_id) {</div><div class="line"><a name="l00331"></a><span class="lineno">  331</span>   <span class="keywordtype">int</span> major = 0;</div><div class="line"><a name="l00332"></a><span class="lineno">  332</span>   <a class="code" href="cuda__utils_8h.html#a06cc7d24ca66505e69f5ad40009f5e8d">CUDA_CALL</a>(cudaDeviceGetAttribute(&amp;major,</div><div class="line"><a name="l00333"></a><span class="lineno">  333</span>                                    cudaDevAttrComputeCapabilityMajor, device_id));</div><div class="line"><a name="l00334"></a><span class="lineno">  334</span>   <span class="keywordflow">return</span> major;</div><div class="line"><a name="l00335"></a><span class="lineno">  335</span> }</div><div class="line"><a name="l00336"></a><span class="lineno">  336</span> </div><div class="line"><a name="l00342"></a><span class="lineno"><a class="line" href="cuda__utils_8h.html#a7c16e8770e4f399cabed1fc231ffd9b6">  342</a></span> <span class="keyword">inline</span> <span class="keywordtype">int</span> <a class="code" href="cuda__utils_8h.html#a7c16e8770e4f399cabed1fc231ffd9b6">ComputeCapabilityMinor</a>(<span class="keywordtype">int</span> device_id) {</div><div class="line"><a name="l00343"></a><span class="lineno">  343</span>   <span class="keywordtype">int</span> minor = 0;</div><div class="line"><a name="l00344"></a><span class="lineno">  344</span>   <a class="code" href="cuda__utils_8h.html#a06cc7d24ca66505e69f5ad40009f5e8d">CUDA_CALL</a>(cudaDeviceGetAttribute(&amp;minor,</div><div class="line"><a name="l00345"></a><span class="lineno">  345</span>                                    cudaDevAttrComputeCapabilityMinor, device_id));</div><div class="line"><a name="l00346"></a><span class="lineno">  346</span>   <span class="keywordflow">return</span> minor;</div><div class="line"><a name="l00347"></a><span class="lineno">  347</span> }</div><div class="line"><a name="l00348"></a><span class="lineno">  348</span> </div><div class="line"><a name="l00354"></a><span class="lineno"><a class="line" href="cuda__utils_8h.html#a9779e3ad0efd0faec7fbe431c0db896d">  354</a></span> <span class="keyword">inline</span> <span class="keywordtype">int</span> <a class="code" href="cuda__utils_8h.html#a9779e3ad0efd0faec7fbe431c0db896d">SMArch</a>(<span class="keywordtype">int</span> device_id) {</div><div class="line"><a name="l00355"></a><span class="lineno">  355</span>   <span class="keyword">auto</span> major = <a class="code" href="cuda__utils_8h.html#aa79f548df23452162de37663f171e99d">ComputeCapabilityMajor</a>(device_id);</div><div class="line"><a name="l00356"></a><span class="lineno">  356</span>   <span class="keyword">auto</span> minor = <a class="code" href="cuda__utils_8h.html#a7c16e8770e4f399cabed1fc231ffd9b6">ComputeCapabilityMinor</a>(device_id);</div><div class="line"><a name="l00357"></a><span class="lineno">  357</span>   <span class="keywordflow">return</span> 10 * major + minor;</div><div class="line"><a name="l00358"></a><span class="lineno">  358</span> }</div><div class="line"><a name="l00359"></a><span class="lineno">  359</span> </div><div class="line"><a name="l00366"></a><span class="lineno"><a class="line" href="cuda__utils_8h.html#afb4268417c1d8886a39142c85c8f188f">  366</a></span> <span class="keyword">inline</span> <span class="keywordtype">bool</span> <a class="code" href="cuda__utils_8h.html#afb4268417c1d8886a39142c85c8f188f">SupportsFloat16Compute</a>(<span class="keywordtype">int</span> device_id) {</div><div class="line"><a name="l00367"></a><span class="lineno">  367</span>   <span class="keywordflow">if</span> (device_id &lt; 0) {</div><div class="line"><a name="l00368"></a><span class="lineno">  368</span>     <span class="keywordflow">return</span> <span class="keyword">false</span>;</div><div class="line"><a name="l00369"></a><span class="lineno">  369</span>   } <span class="keywordflow">else</span> {</div><div class="line"><a name="l00370"></a><span class="lineno">  370</span>     <span class="comment">// Kepler and most Maxwell GPUs do not support fp16 compute</span></div><div class="line"><a name="l00371"></a><span class="lineno">  371</span>     <span class="keywordtype">int</span> computeCapabilityMajor = <a class="code" href="cuda__utils_8h.html#aa79f548df23452162de37663f171e99d">ComputeCapabilityMajor</a>(device_id);</div><div class="line"><a name="l00372"></a><span class="lineno">  372</span>     <span class="keywordflow">return</span> (computeCapabilityMajor &gt; 5) ||</div><div class="line"><a name="l00373"></a><span class="lineno">  373</span>            (computeCapabilityMajor == 5 &amp;&amp; <a class="code" href="cuda__utils_8h.html#a7c16e8770e4f399cabed1fc231ffd9b6">ComputeCapabilityMinor</a>(device_id) &gt;= 3);</div><div class="line"><a name="l00374"></a><span class="lineno">  374</span>   }</div><div class="line"><a name="l00375"></a><span class="lineno">  375</span> }</div><div class="line"><a name="l00376"></a><span class="lineno">  376</span> </div><div class="line"><a name="l00383"></a><span class="lineno"><a class="line" href="cuda__utils_8h.html#af7e22ce6d80d61e8ca37df23880ff1a9">  383</a></span> <span class="keyword">inline</span> <span class="keywordtype">bool</span> <a class="code" href="cuda__utils_8h.html#af7e22ce6d80d61e8ca37df23880ff1a9">SupportsTensorCore</a>(<span class="keywordtype">int</span> device_id) {</div><div class="line"><a name="l00384"></a><span class="lineno">  384</span>   <span class="comment">// Volta (sm_70) supports TensorCore algos</span></div><div class="line"><a name="l00385"></a><span class="lineno">  385</span>   <span class="keywordflow">return</span> device_id &gt;= 0 &amp;&amp;</div><div class="line"><a name="l00386"></a><span class="lineno">  386</span>          <a class="code" href="cuda__utils_8h.html#aa79f548df23452162de37663f171e99d">ComputeCapabilityMajor</a>(device_id) &gt;=7;</div><div class="line"><a name="l00387"></a><span class="lineno">  387</span> }</div><div class="line"><a name="l00388"></a><span class="lineno">  388</span> </div><div class="line"><a name="l00389"></a><span class="lineno">  389</span> <span class="comment">// The policy if the user hasn't set the environment variable MXNET_CUDA_ALLOW_TENSOR_CORE</span></div><div class="line"><a name="l00390"></a><span class="lineno"><a class="line" href="cuda__utils_8h.html#aa7ba00b841d6b7ba443b0e58dac9ab88">  390</a></span> <span class="preprocessor">#define MXNET_CUDA_ALLOW_TENSOR_CORE_DEFAULT true</span></div><div class="line"><a name="l00391"></a><span class="lineno">  391</span> </div><div class="line"><a name="l00396"></a><span class="lineno"><a class="line" href="cuda__utils_8h.html#a464dee13053e3b0b1006c6307069196c">  396</a></span> <span class="keyword">inline</span> <span class="keywordtype">bool</span> <a class="code" href="cuda__utils_8h.html#a464dee13053e3b0b1006c6307069196c">GetEnvAllowTensorCore</a>() {</div><div class="line"><a name="l00397"></a><span class="lineno">  397</span>   <span class="comment">// Since these statics are in the '.h' file, they will exist and will be set</span></div><div class="line"><a name="l00398"></a><span class="lineno">  398</span>   <span class="comment">// separately in each compilation unit.  Not ideal, but cleaner than creating a</span></div><div class="line"><a name="l00399"></a><span class="lineno">  399</span>   <span class="comment">// cuda_utils.cc solely to have a single instance and initialization.</span></div><div class="line"><a name="l00400"></a><span class="lineno">  400</span>   <span class="keyword">static</span> <span class="keywordtype">bool</span> allow_tensor_core = <span class="keyword">false</span>;</div><div class="line"><a name="l00401"></a><span class="lineno">  401</span>   <span class="keyword">static</span> <span class="keywordtype">bool</span> is_set = <span class="keyword">false</span>;</div><div class="line"><a name="l00402"></a><span class="lineno">  402</span>   <span class="keywordflow">if</span> (!is_set) {</div><div class="line"><a name="l00403"></a><span class="lineno">  403</span>     <span class="comment">// Use of optional&lt;bool&gt; here permits: "0", "1", "true" and "false" to all be legal.</span></div><div class="line"><a name="l00404"></a><span class="lineno">  404</span>     <span class="keywordtype">bool</span> default_value = <a class="code" href="cuda__utils_8h.html#aa7ba00b841d6b7ba443b0e58dac9ab88">MXNET_CUDA_ALLOW_TENSOR_CORE_DEFAULT</a>;</div><div class="line"><a name="l00405"></a><span class="lineno">  405</span>     allow_tensor_core = dmlc::GetEnv(<span class="stringliteral">"MXNET_CUDA_ALLOW_TENSOR_CORE"</span>,</div><div class="line"><a name="l00406"></a><span class="lineno">  406</span>                                      dmlc::optional&lt;bool&gt;(default_value)).value();</div><div class="line"><a name="l00407"></a><span class="lineno">  407</span>     is_set = <span class="keyword">true</span>;</div><div class="line"><a name="l00408"></a><span class="lineno">  408</span>   }</div><div class="line"><a name="l00409"></a><span class="lineno">  409</span>   <span class="keywordflow">return</span> allow_tensor_core;</div><div class="line"><a name="l00410"></a><span class="lineno">  410</span> }</div><div class="line"><a name="l00411"></a><span class="lineno">  411</span> </div><div class="line"><a name="l00412"></a><span class="lineno">  412</span> <span class="comment">// The policy if the user hasn't set the environment variable</span></div><div class="line"><a name="l00413"></a><span class="lineno">  413</span> <span class="comment">// CUDNN_TENSOR_OP_MATH_ALLOW_CONVERSION</span></div><div class="line"><a name="l00414"></a><span class="lineno"><a class="line" href="cuda__utils_8h.html#aa16d34c218441b0d4074baa8c66a5521">  414</a></span> <span class="preprocessor">#define MXNET_CUDA_TENSOR_OP_MATH_ALLOW_CONVERSION_DEFAULT false</span></div><div class="line"><a name="l00415"></a><span class="lineno">  415</span> </div><div class="line"><a name="l00419"></a><span class="lineno"><a class="line" href="cuda__utils_8h.html#ad77e70546b7f35ecba0098caa2d07523">  419</a></span> <span class="keyword">inline</span> <span class="keywordtype">bool</span> <a class="code" href="cuda__utils_8h.html#ad77e70546b7f35ecba0098caa2d07523">GetEnvAllowTensorCoreConversion</a>() {</div><div class="line"><a name="l00420"></a><span class="lineno">  420</span>   <span class="comment">// Use of optional&lt;bool&gt; here permits: "0", "1", "true" and "false" to all be</span></div><div class="line"><a name="l00421"></a><span class="lineno">  421</span>   <span class="comment">// legal.</span></div><div class="line"><a name="l00422"></a><span class="lineno">  422</span>   <span class="keywordtype">bool</span> default_value = <a class="code" href="cuda__utils_8h.html#aa16d34c218441b0d4074baa8c66a5521">MXNET_CUDA_TENSOR_OP_MATH_ALLOW_CONVERSION_DEFAULT</a>;</div><div class="line"><a name="l00423"></a><span class="lineno">  423</span>   <span class="keywordflow">return</span> dmlc::GetEnv(<span class="stringliteral">"MXNET_CUDA_TENSOR_OP_MATH_ALLOW_CONVERSION"</span>,</div><div class="line"><a name="l00424"></a><span class="lineno">  424</span>                       dmlc::optional&lt;bool&gt;(default_value))</div><div class="line"><a name="l00425"></a><span class="lineno">  425</span>       .value();</div><div class="line"><a name="l00426"></a><span class="lineno">  426</span> }</div><div class="line"><a name="l00427"></a><span class="lineno">  427</span> </div><div class="line"><a name="l00428"></a><span class="lineno">  428</span> <span class="preprocessor">#if CUDA_VERSION &gt;= 9000</span></div><div class="line"><a name="l00429"></a><span class="lineno">  429</span> <span class="comment">// Sets the cuBLAS math mode that determines the 'allow TensorCore' policy.  Returns previous.</span></div><div class="line"><a name="l00430"></a><span class="lineno">  430</span> <span class="keyword">inline</span> cublasMath_t SetCublasMathMode(cublasHandle_t blas_handle, cublasMath_t new_math_type) {</div><div class="line"><a name="l00431"></a><span class="lineno">  431</span>   <span class="keyword">auto</span> handle_math_mode = CUBLAS_DEFAULT_MATH;</div><div class="line"><a name="l00432"></a><span class="lineno">  432</span>   <a class="code" href="cuda__utils_8h.html#a685d7ca3c9370ff471665abcacdeb381">CUBLAS_CALL</a>(cublasGetMathMode(blas_handle, &amp;handle_math_mode));</div><div class="line"><a name="l00433"></a><span class="lineno">  433</span>   <a class="code" href="cuda__utils_8h.html#a685d7ca3c9370ff471665abcacdeb381">CUBLAS_CALL</a>(cublasSetMathMode(blas_handle, new_math_type));</div><div class="line"><a name="l00434"></a><span class="lineno">  434</span>   <span class="keywordflow">return</span> handle_math_mode;</div><div class="line"><a name="l00435"></a><span class="lineno">  435</span> }</div><div class="line"><a name="l00436"></a><span class="lineno">  436</span> <span class="preprocessor">#endif</span></div><div class="line"><a name="l00437"></a><span class="lineno">  437</span> </div><div class="line"><a name="l00438"></a><span class="lineno">  438</span> <span class="preprocessor">#endif  // MXNET_USE_CUDA</span></div><div class="line"><a name="l00439"></a><span class="lineno">  439</span> </div><div class="line"><a name="l00440"></a><span class="lineno">  440</span> <span class="preprocessor">#if MXNET_USE_CUDNN</span></div><div class="line"><a name="l00441"></a><span class="lineno">  441</span> </div><div class="line"><a name="l00442"></a><span class="lineno">  442</span> <span class="preprocessor">#include &lt;cudnn.h&gt;</span></div><div class="line"><a name="l00443"></a><span class="lineno">  443</span> </div><div class="line"><a name="l00444"></a><span class="lineno">  444</span> <span class="preprocessor">#define CUDNN_CALL(func)                                                      \</span></div><div class="line"><a name="l00445"></a><span class="lineno">  445</span> <span class="preprocessor">  {                                                                           \</span></div><div class="line"><a name="l00446"></a><span class="lineno">  446</span> <span class="preprocessor">    cudnnStatus_t e = (func);                                                 \</span></div><div class="line"><a name="l00447"></a><span class="lineno">  447</span> <span class="preprocessor">    CHECK_EQ(e, CUDNN_STATUS_SUCCESS) &lt;&lt; "cuDNN: " &lt;&lt; cudnnGetErrorString(e); \</span></div><div class="line"><a name="l00448"></a><span class="lineno">  448</span> <span class="preprocessor">  }</span></div><div class="line"><a name="l00449"></a><span class="lineno">  449</span> </div><div class="line"><a name="l00457"></a><span class="lineno">  457</span> <span class="keyword">inline</span> <span class="keywordtype">int</span> MaxForwardAlgos(cudnnHandle_t cudnn_handle) {</div><div class="line"><a name="l00458"></a><span class="lineno">  458</span> <span class="preprocessor">#if CUDNN_MAJOR &gt;= 7</span></div><div class="line"><a name="l00459"></a><span class="lineno">  459</span>   <span class="keywordtype">int</span> max_algos = 0;</div><div class="line"><a name="l00460"></a><span class="lineno">  460</span>   CUDNN_CALL(cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &amp;max_algos));</div><div class="line"><a name="l00461"></a><span class="lineno">  461</span>   <span class="keywordflow">return</span> max_algos;</div><div class="line"><a name="l00462"></a><span class="lineno">  462</span> <span class="preprocessor">#else</span></div><div class="line"><a name="l00463"></a><span class="lineno">  463</span>   <span class="keywordflow">return</span> 10;</div><div class="line"><a name="l00464"></a><span class="lineno">  464</span> <span class="preprocessor">#endif</span></div><div class="line"><a name="l00465"></a><span class="lineno">  465</span> }</div><div class="line"><a name="l00466"></a><span class="lineno">  466</span> </div><div class="line"><a name="l00474"></a><span class="lineno">  474</span> <span class="keyword">inline</span> <span class="keywordtype">int</span> MaxBackwardFilterAlgos(cudnnHandle_t cudnn_handle) {</div><div class="line"><a name="l00475"></a><span class="lineno">  475</span> <span class="preprocessor">#if CUDNN_MAJOR &gt;= 7</span></div><div class="line"><a name="l00476"></a><span class="lineno">  476</span>   <span class="keywordtype">int</span> max_algos = 0;</div><div class="line"><a name="l00477"></a><span class="lineno">  477</span>   CUDNN_CALL(cudnnGetConvolutionBackwardFilterAlgorithmMaxCount(cudnn_handle, &amp;max_algos));</div><div class="line"><a name="l00478"></a><span class="lineno">  478</span>   <span class="keywordflow">return</span> max_algos;</div><div class="line"><a name="l00479"></a><span class="lineno">  479</span> <span class="preprocessor">#else</span></div><div class="line"><a name="l00480"></a><span class="lineno">  480</span>   <span class="keywordflow">return</span> 10;</div><div class="line"><a name="l00481"></a><span class="lineno">  481</span> <span class="preprocessor">#endif</span></div><div class="line"><a name="l00482"></a><span class="lineno">  482</span> }</div><div class="line"><a name="l00483"></a><span class="lineno">  483</span> </div><div class="line"><a name="l00491"></a><span class="lineno">  491</span> <span class="keyword">inline</span> <span class="keywordtype">int</span> MaxBackwardDataAlgos(cudnnHandle_t cudnn_handle) {</div><div class="line"><a name="l00492"></a><span class="lineno">  492</span> <span class="preprocessor">#if CUDNN_MAJOR &gt;= 7</span></div><div class="line"><a name="l00493"></a><span class="lineno">  493</span>   <span class="keywordtype">int</span> max_algos = 0;</div><div class="line"><a name="l00494"></a><span class="lineno">  494</span>   CUDNN_CALL(cudnnGetConvolutionBackwardDataAlgorithmMaxCount(cudnn_handle, &amp;max_algos));</div><div class="line"><a name="l00495"></a><span class="lineno">  495</span>   <span class="keywordflow">return</span> max_algos;</div><div class="line"><a name="l00496"></a><span class="lineno">  496</span> <span class="preprocessor">#else</span></div><div class="line"><a name="l00497"></a><span class="lineno">  497</span>   <span class="keywordflow">return</span> 10;</div><div class="line"><a name="l00498"></a><span class="lineno">  498</span> <span class="preprocessor">#endif</span></div><div class="line"><a name="l00499"></a><span class="lineno">  499</span> }</div><div class="line"><a name="l00500"></a><span class="lineno">  500</span> </div><div class="line"><a name="l00501"></a><span class="lineno">  501</span> <span class="preprocessor">#endif  // MXNET_USE_CUDNN</span></div><div class="line"><a name="l00502"></a><span class="lineno">  502</span> </div><div class="line"><a name="l00503"></a><span class="lineno">  503</span> <span class="comment">// Overload atomicAdd to work for floats on all architectures</span></div><div class="line"><a name="l00504"></a><span class="lineno">  504</span> <span class="preprocessor">#if defined(__CUDA_ARCH__) &amp;&amp; __CUDA_ARCH__ &lt; 600</span></div><div class="line"><a name="l00505"></a><span class="lineno">  505</span> <span class="comment">// From CUDA Programming Guide</span></div><div class="line"><a name="l00506"></a><span class="lineno">  506</span> <span class="keyword">static</span> <span class="keyword">inline</span>  __device__  <span class="keywordtype">void</span> atomicAdd(<span class="keywordtype">double</span> *address, <span class="keywordtype">double</span> val) {</div><div class="line"><a name="l00507"></a><span class="lineno">  507</span>   <span class="keywordtype">unsigned</span> <span class="keywordtype">long</span> <span class="keywordtype">long</span>* address_as_ull =                  <span class="comment">// NOLINT(*)</span></div><div class="line"><a name="l00508"></a><span class="lineno">  508</span>     <span class="keyword">reinterpret_cast&lt;</span><span class="keywordtype">unsigned</span> <span class="keywordtype">long</span> <span class="keywordtype">long</span>*<span class="keyword">&gt;</span>(address);     <span class="comment">// NOLINT(*)</span></div><div class="line"><a name="l00509"></a><span class="lineno">  509</span>   <span class="keywordtype">unsigned</span> <span class="keywordtype">long</span> <span class="keywordtype">long</span> old = *address_as_ull;             <span class="comment">// NOLINT(*)</span></div><div class="line"><a name="l00510"></a><span class="lineno">  510</span>   <span class="keywordtype">unsigned</span> <span class="keywordtype">long</span> <span class="keywordtype">long</span> assumed;                           <span class="comment">// NOLINT(*)</span></div><div class="line"><a name="l00511"></a><span class="lineno">  511</span> </div><div class="line"><a name="l00512"></a><span class="lineno">  512</span>   <span class="keywordflow">do</span> {</div><div class="line"><a name="l00513"></a><span class="lineno">  513</span>     assumed = old;</div><div class="line"><a name="l00514"></a><span class="lineno">  514</span>     old = atomicCAS(address_as_ull, assumed,</div><div class="line"><a name="l00515"></a><span class="lineno">  515</span>                     __double_as_longlong(val +</div><div class="line"><a name="l00516"></a><span class="lineno">  516</span>                     __longlong_as_double(assumed)));</div><div class="line"><a name="l00517"></a><span class="lineno">  517</span> </div><div class="line"><a name="l00518"></a><span class="lineno">  518</span>     <span class="comment">// Note: uses integer comparison to avoid hang in case of NaN (since NaN != NaN)</span></div><div class="line"><a name="l00519"></a><span class="lineno">  519</span>   } <span class="keywordflow">while</span> (assumed != old);</div><div class="line"><a name="l00520"></a><span class="lineno">  520</span> }</div><div class="line"><a name="l00521"></a><span class="lineno">  521</span> <span class="preprocessor">#endif</span></div><div class="line"><a name="l00522"></a><span class="lineno">  522</span> </div><div class="line"><a name="l00523"></a><span class="lineno">  523</span> <span class="comment">// Overload atomicAdd for half precision</span></div><div class="line"><a name="l00524"></a><span class="lineno">  524</span> <span class="comment">// Taken from:</span></div><div class="line"><a name="l00525"></a><span class="lineno">  525</span> <span class="comment">// https://github.com/torch/cutorch/blob/master/lib/THC/THCAtomics.cuh</span></div><div class="line"><a name="l00526"></a><span class="lineno">  526</span> <span class="preprocessor">#if defined(__CUDA_ARCH__)</span></div><div class="line"><a name="l00527"></a><span class="lineno">  527</span> <span class="keyword">static</span> <span class="keyword">inline</span> __device__ <span class="keywordtype">void</span> atomicAdd(mshadow::half::half_t *address,</div><div class="line"><a name="l00528"></a><span class="lineno">  528</span>                                         mshadow::half::half_t val) {</div><div class="line"><a name="l00529"></a><span class="lineno">  529</span>   <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> *address_as_ui =</div><div class="line"><a name="l00530"></a><span class="lineno">  530</span>       <span class="keyword">reinterpret_cast&lt;</span><span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> *<span class="keyword">&gt;</span>(<span class="keyword">reinterpret_cast&lt;</span><span class="keywordtype">char</span> *<span class="keyword">&gt;</span>(address) -</div><div class="line"><a name="l00531"></a><span class="lineno">  531</span>                                    (reinterpret_cast&lt;size_t&gt;(address) &amp; 2));</div><div class="line"><a name="l00532"></a><span class="lineno">  532</span>   <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> old = *address_as_ui;</div><div class="line"><a name="l00533"></a><span class="lineno">  533</span>   <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> assumed;</div><div class="line"><a name="l00534"></a><span class="lineno">  534</span> </div><div class="line"><a name="l00535"></a><span class="lineno">  535</span>   <span class="keywordflow">do</span> {</div><div class="line"><a name="l00536"></a><span class="lineno">  536</span>     assumed = old;</div><div class="line"><a name="l00537"></a><span class="lineno">  537</span>     mshadow::half::half_t hsum;</div><div class="line"><a name="l00538"></a><span class="lineno">  538</span>     hsum.half_ =</div><div class="line"><a name="l00539"></a><span class="lineno">  539</span>         <span class="keyword">reinterpret_cast&lt;</span><span class="keywordtype">size_t</span><span class="keyword">&gt;</span>(address) &amp; 2 ? (old &gt;&gt; 16) : (old &amp; 0xffff);</div><div class="line"><a name="l00540"></a><span class="lineno">  540</span>     hsum += val;</div><div class="line"><a name="l00541"></a><span class="lineno">  541</span>     old = <span class="keyword">reinterpret_cast&lt;</span><span class="keywordtype">size_t</span><span class="keyword">&gt;</span>(address) &amp; 2</div><div class="line"><a name="l00542"></a><span class="lineno">  542</span>               ? (old &amp; 0xffff) | (hsum.half_ &lt;&lt; 16)</div><div class="line"><a name="l00543"></a><span class="lineno">  543</span>               : (old &amp; 0xffff0000) | hsum.half_;</div><div class="line"><a name="l00544"></a><span class="lineno">  544</span>     old = atomicCAS(address_as_ui, assumed, old);</div><div class="line"><a name="l00545"></a><span class="lineno">  545</span>   } <span class="keywordflow">while</span> (assumed != old);</div><div class="line"><a name="l00546"></a><span class="lineno">  546</span> }</div><div class="line"><a name="l00547"></a><span class="lineno">  547</span> </div><div class="line"><a name="l00548"></a><span class="lineno">  548</span> <span class="keyword">static</span> <span class="keyword">inline</span> __device__ <span class="keywordtype">void</span> atomicAdd(uint8_t *address, uint8_t val) {</div><div class="line"><a name="l00549"></a><span class="lineno">  549</span>   <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> * address_as_ui = (<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> *) (address - ((<span class="keywordtype">size_t</span>)address &amp; 0x3));</div><div class="line"><a name="l00550"></a><span class="lineno">  550</span>   <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> old = *address_as_ui;</div><div class="line"><a name="l00551"></a><span class="lineno">  551</span>   <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> shift = (((size_t)address &amp; 0x3) &lt;&lt; 3);</div><div class="line"><a name="l00552"></a><span class="lineno">  552</span>   <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> <a class="code" href="namespacemxnet_1_1cpp.html#acb4fccaa546283e233c15b46f6465443">sum</a>;</div><div class="line"><a name="l00553"></a><span class="lineno">  553</span>   <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> assumed;</div><div class="line"><a name="l00554"></a><span class="lineno">  554</span> </div><div class="line"><a name="l00555"></a><span class="lineno">  555</span>   <span class="keywordflow">do</span> {</div><div class="line"><a name="l00556"></a><span class="lineno">  556</span>     assumed = old;</div><div class="line"><a name="l00557"></a><span class="lineno">  557</span>     sum = val + <span class="keyword">static_cast&lt;</span>uint8_t<span class="keyword">&gt;</span>((old &gt;&gt; shift) &amp; 0xff);</div><div class="line"><a name="l00558"></a><span class="lineno">  558</span>     old = (old &amp; ~(0x000000ff &lt;&lt; shift)) | (sum &lt;&lt; shift);</div><div class="line"><a name="l00559"></a><span class="lineno">  559</span>     old = atomicCAS(address_as_ui, assumed, old);</div><div class="line"><a name="l00560"></a><span class="lineno">  560</span>   } <span class="keywordflow">while</span> (assumed != old);</div><div class="line"><a name="l00561"></a><span class="lineno">  561</span> }</div><div class="line"><a name="l00562"></a><span class="lineno">  562</span> </div><div class="line"><a name="l00563"></a><span class="lineno">  563</span> <span class="keyword">static</span> <span class="keyword">inline</span> __device__ <span class="keywordtype">void</span> atomicAdd(int8_t *address, int8_t val) {</div><div class="line"><a name="l00564"></a><span class="lineno">  564</span>   <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> * address_as_ui = (<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> *) (address - ((<span class="keywordtype">size_t</span>)address &amp; 0x3));</div><div class="line"><a name="l00565"></a><span class="lineno">  565</span>   <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> old = *address_as_ui;</div><div class="line"><a name="l00566"></a><span class="lineno">  566</span>   <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> shift = (((size_t)address &amp; 0x3) &lt;&lt; 3);</div><div class="line"><a name="l00567"></a><span class="lineno">  567</span>   <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> <a class="code" href="namespacemxnet_1_1cpp.html#acb4fccaa546283e233c15b46f6465443">sum</a>;</div><div class="line"><a name="l00568"></a><span class="lineno">  568</span>   <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> assumed;</div><div class="line"><a name="l00569"></a><span class="lineno">  569</span> </div><div class="line"><a name="l00570"></a><span class="lineno">  570</span>   <span class="keywordflow">do</span> {</div><div class="line"><a name="l00571"></a><span class="lineno">  571</span>     assumed = old;</div><div class="line"><a name="l00572"></a><span class="lineno">  572</span>     sum = val + <span class="keyword">static_cast&lt;</span>int8_t<span class="keyword">&gt;</span>((old &gt;&gt; shift) &amp; 0xff);</div><div class="line"><a name="l00573"></a><span class="lineno">  573</span>     old = (old &amp; ~(0x000000ff &lt;&lt; shift)) | (sum &lt;&lt; shift);</div><div class="line"><a name="l00574"></a><span class="lineno">  574</span>     old = atomicCAS(address_as_ui, assumed, old);</div><div class="line"><a name="l00575"></a><span class="lineno">  575</span>   } <span class="keywordflow">while</span> (assumed != old);</div><div class="line"><a name="l00576"></a><span class="lineno">  576</span> }</div><div class="line"><a name="l00577"></a><span class="lineno">  577</span> </div><div class="line"><a name="l00578"></a><span class="lineno">  578</span> <span class="comment">// Overload atomicAdd to work for signed int64 on all architectures</span></div><div class="line"><a name="l00579"></a><span class="lineno">  579</span> <span class="keyword">static</span> <span class="keyword">inline</span>  __device__  <span class="keywordtype">void</span> atomicAdd(int64_t *address, int64_t val) {</div><div class="line"><a name="l00580"></a><span class="lineno">  580</span>   atomicAdd(reinterpret_cast&lt;unsigned long long*&gt;(address), static_cast&lt;unsigned long long&gt;(val)); <span class="comment">// NOLINT</span></div><div class="line"><a name="l00581"></a><span class="lineno">  581</span> }</div><div class="line"><a name="l00582"></a><span class="lineno">  582</span> </div><div class="line"><a name="l00583"></a><span class="lineno">  583</span> <span class="keyword">template</span> &lt;<span class="keyword">typename</span> DType&gt;</div><div class="line"><a name="l00584"></a><span class="lineno">  584</span> __device__ <span class="keyword">inline</span> DType ldg(<span class="keyword">const</span> DType* address) {</div><div class="line"><a name="l00585"></a><span class="lineno">  585</span> <span class="preprocessor">#if __CUDA_ARCH__ &gt;= 350</span></div><div class="line"><a name="l00586"></a><span class="lineno">  586</span>     <span class="keywordflow">return</span> __ldg(address);</div><div class="line"><a name="l00587"></a><span class="lineno">  587</span> <span class="preprocessor">#else</span></div><div class="line"><a name="l00588"></a><span class="lineno">  588</span>     <span class="keywordflow">return</span> *address;</div><div class="line"><a name="l00589"></a><span class="lineno">  589</span> <span class="preprocessor">#endif</span></div><div class="line"><a name="l00590"></a><span class="lineno">  590</span> }</div><div class="line"><a name="l00591"></a><span class="lineno">  591</span> <span class="preprocessor">#endif</span></div><div class="line"><a name="l00592"></a><span class="lineno">  592</span> </div><div class="line"><a name="l00593"></a><span class="lineno">  593</span> <span class="preprocessor">#endif  // MXNET_COMMON_CUDA_UTILS_H_</span></div><div class="ttc" id="cuda__utils_8h_html_a685d7ca3c9370ff471665abcacdeb381"><div class="ttname"><a href="cuda__utils_8h.html#a685d7ca3c9370ff471665abcacdeb381">CUBLAS_CALL</a></div><div class="ttdeci">#define CUBLAS_CALL(func)</div><div class="ttdoc">Protected cuBLAS call. </div><div class="ttdef"><b>Definition:</b> cuda_utils.h:100</div></div>
<div class="ttc" id="cuda__utils_8h_html_aa79f548df23452162de37663f171e99d"><div class="ttname"><a href="cuda__utils_8h.html#aa79f548df23452162de37663f171e99d">ComputeCapabilityMajor</a></div><div class="ttdeci">int ComputeCapabilityMajor(int device_id)</div><div class="ttdoc">Determine major version number of the gpu&amp;#39;s cuda compute architecture. </div><div class="ttdef"><b>Definition:</b> cuda_utils.h:330</div></div>
<div class="ttc" id="classmxnet_1_1common_1_1cuda_1_1DeviceStore_html"><div class="ttname"><a href="classmxnet_1_1common_1_1cuda_1_1DeviceStore.html">mxnet::common::cuda::DeviceStore</a></div><div class="ttdef"><b>Definition:</b> cuda_utils.h:286</div></div>
<div class="ttc" id="cuda__utils_8h_html_ad77e70546b7f35ecba0098caa2d07523"><div class="ttname"><a href="cuda__utils_8h.html#ad77e70546b7f35ecba0098caa2d07523">GetEnvAllowTensorCoreConversion</a></div><div class="ttdeci">bool GetEnvAllowTensorCoreConversion()</div><div class="ttdoc">Returns global policy for TensorCore implicit type casting. </div><div class="ttdef"><b>Definition:</b> cuda_utils.h:419</div></div>
<div class="ttc" id="namespacemxnet_html"><div class="ttname"><a href="namespacemxnet.html">mxnet</a></div><div class="ttdoc">namespace of mxnet </div><div class="ttdef"><b>Definition:</b> base.h:118</div></div>
<div class="ttc" id="cuda__utils_8h_html_a464dee13053e3b0b1006c6307069196c"><div class="ttname"><a href="cuda__utils_8h.html#a464dee13053e3b0b1006c6307069196c">GetEnvAllowTensorCore</a></div><div class="ttdeci">bool GetEnvAllowTensorCore()</div><div class="ttdoc">Returns global policy for TensorCore algo use. </div><div class="ttdef"><b>Definition:</b> cuda_utils.h:396</div></div>
<div class="ttc" id="classmxnet_1_1common_1_1cuda_1_1DeviceStore_html_ad9878a09a93d4fcaf9d0639b3613d9f7"><div class="ttname"><a href="classmxnet_1_1common_1_1cuda_1_1DeviceStore.html#ad9878a09a93d4fcaf9d0639b3613d9f7">mxnet::common::cuda::DeviceStore::DeviceStore</a></div><div class="ttdeci">DeviceStore(int requested_device=-1, bool restore=true)</div><div class="ttdoc">default constructor- only optionally restores previous device </div><div class="ttdef"><b>Definition:</b> cuda_utils.h:289</div></div>
<div class="ttc" id="cuda__utils_8h_html_a9779e3ad0efd0faec7fbe431c0db896d"><div class="ttname"><a href="cuda__utils_8h.html#a9779e3ad0efd0faec7fbe431c0db896d">SMArch</a></div><div class="ttdeci">int SMArch(int device_id)</div><div class="ttdoc">Return the integer SM architecture (e.g. Volta = 70). </div><div class="ttdef"><b>Definition:</b> cuda_utils.h:354</div></div>
<div class="ttc" id="namespacemxnet_1_1common_1_1cuda_html_a03888f252f813f6d052ae84bf8801498"><div class="ttname"><a href="namespacemxnet_1_1common_1_1cuda.html#a03888f252f813f6d052ae84bf8801498">mxnet::common::cuda::CudaMin</a></div><div class="ttdeci">DType __device__ CudaMin(DType a, DType b)</div><div class="ttdef"><b>Definition:</b> cuda_utils.h:282</div></div>
<div class="ttc" id="classmxnet_1_1common_1_1cuda_1_1DeviceStore_html_a01163fd4915e74bdd81dd7305917f0e4"><div class="ttname"><a href="classmxnet_1_1common_1_1cuda_1_1DeviceStore.html#a01163fd4915e74bdd81dd7305917f0e4">mxnet::common::cuda::DeviceStore::SetDevice</a></div><div class="ttdeci">void SetDevice(int device)</div><div class="ttdef"><b>Definition:</b> cuda_utils.h:308</div></div>
<div class="ttc" id="cuda__utils_8h_html_afb4268417c1d8886a39142c85c8f188f"><div class="ttname"><a href="cuda__utils_8h.html#afb4268417c1d8886a39142c85c8f188f">SupportsFloat16Compute</a></div><div class="ttdeci">bool SupportsFloat16Compute(int device_id)</div><div class="ttdoc">Determine whether a cuda-capable gpu&amp;#39;s architecture supports float16 math. Assume not if device_id is...</div><div class="ttdef"><b>Definition:</b> cuda_utils.h:366</div></div>
<div class="ttc" id="namespacemxnet_1_1common_1_1cuda_html_a6f3ee04eb382c57e10916108db3efd80"><div class="ttname"><a href="namespacemxnet_1_1common_1_1cuda.html#a6f3ee04eb382c57e10916108db3efd80">mxnet::common::cuda::CudaMax</a></div><div class="ttdeci">DType __device__ CudaMax(DType a, DType b)</div><div class="ttdef"><b>Definition:</b> cuda_utils.h:277</div></div>
<div class="ttc" id="cuda__utils_8h_html_aa16d34c218441b0d4074baa8c66a5521"><div class="ttname"><a href="cuda__utils_8h.html#aa16d34c218441b0d4074baa8c66a5521">MXNET_CUDA_TENSOR_OP_MATH_ALLOW_CONVERSION_DEFAULT</a></div><div class="ttdeci">#define MXNET_CUDA_TENSOR_OP_MATH_ALLOW_CONVERSION_DEFAULT</div><div class="ttdef"><b>Definition:</b> cuda_utils.h:414</div></div>
<div class="ttc" id="cuda__utils_8h_html_af7e22ce6d80d61e8ca37df23880ff1a9"><div class="ttname"><a href="cuda__utils_8h.html#af7e22ce6d80d61e8ca37df23880ff1a9">SupportsTensorCore</a></div><div class="ttdeci">bool SupportsTensorCore(int device_id)</div><div class="ttdoc">Determine whether a cuda-capable gpu&amp;#39;s architecture supports Tensor Core math. Assume not if device_i...</div><div class="ttdef"><b>Definition:</b> cuda_utils.h:383</div></div>
<div class="ttc" id="namespacemxnet_1_1common_1_1cuda_html_abf9bcb4cb696e9ae61b818510dac39c8"><div class="ttname"><a href="namespacemxnet_1_1common_1_1cuda.html#abf9bcb4cb696e9ae61b818510dac39c8">mxnet::common::cuda::CusolverGetErrorString</a></div><div class="ttdeci">const char * CusolverGetErrorString(cusolverStatus_t error)</div><div class="ttdoc">Get string representation of cuSOLVER errors. </div><div class="ttdef"><b>Definition:</b> cuda_utils.h:215</div></div>
<div class="ttc" id="cuda__utils_8h_html_aa7ba00b841d6b7ba443b0e58dac9ab88"><div class="ttname"><a href="cuda__utils_8h.html#aa7ba00b841d6b7ba443b0e58dac9ab88">MXNET_CUDA_ALLOW_TENSOR_CORE_DEFAULT</a></div><div class="ttdeci">#define MXNET_CUDA_ALLOW_TENSOR_CORE_DEFAULT</div><div class="ttdef"><b>Definition:</b> cuda_utils.h:390</div></div>
<div class="ttc" id="namespacemxnet_1_1common_1_1cuda_html_a97c06b2f4d26445a7386b0f54fae1feb"><div class="ttname"><a href="namespacemxnet_1_1common_1_1cuda.html#a97c06b2f4d26445a7386b0f54fae1feb">mxnet::common::cuda::CurandGetErrorString</a></div><div class="ttdeci">const char * CurandGetErrorString(curandStatus_t status)</div><div class="ttdoc">Get string representation of cuRAND errors. </div><div class="ttdef"><b>Definition:</b> cuda_utils.h:244</div></div>
<div class="ttc" id="classmxnet_1_1common_1_1cuda_1_1DeviceStore_html_a701d38ae493688ee2136995fe8611aa0"><div class="ttname"><a href="classmxnet_1_1common_1_1cuda_1_1DeviceStore.html#a701d38ae493688ee2136995fe8611aa0">mxnet::common::cuda::DeviceStore::~DeviceStore</a></div><div class="ttdeci">~DeviceStore()</div><div class="ttdef"><b>Definition:</b> cuda_utils.h:300</div></div>
<div class="ttc" id="cuda__utils_8h_html_a7c16e8770e4f399cabed1fc231ffd9b6"><div class="ttname"><a href="cuda__utils_8h.html#a7c16e8770e4f399cabed1fc231ffd9b6">ComputeCapabilityMinor</a></div><div class="ttdeci">int ComputeCapabilityMinor(int device_id)</div><div class="ttdoc">Determine minor version number of the gpu&amp;#39;s cuda compute architecture. </div><div class="ttdef"><b>Definition:</b> cuda_utils.h:342</div></div>
<div class="ttc" id="cuda__utils_8h_html_a06cc7d24ca66505e69f5ad40009f5e8d"><div class="ttname"><a href="cuda__utils_8h.html#a06cc7d24ca66505e69f5ad40009f5e8d">CUDA_CALL</a></div><div class="ttdeci">#define CUDA_CALL(func)</div><div class="ttdoc">Protected CUDA call. </div><div class="ttdef"><b>Definition:</b> cuda_utils.h:87</div></div>
<div class="ttc" id="namespacemxnet_1_1common_1_1cuda_html_a9feee613a4f16a954dd68e55345a72ac"><div class="ttname"><a href="namespacemxnet_1_1common_1_1cuda.html#a9feee613a4f16a954dd68e55345a72ac">mxnet::common::cuda::CublasGetErrorString</a></div><div class="ttdeci">const char * CublasGetErrorString(cublasStatus_t error)</div><div class="ttdoc">Get string representation of cuBLAS errors. </div><div class="ttdef"><b>Definition:</b> cuda_utils.h:184</div></div>
<div class="ttc" id="namespacemxnet_1_1cpp_html_acb4fccaa546283e233c15b46f6465443"><div class="ttname"><a href="namespacemxnet_1_1cpp.html#acb4fccaa546283e233c15b46f6465443">mxnet::cpp::sum</a></div><div class="ttdeci">Symbol sum(const std::string &amp;symbol_name, Symbol data, dmlc::optional&lt; Shape &gt; axis=dmlc::optional&lt; Shape &gt;(), bool keepdims=false, bool exclude=false)</div><div class="ttdef"><b>Definition:</b> op.h:2567</div></div>
</div><!-- fragment --></div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated on Thu Sep 19 2019 12:37:33 for mxnet by  <a href="http://www.doxygen.org/index.html">
<img alt="doxygen" class="footer" src="doxygen.png"/>
</a> 1.8.11
</small></address>
</body>
</html>
