<!DOCTYPE html>

<html lang="en">
<head>
<meta charset="utf-8"/>
<meta content="IE=edge" http-equiv="X-UA-Compatible"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="Build/Install MXNet with MKL-DNN" property="og:title">
<meta content="https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/image/og-logo.png" property="og:image">
<meta content="https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/image/og-logo.png" property="og:image:secure_url">
<meta content="Build/Install MXNet with MKL-DNN" property="og:description"/>
<title>Build/Install MXNet with MKL-DNN — mxnet  documentation</title>
<link crossorigin="anonymous" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css" integrity="sha384-1q8mTJOASx8j1Au+a5WDVnPi2lkFfwwEAa8hDDdjZlpLegxhjVME1fgjWPGmkzs7" rel="stylesheet"/>
<link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css" rel="stylesheet"/>
<link href="../../_static/basic.css" rel="stylesheet" type="text/css">
<link href="../../_static/pygments.css" rel="stylesheet" type="text/css">
<link href="../../_static/mxnet.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../../',
        VERSION:     '',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true,
        SOURCELINK_SUFFIX: '.txt'
      };
    </script>
<script src="https://code.jquery.com/jquery-1.11.1.min.js" type="text/javascript"></script>
<script src="../../_static/underscore.js" type="text/javascript"></script>
<script src="../../_static/searchtools_custom.js" type="text/javascript"></script>
<script src="../../_static/doctools.js" type="text/javascript"></script>
<script src="../../_static/selectlang.js" type="text/javascript"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
<script type="text/javascript"> jQuery(function() { Search.loadIndex("/versions/1.5.0/searchindex.js"); Search.init();}); </script>
<script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new
      Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-96378503-1', 'auto');
      ga('send', 'pageview');

    </script>
<!-- -->
<!-- <script type="text/javascript" src="../../_static/jquery.js"></script> -->
<!-- -->
<!-- <script type="text/javascript" src="../../_static/underscore.js"></script> -->
<!-- -->
<!-- <script type="text/javascript" src="../../_static/doctools.js"></script> -->
<!-- -->
<!-- <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script> -->
<!-- -->
<link href="../../genindex.html" rel="index" title="Index">
<link href="../../search.html" rel="search" title="Search"/>
<link href="index.html" rel="up" title="Tutorials"/>
<link href="operator_list.html" rel="next" title="MKL-DNN Operator list"/>
<link href="index.html" rel="prev" title="Tutorials"/>
<link href="https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/image/mxnet-icon.png" rel="icon" type="image/png"/>
</link></link></link></meta></meta></meta></head>
<body background="https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/image/mxnet-background-compressed.jpeg" role="document">
<div class="content-block"><div class="navbar navbar-fixed-top">
<div class="container" id="navContainer">
<div class="innder" id="header-inner">
<h1 id="logo-wrap">
<a href="../../" id="logo"><img src="https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/image/mxnet_logo.png"/></a>
</h1>
<nav class="nav-bar" id="main-nav">
<a class="main-nav-link" href="/versions/1.5.0/install/index.html">Install</a>
<span id="dropdown-menu-position-anchor">
<a aria-expanded="true" aria-haspopup="true" class="main-nav-link dropdown-toggle" data-toggle="dropdown" href="#" role="button">Gluon <span class="caret"></span></a>
<ul class="dropdown-menu navbar-menu" id="package-dropdown-menu">
<li><a class="main-nav-link" href="/versions/1.5.0/tutorials/gluon/gluon.html">About</a></li>
<li><a class="main-nav-link" href="https://www.d2l.ai/">Dive into Deep Learning</a></li>
<li><a class="main-nav-link" href="https://gluon-cv.mxnet.io">GluonCV Toolkit</a></li>
<li><a class="main-nav-link" href="https://gluon-nlp.mxnet.io/">GluonNLP Toolkit</a></li>
</ul>
</span>
<span id="dropdown-menu-position-anchor">
<a aria-expanded="true" aria-haspopup="true" class="main-nav-link dropdown-toggle" data-toggle="dropdown" href="#" role="button">API <span class="caret"></span></a>
<ul class="dropdown-menu navbar-menu" id="package-dropdown-menu">
<li><a class="main-nav-link" href="/versions/1.5.0/api/python/index.html">Python</a></li>
<li><a class="main-nav-link" href="/versions/1.5.0/api/c++/index.html">C++</a></li>
<li><a class="main-nav-link" href="/versions/1.5.0/api/clojure/index.html">Clojure</a></li>
<li><a class="main-nav-link" href="/versions/1.5.0/api/java/index.html">Java</a></li>
<li><a class="main-nav-link" href="/versions/1.5.0/api/julia/index.html">Julia</a></li>
<li><a class="main-nav-link" href="/versions/1.5.0/api/perl/index.html">Perl</a></li>
<li><a class="main-nav-link" href="/versions/1.5.0/api/r/index.html">R</a></li>
<li><a class="main-nav-link" href="/versions/1.5.0/api/scala/index.html">Scala</a></li>
</ul>
</span>
<span id="dropdown-menu-position-anchor-docs">
<a aria-expanded="true" aria-haspopup="true" class="main-nav-link dropdown-toggle" data-toggle="dropdown" href="#" role="button">Docs <span class="caret"></span></a>
<ul class="dropdown-menu navbar-menu" id="package-dropdown-menu-docs">
<li><a class="main-nav-link" href="/versions/1.5.0/faq/index.html">FAQ</a></li>
<li><a class="main-nav-link" href="/versions/1.5.0/tutorials/index.html">Tutorials</a>
<li><a class="main-nav-link" href="https://github.com/apache/incubator-mxnet/tree/1.5.0/example">Examples</a></li>
<li><a class="main-nav-link" href="/versions/1.5.0/architecture/index.html">Architecture</a></li>
<li><a class="main-nav-link" href="https://cwiki.apache.org/confluence/display/MXNET/Apache+MXNet+Home">Developer Wiki</a></li>
<li><a class="main-nav-link" href="/versions/1.5.0/model_zoo/index.html">Model Zoo</a></li>
<li><a class="main-nav-link" href="https://github.com/onnx/onnx-mxnet">ONNX</a></li>
</li></ul>
</span>
<span id="dropdown-menu-position-anchor-community">
<a aria-expanded="true" aria-haspopup="true" class="main-nav-link dropdown-toggle" data-toggle="dropdown" href="#" role="button">Community <span class="caret"></span></a>
<ul class="dropdown-menu navbar-menu" id="package-dropdown-menu-community">
<li><a class="main-nav-link" href="http://discuss.mxnet.io">Forum</a></li>
<li><a class="main-nav-link" href="https://github.com/apache/incubator-mxnet/tree/1.5.0">Github</a></li>
<li><a class="main-nav-link" href="/versions/1.5.0/community/contribute.html">Contribute</a></li>
<li><a class="main-nav-link" href="/versions/1.5.0/community/ecosystem.html">Ecosystem</a></li>
<li><a class="main-nav-link" href="/versions/1.5.0/community/powered_by.html">Powered By</a></li>
</ul>
</span>
<span id="dropdown-menu-position-anchor-version" style="position: relative"><a href="#" class="main-nav-link dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="true">1.5.0<span class="caret"></span></a><ul id="package-dropdown-menu" class="dropdown-menu"><li><a href="/">master</a></li><li><a href=/versions/1.6/>1.6</a></li><li><a href=/versions/1.5.0/>1.5.0</a></li><li><a href=/versions/1.4.1/>1.4.1</a></li><li><a href=/versions/1.3.1/>1.3.1</a></li><li><a href=/versions/1.2.1/>1.2.1</a></li><li><a href=/versions/1.1.0/>1.1.0</a></li><li><a href=/versions/1.0.0/>1.0.0</a></li><li><a href=/versions/0.12.1/>0.12.1</a></li><li><a href=/versions/0.11.0/>0.11.0</a></li></ul></span></nav>
<script> function getRootPath(){ return "../../" } </script>
<div class="burgerIcon dropdown">
<a class="dropdown-toggle" data-toggle="dropdown" href="#" role="button">☰</a>
<ul class="dropdown-menu" id="burgerMenu">
<li><a href="/versions/1.5.0/install/index.html">Install</a></li>
<li><a class="main-nav-link" href="/versions/1.5.0/tutorials/index.html">Tutorials</a></li>
<li class="dropdown-submenu dropdown">
<a aria-expanded="true" aria-haspopup="true" class="dropdown-toggle burger-link" data-toggle="dropdown" href="#" tabindex="-1">Gluon</a>
<ul class="dropdown-menu navbar-menu" id="package-dropdown-menu">
<li><a class="main-nav-link" href="/versions/1.5.0/tutorials/gluon/gluon.html">About</a></li>
<li><a class="main-nav-link" href="http://gluon.mxnet.io">The Straight Dope (Tutorials)</a></li>
<li><a class="main-nav-link" href="https://gluon-cv.mxnet.io">GluonCV Toolkit</a></li>
<li><a class="main-nav-link" href="https://gluon-nlp.mxnet.io/">GluonNLP Toolkit</a></li>
</ul>
</li>
<li class="dropdown-submenu">
<a aria-expanded="true" aria-haspopup="true" class="dropdown-toggle burger-link" data-toggle="dropdown" href="#" tabindex="-1">API</a>
<ul class="dropdown-menu">
<li><a class="main-nav-link" href="/versions/1.5.0/api/python/index.html">Python</a></li>
<li><a class="main-nav-link" href="/versions/1.5.0/api/c++/index.html">C++</a></li>
<li><a class="main-nav-link" href="/versions/1.5.0/api/clojure/index.html">Clojure</a></li>
<li><a class="main-nav-link" href="/versions/1.5.0/api/java/index.html">Java</a></li>
<li><a class="main-nav-link" href="/versions/1.5.0/api/julia/index.html">Julia</a></li>
<li><a class="main-nav-link" href="/versions/1.5.0/api/perl/index.html">Perl</a></li>
<li><a class="main-nav-link" href="/versions/1.5.0/api/r/index.html">R</a></li>
<li><a class="main-nav-link" href="/versions/1.5.0/api/scala/index.html">Scala</a></li>
</ul>
</li>
<li class="dropdown-submenu">
<a aria-expanded="true" aria-haspopup="true" class="dropdown-toggle burger-link" data-toggle="dropdown" href="#" tabindex="-1">Docs</a>
<ul class="dropdown-menu">
<li><a href="/versions/1.5.0/faq/index.html" tabindex="-1">FAQ</a></li>
<li><a href="/versions/1.5.0/tutorials/index.html" tabindex="-1">Tutorials</a></li>
<li><a href="https://github.com/apache/incubator-mxnet/tree/1.5.0/example" tabindex="-1">Examples</a></li>
<li><a href="/versions/1.5.0/architecture/index.html" tabindex="-1">Architecture</a></li>
<li><a href="https://cwiki.apache.org/confluence/display/MXNET/Apache+MXNet+Home" tabindex="-1">Developer Wiki</a></li>
<li><a href="/versions/1.5.0/model_zoo/index.html" tabindex="-1">Gluon Model Zoo</a></li>
<li><a href="https://github.com/onnx/onnx-mxnet" tabindex="-1">ONNX</a></li>
</ul>
</li>
<li class="dropdown-submenu dropdown">
<a aria-haspopup="true" class="dropdown-toggle burger-link" data-toggle="dropdown" href="#" role="button" tabindex="-1">Community</a>
<ul class="dropdown-menu">
<li><a href="http://discuss.mxnet.io" tabindex="-1">Forum</a></li>
<li><a href="https://github.com/apache/incubator-mxnet/tree/1.5.0" tabindex="-1">Github</a></li>
<li><a href="/versions/1.5.0/community/contribute.html" tabindex="-1">Contribute</a></li>
<li><a href="/versions/1.5.0/community/ecosystem.html" tabindex="-1">Ecosystem</a></li>
<li><a href="/versions/1.5.0/community/powered_by.html" tabindex="-1">Powered By</a></li>
</ul>
</li>
<li id="dropdown-menu-position-anchor-version-mobile" class="dropdown-submenu" style="position: relative"><a href="#" tabindex="-1">1.5.0</a><ul class="dropdown-menu"><li><a tabindex="-1" href=/>master</a></li><li><a tabindex="-1" href=/versions/1.6/>1.6</a></li><li><a tabindex="-1" href=/versions/1.5.0/>1.5.0</a></li><li><a tabindex="-1" href=/versions/1.4.1/>1.4.1</a></li><li><a tabindex="-1" href=/versions/1.3.1/>1.3.1</a></li><li><a tabindex="-1" href=/versions/1.2.1/>1.2.1</a></li><li><a tabindex="-1" href=/versions/1.1.0/>1.1.0</a></li><li><a tabindex="-1" href=/versions/1.0.0/>1.0.0</a></li><li><a tabindex="-1" href=/versions/0.12.1/>0.12.1</a></li><li><a tabindex="-1" href=/versions/0.11.0/>0.11.0</a></li></ul></li></ul>
</div>
<div class="plusIcon dropdown">
<a class="dropdown-toggle" data-toggle="dropdown" href="#" role="button"><span aria-hidden="true" class="glyphicon glyphicon-plus"></span></a>
<ul class="dropdown-menu dropdown-menu-right" id="plusMenu"></ul>
</div>
<div id="search-input-wrap">
<form action="../../search.html" autocomplete="off" class="" method="get" role="search">
<div class="form-group inner-addon left-addon">
<i class="glyphicon glyphicon-search"></i>
<input class="form-control" name="q" placeholder="Search" type="text"/>
</div>
<input name="check_keywords" type="hidden" value="yes">
<input name="area" type="hidden" value="default"/>
</input></form>
<div id="search-preview"></div>
</div>
<div id="searchIcon">
<span aria-hidden="true" class="glyphicon glyphicon-search"></span>
</div>
<!-- <div id="lang-select-wrap"> -->
<!--   <label id="lang-select-label"> -->
<!--     <\!-- <i class="fa fa-globe"></i> -\-> -->
<!--     <span></span> -->
<!--   </label> -->
<!--   <select id="lang-select"> -->
<!--     <option value="en">Eng</option> -->
<!--     <option value="zh">中文</option> -->
<!--   </select> -->
<!-- </div> -->
<!--     <a id="mobile-nav-toggle">
        <span class="mobile-nav-toggle-bar"></span>
        <span class="mobile-nav-toggle-bar"></span>
        <span class="mobile-nav-toggle-bar"></span>
      </a> -->
</div>
</div>
</div>
<script type="text/javascript">
        $('body').css('background', 'white');
    </script>
<div class="container">
<div class="row">
<div aria-label="main navigation" class="sphinxsidebar leftsidebar" role="navigation">
<div class="sphinxsidebarwrapper">
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../api/index.html">MXNet APIs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../architecture/index.html">MXNet Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../community/index.html">MXNet Community</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/index.html">MXNet FAQ</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../gluon/index.html">About Gluon</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../install/index.html">Installing MXNet</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../install/index.html#nvidia-jetson-tx-family">Nvidia Jetson TX family</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../install/index.html#source-download">Source Download</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model_zoo/index.html">MXNet Model Zoo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../index.html">Tutorials</a></li>
</ul>
</div>
</div>
<div class="content">
<div class="page-tracker"></div>
<!--- Licensed to the Apache Software Foundation (ASF) under one -->
<!--- or more contributor license agreements.  See the NOTICE file -->
<!--- distributed with this work for additional information -->
<!--- regarding copyright ownership.  The ASF licenses this file -->
<!--- to you under the Apache License, Version 2.0 (the -->
<!--- "License"); you may not use this file except in compliance -->
<!--- with the License.  You may obtain a copy of the License at --><!---   http://www.apache.org/licenses/LICENSE-2.0 --><!--- Unless required by applicable law or agreed to in writing, -->
<!--- software distributed under the License is distributed on an -->
<!--- "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY -->
<!--- KIND, either express or implied.  See the License for the -->
<!--- specific language governing permissions and limitations -->
<!--- under the License. --><div class="section" id="build-install-mxnet-with-mkl-dnn">
<span id="build-install-mxnet-with-mkl-dnn"></span><h1>Build/Install MXNet with MKL-DNN<a class="headerlink" href="#build-install-mxnet-with-mkl-dnn" title="Permalink to this headline">¶</a></h1>
<p>A better training and inference performance is expected to be achieved on Intel-Architecture CPUs with MXNet built with <a class="reference external" href="https://github.com/intel/mkl-dnn">Intel MKL-DNN</a> on multiple operating system, including Linux, Windows and MacOS.
In the following sections, you will find build instructions for MXNet with Intel MKL-DNN on Linux, MacOS and Windows.</p>
<p>Please find MKL-DNN optimized operators and other features in the <a class="reference internal" href="operator_list.html"><span class="doc">MKL-DNN operator list</span></a>.</p>
<p>The detailed performance data collected on Intel Xeon CPU with MXNet built with Intel MKL-DNN can be found <a class="reference external" href="/faq/perf.html#intel-cpu">here</a>.</p>
<h2 id="0">Contents</h2><ul class="simple">
<li><a class="reference external" href="#1">1. Linux</a></li>
<li><a class="reference external" href="#2">2. MacOS</a></li>
<li><a class="reference external" href="#3">3. Windows</a></li>
<li><a class="reference external" href="#4">4. Verify MXNet with python</a></li>
<li><a class="reference external" href="#5">5. Enable MKL BLAS</a></li>
<li><a class="reference external" href="#6">6. Enable graph optimization</a></li>
<li><a class="reference external" href="#7">7. Quantization</a></li>
<li><a class="reference external" href="#8">8. Support</a></li>
</ul>
<h2 id="1">Linux</h2><div class="section" id="prerequisites">
<span id="prerequisites"></span><h2>Prerequisites<a class="headerlink" href="#prerequisites" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">sudo</span> <span class="n">apt</span><span class="o">-</span><span class="n">get</span> <span class="n">update</span>
<span class="n">sudo</span> <span class="n">apt</span><span class="o">-</span><span class="n">get</span> <span class="n">install</span> <span class="o">-</span><span class="n">y</span> <span class="n">build</span><span class="o">-</span><span class="n">essential</span> <span class="n">git</span>
<span class="n">sudo</span> <span class="n">apt</span><span class="o">-</span><span class="n">get</span> <span class="n">install</span> <span class="o">-</span><span class="n">y</span> <span class="n">libopenblas</span><span class="o">-</span><span class="n">dev</span> <span class="n">liblapack</span><span class="o">-</span><span class="n">dev</span>
<span class="n">sudo</span> <span class="n">apt</span><span class="o">-</span><span class="n">get</span> <span class="n">install</span> <span class="o">-</span><span class="n">y</span> <span class="n">libopencv</span><span class="o">-</span><span class="n">dev</span>
<span class="n">sudo</span> <span class="n">apt</span><span class="o">-</span><span class="n">get</span> <span class="n">install</span> <span class="o">-</span><span class="n">y</span> <span class="n">graphviz</span>
</pre></div>
</div>
</div>
<div class="section" id="clone-mxnet-sources">
<span id="clone-mxnet-sources"></span><h2>Clone MXNet sources<a class="headerlink" href="#clone-mxnet-sources" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">git</span> <span class="n">clone</span> <span class="o">--</span><span class="n">recursive</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">github</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">apache</span><span class="o">/</span><span class="n">incubator</span><span class="o">-</span><span class="n">mxnet</span><span class="o">.</span><span class="n">git</span>
<span class="n">cd</span> <span class="n">incubator</span><span class="o">-</span><span class="n">mxnet</span>
</pre></div>
</div>
</div>
<div class="section" id="build-mxnet-with-mkl-dnn">
<span id="build-mxnet-with-mkl-dnn"></span><h2>Build MXNet with MKL-DNN<a class="headerlink" href="#build-mxnet-with-mkl-dnn" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default"><div class="highlight"><pre><span></span>make -j $(nproc) USE_OPENCV=1 USE_MKLDNN=1 USE_BLAS=mkl USE_INTEL_PATH=/opt/intel
</pre></div>
</div>
<p>If you don’t have the full <a class="reference external" href="https://software.intel.com/en-us/intel-mkl">MKL</a> library installation, you might use OpenBLAS as the blas library, by setting USE_BLAS=openblas.</p>
<h2 id="2">MacOS</h2></div>
<div class="section" id="prerequisites">
<span id="id1"></span><h2>Prerequisites<a class="headerlink" href="#prerequisites" title="Permalink to this headline">¶</a></h2>
<p>Install the dependencies, required for MXNet, with the following commands:</p>
<ul class="simple">
<li><a class="reference external" href="https://brew.sh/">Homebrew</a></li>
<li>llvm (clang in macOS does not support OpenMP)</li>
<li>OpenCV (for computer vision operations)</li>
</ul>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="c1"># Paste this command in Mac terminal to install Homebrew</span>
<span class="o">/</span><span class="n">usr</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">ruby</span> <span class="o">-</span><span class="n">e</span> <span class="s2">"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)"</span>

<span class="c1"># install dependency</span>
<span class="n">brew</span> <span class="n">update</span>
<span class="n">brew</span> <span class="n">install</span> <span class="n">pkg</span><span class="o">-</span><span class="n">config</span>
<span class="n">brew</span> <span class="n">install</span> <span class="n">graphviz</span>
<span class="n">brew</span> <span class="n">tap</span> <span class="n">homebrew</span><span class="o">/</span><span class="n">core</span>
<span class="n">brew</span> <span class="n">install</span> <span class="n">opencv</span>
<span class="n">brew</span> <span class="n">tap</span> <span class="n">homebrew</span><span class="o">/</span><span class="n">versions</span>
<span class="n">brew</span> <span class="n">install</span> <span class="n">llvm</span>
</pre></div>
</div>
</div>
<div class="section" id="clone-mxnet-sources">
<span id="id2"></span><h2>Clone MXNet sources<a class="headerlink" href="#clone-mxnet-sources" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">git</span> <span class="n">clone</span> <span class="o">--</span><span class="n">recursive</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">github</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">apache</span><span class="o">/</span><span class="n">incubator</span><span class="o">-</span><span class="n">mxnet</span><span class="o">.</span><span class="n">git</span>
<span class="n">cd</span> <span class="n">incubator</span><span class="o">-</span><span class="n">mxnet</span>
</pre></div>
</div>
</div>
<div class="section" id="build-mxnet-with-mkl-dnn">
<span id="id3"></span><h2>Build MXNet with MKL-DNN<a class="headerlink" href="#build-mxnet-with-mkl-dnn" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default"><div class="highlight"><pre><span></span>LIBRARY_PATH=$(brew --prefix llvm)/lib/ make -j $(sysctl -n hw.ncpu) CC=$(brew --prefix llvm)/bin/clang CXX=$(brew --prefix llvm)/bin/clang++ USE_OPENCV=1 USE_OPENMP=1 USE_MKLDNN=1 USE_BLAS=apple USE_PROFILER=1
</pre></div>
</div>
<h2 id="3">Windows</h2><p>On Windows, you can use <a class="reference external" href="https://www.visualstudio.com/vs/older-downloads/">Micrsoft Visual Studio 2015</a> and <a class="reference external" href="https://www.visualstudio.com/downloads/">Microsoft Visual Studio 2017</a> to compile MXNet with Intel MKL-DNN.
<a class="reference external" href="https://www.visualstudio.com/vs/older-downloads/">Micrsoft Visual Studio 2015</a> is recommended.</p>
<p><strong>Visual Studio 2015</strong></p>
<p>To build and install MXNet yourself, you need the following dependencies. Install the required dependencies:</p>
<ol class="simple">
<li>If <a class="reference external" href="https://www.visualstudio.com/vs/older-downloads/">Microsoft Visual Studio 2015</a> is not already installed, download and install it. You can download and install the free community edition.</li>
<li>Download and Install <a class="reference external" href="https://cmake.org/files/v3.14/cmake-3.14.0-win64-x64.msi">CMake 3</a> if it is not already installed.</li>
<li>Download <a class="reference external" href="https://sourceforge.net/projects/opencvlibrary/files/3.4.5/opencv-3.4.5-vc14_vc15.exe/download">OpenCV 3</a>, and unzip the OpenCV package, set the environment variable <code class="docutils literal"><span class="pre">OpenCV_DIR</span></code> to point to the <code class="docutils literal"><span class="pre">OpenCV</span> <span class="pre">build</span> <span class="pre">directory</span></code> (e.g.,<code class="docutils literal"><span class="pre">OpenCV_DIR</span> <span class="pre">=</span> <span class="pre">C:\opencv\build</span></code>). Also, add the OpenCV bin directory (<code class="docutils literal"><span class="pre">C:\opencv\build\x64\vc14\bin</span></code> for example) to the <code class="docutils literal"><span class="pre">PATH</span></code> variable.</li>
<li>If you have Intel Math Kernel Library (Intel MKL) installed, set <code class="docutils literal"><span class="pre">MKL_ROOT</span></code> to point to <code class="docutils literal"><span class="pre">MKL</span></code> directory that contains the <code class="docutils literal"><span class="pre">include</span></code> and <code class="docutils literal"><span class="pre">lib</span></code>. If you want to use MKL blas, you should set <code class="docutils literal"><span class="pre">-DUSE_BLAS=mkl</span></code> when cmake. Typically, you can find the directory in <code class="docutils literal"><span class="pre">C:\Program</span> <span class="pre">Files</span> <span class="pre">(x86)\IntelSWTools\compilers_and_libraries\windows\mkl</span></code>.</li>
<li>If you don’t have the Intel Math Kernel Library (MKL) installed, download and install <a class="reference external" href="http://sourceforge.net/projects/openblas/files/v0.2.14/">OpenBLAS</a>, or build the latest version of OpenBLAS from source. Note that you should also download <code class="docutils literal"><span class="pre">mingw64.dll.zip</span></code> along with openBLAS and add them to PATH.</li>
<li>Set the environment variable <code class="docutils literal"><span class="pre">OpenBLAS_HOME</span></code> to point to the <code class="docutils literal"><span class="pre">OpenBLAS</span></code> directory that contains the <code class="docutils literal"><span class="pre">include</span></code> and <code class="docutils literal"><span class="pre">lib</span></code> directories. Typically, you can find the directory in <code class="docutils literal"><span class="pre">C:\Downloads\OpenBLAS\</span></code>.</li>
</ol>
<p>After you have installed all of the required dependencies, build the MXNet source code:</p>
<ol class="simple">
<li>Start a Visual Studio command prompt by click windows Start menu>>Visual Studio 2015>>VS2015 X64 Native Tools Command Prompt, and download the MXNet source code from <a class="reference external" href="https://github.com/apache/incubator-mxnet">GitHub</a> by the command:</li>
</ol>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">git</span> <span class="n">clone</span> <span class="o">--</span><span class="n">recursive</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">github</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">apache</span><span class="o">/</span><span class="n">incubator</span><span class="o">-</span><span class="n">mxnet</span><span class="o">.</span><span class="n">git</span>
<span class="n">cd</span> <span class="n">C</span><span class="p">:</span>\<span class="n">incubator</span><span class="o">-</span><span class="n">mxent</span>
</pre></div>
</div>
<ol class="simple">
<li>Enable Intel MKL-DNN by -DUSE_MKLDNN=1. Use <a class="reference external" href="https://cmake.org/">CMake 3</a> to create a Visual Studio solution in <code class="docutils literal"><span class="pre">./build</span></code>. Make sure to specify the architecture in the
command:</li>
</ol>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="o">></span><span class="n">mkdir</span> <span class="n">build</span>
<span class="o">></span><span class="n">cd</span> <span class="n">build</span>
<span class="o">></span><span class="n">cmake</span> <span class="o">-</span><span class="n">G</span> <span class="s2">"Visual Studio 14 Win64"</span> <span class="o">..</span> <span class="o">-</span><span class="n">DUSE_CUDA</span><span class="o">=</span><span class="mi">0</span> <span class="o">-</span><span class="n">DUSE_CUDNN</span><span class="o">=</span><span class="mi">0</span> <span class="o">-</span><span class="n">DUSE_NVRTC</span><span class="o">=</span><span class="mi">0</span> <span class="o">-</span><span class="n">DUSE_OPENCV</span><span class="o">=</span><span class="mi">1</span> <span class="o">-</span><span class="n">DUSE_OPENMP</span><span class="o">=</span><span class="mi">1</span> <span class="o">-</span><span class="n">DUSE_PROFILER</span><span class="o">=</span><span class="mi">1</span> <span class="o">-</span><span class="n">DUSE_BLAS</span><span class="o">=</span><span class="nb">open</span> <span class="o">-</span><span class="n">DUSE_LAPACK</span><span class="o">=</span><span class="mi">1</span> <span class="o">-</span><span class="n">DUSE_DIST_KVSTORE</span><span class="o">=</span><span class="mi">0</span> <span class="o">-</span><span class="n">DCUDA_ARCH_NAME</span><span class="o">=</span><span class="n">All</span> <span class="o">-</span><span class="n">DUSE_MKLDNN</span><span class="o">=</span><span class="mi">1</span> <span class="o">-</span><span class="n">DCMAKE_BUILD_TYPE</span><span class="o">=</span><span class="n">Release</span>
</pre></div>
</div>
<ol class="simple">
<li>Enable Intel MKL-DNN and Intel MKL as BLAS library by the command:</li>
</ol>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="o">></span><span class="s2">"C:\Program Files (x86)\IntelSWTools\compilers_and_libraries\windows\mkl</span><span class="se">\b</span><span class="s2">in\mklvars.bat"</span> <span class="n">intel64</span>
<span class="o">></span><span class="n">cmake</span> <span class="o">-</span><span class="n">G</span> <span class="s2">"Visual Studio 14 Win64"</span> <span class="o">..</span> <span class="o">-</span><span class="n">DUSE_CUDA</span><span class="o">=</span><span class="mi">0</span> <span class="o">-</span><span class="n">DUSE_CUDNN</span><span class="o">=</span><span class="mi">0</span> <span class="o">-</span><span class="n">DUSE_NVRTC</span><span class="o">=</span><span class="mi">0</span> <span class="o">-</span><span class="n">DUSE_OPENCV</span><span class="o">=</span><span class="mi">1</span> <span class="o">-</span><span class="n">DUSE_OPENMP</span><span class="o">=</span><span class="mi">1</span> <span class="o">-</span><span class="n">DUSE_PROFILER</span><span class="o">=</span><span class="mi">1</span> <span class="o">-</span><span class="n">DUSE_BLAS</span><span class="o">=</span><span class="n">mkl</span> <span class="o">-</span><span class="n">DUSE_LAPACK</span><span class="o">=</span><span class="mi">1</span> <span class="o">-</span><span class="n">DUSE_DIST_KVSTORE</span><span class="o">=</span><span class="mi">0</span> <span class="o">-</span><span class="n">DCUDA_ARCH_NAME</span><span class="o">=</span><span class="n">All</span> <span class="o">-</span><span class="n">DUSE_MKLDNN</span><span class="o">=</span><span class="mi">1</span> <span class="o">-</span><span class="n">DCMAKE_BUILD_TYPE</span><span class="o">=</span><span class="n">Release</span> <span class="o">-</span><span class="n">DMKL_ROOT</span><span class="o">=</span><span class="s2">"C:\Program Files (x86)\IntelSWTools\compilers_and_libraries\windows\mkl"</span> 
</pre></div>
</div>
<ol class="simple">
<li>After the CMake successfully completed, in Visual Studio, open the solution file <code class="docutils literal"><span class="pre">.sln</span></code> and compile it, or compile the the MXNet source code by using following command:</li>
</ol>
<div class="highlight-r"><div class="highlight"><pre><span></span><span class="n">msbuild</span> <span class="n">mxnet.sln</span> <span class="o">/</span><span class="n">p</span><span class="o">:</span><span class="n">Configuration</span><span class="o">=</span><span class="n">Release</span><span class="p">;</span><span class="n">Platform</span><span class="o">=</span><span class="n">x64</span> <span class="o">/</span><span class="n">maxcpucount</span>
</pre></div>
</div>
<p>These commands produce mxnet library called <code class="docutils literal"><span class="pre">libmxnet.dll</span></code> in the <code class="docutils literal"><span class="pre">./build/Release/</span></code> or <code class="docutils literal"><span class="pre">./build/Debug</span></code> folder. Also <code class="docutils literal"><span class="pre">libmkldnn.dll</span></code> with be in the <code class="docutils literal"><span class="pre">./build/3rdparty/mkldnn/src/Release/</span></code></p>
<ol class="simple">
<li>Make sure that all the dll files used above(such as <code class="docutils literal"><span class="pre">libmkldnn.dll</span></code>, <code class="docutils literal"><span class="pre">libmklml*.dll</span></code>, <code class="docutils literal"><span class="pre">libiomp5.dll</span></code>, <code class="docutils literal"><span class="pre">libopenblas*.dll</span></code>, etc) are added to the system PATH. For convinence, you can put all of them to <code class="docutils literal"><span class="pre">\windows\system32</span></code>. Or you will come across <code class="docutils literal"><span class="pre">Not</span> <span class="pre">Found</span> <span class="pre">Dependencies</span></code> when loading MXNet.</li>
</ol>
<p><strong>Visual Studio 2017</strong></p>
<p>User can follow the same steps of Visual Studio 2015 to build MXNET with MKL-DNN, but change the version related command, for example,<code class="docutils literal"><span class="pre">C:\opencv\build\x64\vc15\bin</span></code> and build command is as below:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="o">></span><span class="n">cmake</span> <span class="o">-</span><span class="n">G</span> <span class="s2">"Visual Studio 15 Win64"</span> <span class="o">..</span> <span class="o">-</span><span class="n">DUSE_CUDA</span><span class="o">=</span><span class="mi">0</span> <span class="o">-</span><span class="n">DUSE_CUDNN</span><span class="o">=</span><span class="mi">0</span> <span class="o">-</span><span class="n">DUSE_NVRTC</span><span class="o">=</span><span class="mi">0</span> <span class="o">-</span><span class="n">DUSE_OPENCV</span><span class="o">=</span><span class="mi">1</span> <span class="o">-</span><span class="n">DUSE_OPENMP</span><span class="o">=</span><span class="mi">1</span> <span class="o">-</span><span class="n">DUSE_PROFILER</span><span class="o">=</span><span class="mi">1</span> <span class="o">-</span><span class="n">DUSE_BLAS</span><span class="o">=</span><span class="n">mkl</span> <span class="o">-</span><span class="n">DUSE_LAPACK</span><span class="o">=</span><span class="mi">1</span> <span class="o">-</span><span class="n">DUSE_DIST_KVSTORE</span><span class="o">=</span><span class="mi">0</span> <span class="o">-</span><span class="n">DCUDA_ARCH_NAME</span><span class="o">=</span><span class="n">All</span> <span class="o">-</span><span class="n">DUSE_MKLDNN</span><span class="o">=</span><span class="mi">1</span> <span class="o">-</span><span class="n">DCMAKE_BUILD_TYPE</span><span class="o">=</span><span class="n">Release</span> <span class="o">-</span><span class="n">DMKL_ROOT</span><span class="o">=</span><span class="s2">"C:\Program Files (x86)\IntelSWTools\compilers_and_libraries\windows\mkl"</span>
</pre></div>
</div>
<h2 id="4">Verify MXNet with python</h2><p>Preinstall python and some dependent modules:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">numpy</span> <span class="n">graphviz</span>
<span class="nb">set</span> <span class="n">PYTHONPATH</span><span class="o">=</span><span class="p">[</span><span class="n">workdir</span><span class="p">]</span>\<span class="n">incubator</span><span class="o">-</span><span class="n">mxnet</span>\<span class="n">python</span>
</pre></div>
</div>
<p>or install mxnet</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">cd</span> <span class="n">python</span>
<span class="n">sudo</span> <span class="n">python</span> <span class="n">setup</span><span class="o">.</span><span class="n">py</span> <span class="n">install</span>
<span class="n">python</span> <span class="o">-</span><span class="n">c</span> <span class="s2">"import mxnet as mx;print((mx.nd.ones((2, 3))*2).asnumpy());"</span>
</pre></div>
</div>
<p>Expected Output:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="p">[[</span> <span class="mf">2.</span>  <span class="mf">2.</span>  <span class="mf">2.</span><span class="p">]</span>
 <span class="p">[</span> <span class="mf">2.</span>  <span class="mf">2.</span>  <span class="mf">2.</span><span class="p">]]</span>
</pre></div>
</div>
</div>
<div class="section" id="verify-whether-mkl-dnn-works">
<span id="verify-whether-mkl-dnn-works"></span><h2>Verify whether MKL-DNN works<a class="headerlink" href="#verify-whether-mkl-dnn-works" title="Permalink to this headline">¶</a></h2>
<p>After MXNet is installed, you can verify if MKL-DNN backend works well with a single Convolution layer.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mxnet</span> <span class="k">as</span> <span class="nn">mx</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">num_filter</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">kernel</span> <span class="o">=</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">pad</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">mx</span><span class="o">.</span><span class="n">sym</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="s1">'x'</span><span class="p">)</span>
<span class="n">w</span> <span class="o">=</span> <span class="n">mx</span><span class="o">.</span><span class="n">sym</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="s1">'w'</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">mx</span><span class="o">.</span><span class="n">sym</span><span class="o">.</span><span class="n">Convolution</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="n">w</span><span class="p">,</span> <span class="n">num_filter</span><span class="o">=</span><span class="n">num_filter</span><span class="p">,</span> <span class="n">kernel</span><span class="o">=</span><span class="n">kernel</span><span class="p">,</span> <span class="n">no_bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="n">pad</span><span class="p">)</span>
<span class="n">exe</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">simple_bind</span><span class="p">(</span><span class="n">mx</span><span class="o">.</span><span class="n">cpu</span><span class="p">(),</span> <span class="n">x</span><span class="o">=</span><span class="n">shape</span><span class="p">)</span>

<span class="n">exe</span><span class="o">.</span><span class="n">arg_arrays</span><span class="p">[</span><span class="mi">0</span><span class="p">][:]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">exe</span><span class="o">.</span><span class="n">arg_arrays</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">exe</span><span class="o">.</span><span class="n">arg_arrays</span><span class="p">[</span><span class="mi">1</span><span class="p">][:]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">exe</span><span class="o">.</span><span class="n">arg_arrays</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">exe</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">is_train</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">o</span> <span class="o">=</span> <span class="n">exe</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">t</span> <span class="o">=</span> <span class="n">o</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span>
</pre></div>
</div>
<p>More detailed debugging and profiling information can be logged by setting the environment variable ‘MKLDNN_VERBOSE’:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">export</span> <span class="n">MKLDNN_VERBOSE</span><span class="o">=</span><span class="mi">1</span>
</pre></div>
</div>
<p>For example, by running above code snippet, the following debugging logs providing more insights on MKL-DNN primitives <code class="docutils literal"><span class="pre">convolution</span></code> and <code class="docutils literal"><span class="pre">reorder</span></code>. That includes: Memory layout, infer shape and the time cost of primitive execution.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">mkldnn_verbose</span><span class="p">,</span><span class="n">exec</span><span class="p">,</span><span class="n">reorder</span><span class="p">,</span><span class="n">jit</span><span class="p">:</span><span class="n">uni</span><span class="p">,</span><span class="n">undef</span><span class="p">,</span><span class="ow">in</span><span class="p">:</span><span class="n">f32_nchw</span> <span class="n">out</span><span class="p">:</span><span class="n">f32_nChw16c</span><span class="p">,</span><span class="n">num</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="mi">32</span><span class="n">x32x256x256</span><span class="p">,</span><span class="mf">6.47681</span>
<span class="n">mkldnn_verbose</span><span class="p">,</span><span class="n">exec</span><span class="p">,</span><span class="n">reorder</span><span class="p">,</span><span class="n">jit</span><span class="p">:</span><span class="n">uni</span><span class="p">,</span><span class="n">undef</span><span class="p">,</span><span class="ow">in</span><span class="p">:</span><span class="n">f32_oihw</span> <span class="n">out</span><span class="p">:</span><span class="n">f32_OIhw16i16o</span><span class="p">,</span><span class="n">num</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="mi">32</span><span class="n">x32x3x3</span><span class="p">,</span><span class="mf">0.0429688</span>
<span class="n">mkldnn_verbose</span><span class="p">,</span><span class="n">exec</span><span class="p">,</span><span class="n">convolution</span><span class="p">,</span><span class="n">jit</span><span class="p">:</span><span class="n">avx512_common</span><span class="p">,</span><span class="n">forward_inference</span><span class="p">,</span><span class="n">fsrc</span><span class="p">:</span><span class="n">nChw16c</span> <span class="n">fwei</span><span class="p">:</span><span class="n">OIhw16i16o</span> <span class="n">fbia</span><span class="p">:</span><span class="n">undef</span> <span class="n">fdst</span><span class="p">:</span><span class="n">nChw16c</span><span class="p">,</span><span class="n">alg</span><span class="p">:</span><span class="n">convolution_direct</span><span class="p">,</span><span class="n">mb32_g1ic32oc32_ih256oh256kh3sh1dh0ph1_iw256ow256kw3sw1dw0pw1</span><span class="p">,</span><span class="mf">9.98193</span>
<span class="n">mkldnn_verbose</span><span class="p">,</span><span class="n">exec</span><span class="p">,</span><span class="n">reorder</span><span class="p">,</span><span class="n">jit</span><span class="p">:</span><span class="n">uni</span><span class="p">,</span><span class="n">undef</span><span class="p">,</span><span class="ow">in</span><span class="p">:</span><span class="n">f32_oihw</span> <span class="n">out</span><span class="p">:</span><span class="n">f32_OIhw16i16o</span><span class="p">,</span><span class="n">num</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="mi">32</span><span class="n">x32x3x3</span><span class="p">,</span><span class="mf">0.0510254</span>
<span class="n">mkldnn_verbose</span><span class="p">,</span><span class="n">exec</span><span class="p">,</span><span class="n">reorder</span><span class="p">,</span><span class="n">jit</span><span class="p">:</span><span class="n">uni</span><span class="p">,</span><span class="n">undef</span><span class="p">,</span><span class="ow">in</span><span class="p">:</span><span class="n">f32_nChw16c</span> <span class="n">out</span><span class="p">:</span><span class="n">f32_nchw</span><span class="p">,</span><span class="n">num</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="mi">32</span><span class="n">x32x256x256</span><span class="p">,</span><span class="mf">20.4819</span>
</pre></div>
</div>
<h2 id="5">Enable MKL BLAS</h2><p>With MKL BLAS, the performace is expected to furtherly improved with variable range depending on the computation load of the models.
You can redistribute not only dynamic libraries but also headers, examples and static libraries on accepting the license <a class="reference external" href="https://software.intel.com/en-us/license/intel-simplified-software-license">Intel Simplified license</a>.
Installing the full MKL installation enables MKL support for all operators under the linalg namespace.</p>
<ol class="simple">
<li>Download and install the latest full MKL version following instructions on the <a class="reference external" href="https://software.intel.com/en-us/mkl">intel website.</a></li>
<li>Run <code class="docutils literal"><span class="pre">make</span> <span class="pre">-j</span> <span class="pre">${nproc}</span> <span class="pre">USE_BLAS=mkl</span></code></li>
<li>Navigate into the python directory</li>
<li>Run <code class="docutils literal"><span class="pre">sudo</span> <span class="pre">python</span> <span class="pre">setup.py</span> <span class="pre">install</span></code></li>
</ol>
</div>
<div class="section" id="verify-whether-mkl-works">
<span id="verify-whether-mkl-works"></span><h2>Verify whether MKL works<a class="headerlink" href="#verify-whether-mkl-works" title="Permalink to this headline">¶</a></h2>
<p>After MXNet is installed, you can verify if MKL BLAS works well with a single dot layer.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mxnet</span> <span class="k">as</span> <span class="nn">mx</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">shape_x</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>
<span class="n">shape_w</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>

<span class="n">x_npy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">shape_x</span><span class="p">)</span>
<span class="n">w_npy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">shape_w</span><span class="p">)</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">mx</span><span class="o">.</span><span class="n">sym</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="s1">'x'</span><span class="p">)</span>
<span class="n">w</span> <span class="o">=</span> <span class="n">mx</span><span class="o">.</span><span class="n">sym</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="s1">'w'</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">mx</span><span class="o">.</span><span class="n">sym</span><span class="o">.</span><span class="n">batch_dot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">transpose_b</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">exe</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">simple_bind</span><span class="p">(</span><span class="n">mx</span><span class="o">.</span><span class="n">cpu</span><span class="p">(),</span> <span class="n">x</span><span class="o">=</span><span class="n">x_npy</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">w</span><span class="o">=</span><span class="n">w_npy</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">exe</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">is_train</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">o</span> <span class="o">=</span> <span class="n">exe</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">t</span> <span class="o">=</span> <span class="n">o</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span>
</pre></div>
</div>
<p>You can open the <code class="docutils literal"><span class="pre">MKL_VERBOSE</span></code> flag by setting environment variable:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">export</span> <span class="n">MKL_VERBOSE</span><span class="o">=</span><span class="mi">1</span>
</pre></div>
</div>
<p>Then by running above code snippet, you probably will get the following output message which means <code class="docutils literal"><span class="pre">SGEMM</span></code> primitive from MKL are called. Layout information and primitive execution performance are also demonstrated in the log message.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">Numpy</span> <span class="o">+</span> <span class="n">Intel</span><span class="p">(</span><span class="n">R</span><span class="p">)</span> <span class="n">MKL</span><span class="p">:</span> <span class="n">THREADING</span> <span class="n">LAYER</span><span class="p">:</span> <span class="p">(</span><span class="n">null</span><span class="p">)</span>
<span class="n">Numpy</span> <span class="o">+</span> <span class="n">Intel</span><span class="p">(</span><span class="n">R</span><span class="p">)</span> <span class="n">MKL</span><span class="p">:</span> <span class="n">setting</span> <span class="n">Intel</span><span class="p">(</span><span class="n">R</span><span class="p">)</span> <span class="n">MKL</span> <span class="n">to</span> <span class="n">use</span> <span class="n">INTEL</span> <span class="n">OpenMP</span> <span class="n">runtime</span>
<span class="n">Numpy</span> <span class="o">+</span> <span class="n">Intel</span><span class="p">(</span><span class="n">R</span><span class="p">)</span> <span class="n">MKL</span><span class="p">:</span> <span class="n">preloading</span> <span class="n">libiomp5</span><span class="o">.</span><span class="n">so</span> <span class="n">runtime</span>
<span class="n">MKL_VERBOSE</span> <span class="n">Intel</span><span class="p">(</span><span class="n">R</span><span class="p">)</span> <span class="n">MKL</span> <span class="mf">2019.0</span> <span class="n">Update</span> <span class="mi">3</span> <span class="n">Product</span> <span class="n">build</span> <span class="mi">20190125</span> <span class="k">for</span> <span class="n">Intel</span><span class="p">(</span><span class="n">R</span><span class="p">)</span> <span class="mi">64</span> <span class="n">architecture</span> <span class="n">Intel</span><span class="p">(</span><span class="n">R</span><span class="p">)</span> <span class="n">Advanced</span> <span class="n">Vector</span> <span class="n">Extensions</span> <span class="mi">512</span> <span class="p">(</span><span class="n">Intel</span><span class="p">(</span><span class="n">R</span><span class="p">)</span> <span class="n">AVX</span><span class="o">-</span><span class="mi">512</span><span class="p">)</span> <span class="n">enabled</span> <span class="n">processors</span><span class="p">,</span> <span class="n">Lnx</span> <span class="mf">2.40</span><span class="n">GHz</span> <span class="n">lp64</span> <span class="n">intel_thread</span> <span class="n">NMICDev</span><span class="p">:</span><span class="mi">0</span>
<span class="n">MKL_VERBOSE</span> <span class="n">SGEMM</span><span class="p">(</span><span class="n">T</span><span class="p">,</span><span class="n">N</span><span class="p">,</span><span class="mi">12</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mh">0x7f7f927b1378</span><span class="p">,</span><span class="mh">0x1bc2140</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mh">0x1ba8040</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mh">0x7f7f927b1380</span><span class="p">,</span><span class="mh">0x7f7f7400a280</span><span class="p">,</span><span class="mi">12</span><span class="p">)</span> <span class="mf">8.93</span><span class="n">ms</span> <span class="n">CNR</span><span class="p">:</span><span class="n">OFF</span> <span class="n">Dyn</span><span class="p">:</span><span class="mi">1</span> <span class="n">FastMM</span><span class="p">:</span><span class="mi">1</span> <span class="n">TID</span><span class="p">:</span><span class="mi">0</span>  <span class="n">NThr</span><span class="p">:</span><span class="mi">40</span> <span class="n">WDiv</span><span class="p">:</span><span class="n">HOST</span><span class="p">:</span><span class="o">+</span><span class="mf">0.000</span>
</pre></div>
</div>
<h2 id="6">Enable graph optimization</h2><p>Graph optimization by subgraph feature are available in master branch. You can build from source and then use below command to enable this <em>experimental</em> feature for better performance:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">export</span> <span class="n">MXNET_SUBGRAPH_BACKEND</span><span class="o">=</span><span class="n">MKLDNN</span>
</pre></div>
</div>
<p>This limitations of this experimental feature are:</p>
<ul class="simple">
<li>Use this feature only for inference. When training, be sure to turn the feature off by unsetting the <code class="docutils literal"><span class="pre">MXNET_SUBGRAPH_BACKEND</span></code> environment variable.</li>
<li>This feature will only run on the CPU, even if you’re using a GPU-enabled build of MXNet.</li>
</ul>
<h2 id="7">Quantization and Inference with INT8</h2><p>Benefiting from Intel MKL-DNN, MXNet built with Intel MKL-DNN brings outstanding performance improvement on quantization and inference with INT8 Intel CPU Platform on Intel Xeon Scalable Platform.</p>
<ul class="simple">
<li><a class="reference external" href="https://github.com/apache/incubator-mxnet/tree/master/example/quantization">CNN Quantization Examples</a>.</li>
<li><a class="reference external" href="https://cwiki.apache.org/confluence/display/MXNET/MXNet+Graph+Optimization+and+Quantization+based+on+subgraph+and+MKL-DNN">Model Quantization for Production-Level Neural Network Inference</a>.</li>
</ul>
<h2 id="8">Next Steps and Support</h2><ul class="simple">
<li>For questions or support specific to MKL, visit the <a class="reference external" href="https://software.intel.com/en-us/mkl">Intel MKL</a> website.</li>
<li>For questions or support specific to MKL, visit the <a class="reference external" href="https://github.com/intel/mkl-dnn">Intel MKLDNN</a> website.</li>
<li>If you find bugs, please open an issue on GitHub for <a class="reference external" href="https://github.com/apache/incubator-mxnet/labels/MKL">MXNet with MKL</a> or <a class="reference external" href="https://github.com/apache/incubator-mxnet/labels/MKLDNN">MXNet with MKLDNN</a>.</li>
</ul>
</div>
</div>
</div>
</div>
<div aria-label="main navigation" class="sphinxsidebar rightsidebar" role="navigation">
<div class="sphinxsidebarwrapper">
<h3><a href="../../index.html">Table Of Contents</a></h3>
<ul>
<li><a class="reference internal" href="#">Build/Install MXNet with MKL-DNN</a><ul>
<li><a class="reference internal" href="#prerequisites">Prerequisites</a></li>
<li><a class="reference internal" href="#clone-mxnet-sources">Clone MXNet sources</a></li>
<li><a class="reference internal" href="#build-mxnet-with-mkl-dnn">Build MXNet with MKL-DNN</a></li>
<li><a class="reference internal" href="#prerequisites">Prerequisites</a></li>
<li><a class="reference internal" href="#clone-mxnet-sources">Clone MXNet sources</a></li>
<li><a class="reference internal" href="#build-mxnet-with-mkl-dnn">Build MXNet with MKL-DNN</a></li>
<li><a class="reference internal" href="#verify-whether-mkl-dnn-works">Verify whether MKL-DNN works</a></li>
<li><a class="reference internal" href="#verify-whether-mkl-works">Verify whether MKL works</a></li>
</ul>
</li>
</ul>
</div>
</div>
</div><div class="footer">
<div class="section-disclaimer">
<div class="container">
<div>
<img height="60" src="https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/image/apache_incubator_logo.png"/>
<p>
            Apache MXNet is an effort undergoing incubation at The Apache Software Foundation (ASF), <strong>sponsored by the <i>Apache Incubator</i></strong>. Incubation is required of all newly accepted projects until a further review indicates that the infrastructure, communications, and decision making process have stabilized in a manner consistent with other successful ASF projects. While incubation status is not necessarily a reflection of the completeness or stability of the code, it does indicate that the project has yet to be fully endorsed by the ASF.
        </p>
<p>
            "Copyright © 2017-2018, The Apache Software Foundation
            Apache MXNet, MXNet, Apache, the Apache feather, and the Apache MXNet project logo are either registered trademarks or trademarks of the Apache Software Foundation."
        </p>
</div>
</div>
</div>
</div> <!-- pagename != index -->
</div>
<script crossorigin="anonymous" integrity="sha384-0mSbJDEHialfmuBBQP6A4Qrprq5OVfW37PRR3j5ELqxss1yVqOtnepnHVP9aJ7xS" src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/js/bootstrap.min.js"></script>
<script src="../../_static/js/sidebar.js" type="text/javascript"></script>
<script src="../../_static/js/search.js" type="text/javascript"></script>
<script src="../../_static/js/navbar.js" type="text/javascript"></script>
<script src="../../_static/js/clipboard.min.js" type="text/javascript"></script>
<script src="../../_static/js/copycode.js" type="text/javascript"></script>
<script src="../../_static/js/page.js" type="text/javascript"></script>
<script src="../../_static/js/docversion.js" type="text/javascript"></script>
<script type="text/javascript">
        $('body').ready(function () {
            $('body').css('visibility', 'visible');
        });
    </script>
</body>
</html>