<!DOCTYPE html PUBLIC ""
    "">

<html><head><meta charset="utf-8"/><title>org.apache.clojure-mxnet.ndarray-random-api documentation</title><link href="css/default.css" rel="stylesheet" type="text/css"/><link href="css/highlight.css" rel="stylesheet" type="text/css"/><script src="js/highlight.min.js" type="text/javascript"></script><script src="js/jquery.min.js" type="text/javascript"></script><script src="js/page_effects.js" type="text/javascript"></script><script>hljs.initHighlightingOnLoad();</script></head><body><div id="header"><h2>Generated by <a href="https://github.com/weavejester/codox">Codox</a></h2><h1><a href="index.html"><span class="project-title"><span class="project-name">Clojure-mxnet</span> <span class="project-version">1.5.1-SNAPSHOT</span></span></a></h1></div><div class="sidebar primary"><h3 class="no-link"><span class="inner">Project</span></h3><ul class="index-link"><li class="depth-1 "><a href="index.html"><div class="inner">Index</div></a></li></ul><h3 class="no-link"><span class="inner">Namespaces</span></h3><ul><li class="depth-1"><div class="no-link"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>org</span></div></div></li><li class="depth-2"><div class="no-link"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>apache</span></div></div></li><li class="depth-3"><div class="no-link"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>clojure-mxnet</span></div></div></li><li class="depth-4 branch"><a href="org.apache.clojure-mxnet.base.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>base</span></div></a></li><li class="depth-4 branch"><a href="org.apache.clojure-mxnet.callback.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>callback</span></div></a></li><li class="depth-4 branch"><a href="org.apache.clojure-mxnet.context.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>context</span></div></a></li><li class="depth-4 branch"><a href="org.apache.clojure-mxnet.dtype.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>dtype</span></div></a></li><li class="depth-4 branch"><a href="org.apache.clojure-mxnet.eval-metric.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>eval-metric</span></div></a></li><li class="depth-4 branch"><a href="org.apache.clojure-mxnet.executor.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>executor</span></div></a></li><li class="depth-4 branch"><a href="org.apache.clojure-mxnet.image.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>image</span></div></a></li><li class="depth-4 branch"><a href="org.apache.clojure-mxnet.infer.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>infer</span></div></a></li><li class="depth-4 branch"><a href="org.apache.clojure-mxnet.initializer.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>initializer</span></div></a></li><li class="depth-4 branch"><a href="org.apache.clojure-mxnet.io.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>io</span></div></a></li><li class="depth-4 branch"><a href="org.apache.clojure-mxnet.kvstore.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>kvstore</span></div></a></li><li class="depth-4 branch"><a href="org.apache.clojure-mxnet.kvstore-server.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>kvstore-server</span></div></a></li><li class="depth-4 branch"><a href="org.apache.clojure-mxnet.layout.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>layout</span></div></a></li><li class="depth-4 branch"><a href="org.apache.clojure-mxnet.lr-scheduler.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>lr-scheduler</span></div></a></li><li class="depth-4 branch"><a href="org.apache.clojure-mxnet.module.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>module</span></div></a></li><li class="depth-4 branch"><a href="org.apache.clojure-mxnet.monitor.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>monitor</span></div></a></li><li class="depth-4 branch"><a href="org.apache.clojure-mxnet.ndarray.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>ndarray</span></div></a></li><li class="depth-4 branch"><a href="org.apache.clojure-mxnet.ndarray-api.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>ndarray-api</span></div></a></li><li class="depth-4 branch current"><a href="org.apache.clojure-mxnet.ndarray-random-api.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>ndarray-random-api</span></div></a></li><li class="depth-4 branch"><a href="org.apache.clojure-mxnet.optimizer.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>optimizer</span></div></a></li><li class="depth-4 branch"><a href="org.apache.clojure-mxnet.primitives.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>primitives</span></div></a></li><li class="depth-4 branch"><a href="org.apache.clojure-mxnet.profiler.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>profiler</span></div></a></li><li class="depth-4 branch"><a href="org.apache.clojure-mxnet.random.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>random</span></div></a></li><li class="depth-4 branch"><a href="org.apache.clojure-mxnet.resource-scope.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>resource-scope</span></div></a></li><li class="depth-4 branch"><a href="org.apache.clojure-mxnet.shape.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>shape</span></div></a></li><li class="depth-4 branch"><a href="org.apache.clojure-mxnet.symbol.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>symbol</span></div></a></li><li class="depth-4 branch"><a href="org.apache.clojure-mxnet.symbol-api.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>symbol-api</span></div></a></li><li class="depth-4 branch"><a href="org.apache.clojure-mxnet.symbol-random-api.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>symbol-random-api</span></div></a></li><li class="depth-4 branch"><a href="org.apache.clojure-mxnet.util.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>util</span></div></a></li><li class="depth-4"><a href="org.apache.clojure-mxnet.visualization.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>visualization</span></div></a></li></ul></div><div class="sidebar secondary"><h3><a href="#top"><span class="inner">Public Vars</span></a></h3><ul><li class="depth-1"><a href="org.apache.clojure-mxnet.ndarray-random-api.html#var-exponential"><div class="inner"><span>exponential</span></div></a></li><li class="depth-1"><a href="org.apache.clojure-mxnet.ndarray-random-api.html#var-exponential-like"><div class="inner"><span>exponential-like</span></div></a></li><li class="depth-1"><a href="org.apache.clojure-mxnet.ndarray-random-api.html#var-gamma"><div class="inner"><span>gamma</span></div></a></li><li class="depth-1"><a href="org.apache.clojure-mxnet.ndarray-random-api.html#var-gamma-like"><div class="inner"><span>gamma-like</span></div></a></li><li class="depth-1"><a href="org.apache.clojure-mxnet.ndarray-random-api.html#var-generalized-negative-binomial"><div class="inner"><span>generalized-negative-binomial</span></div></a></li><li class="depth-1"><a href="org.apache.clojure-mxnet.ndarray-random-api.html#var-generalized-negative-binomial-like"><div class="inner"><span>generalized-negative-binomial-like</span></div></a></li><li class="depth-1"><a href="org.apache.clojure-mxnet.ndarray-random-api.html#var-multinomial-like"><div class="inner"><span>multinomial-like</span></div></a></li><li class="depth-1"><a href="org.apache.clojure-mxnet.ndarray-random-api.html#var-negative-binomial"><div class="inner"><span>negative-binomial</span></div></a></li><li class="depth-1"><a href="org.apache.clojure-mxnet.ndarray-random-api.html#var-negative-binomial-like"><div class="inner"><span>negative-binomial-like</span></div></a></li><li class="depth-1"><a href="org.apache.clojure-mxnet.ndarray-random-api.html#var-normal"><div class="inner"><span>normal</span></div></a></li><li class="depth-1"><a href="org.apache.clojure-mxnet.ndarray-random-api.html#var-normal-like"><div class="inner"><span>normal-like</span></div></a></li><li class="depth-1"><a href="org.apache.clojure-mxnet.ndarray-random-api.html#var-poisson"><div class="inner"><span>poisson</span></div></a></li><li class="depth-1"><a href="org.apache.clojure-mxnet.ndarray-random-api.html#var-poisson-like"><div class="inner"><span>poisson-like</span></div></a></li><li class="depth-1"><a href="org.apache.clojure-mxnet.ndarray-random-api.html#var-randint"><div class="inner"><span>randint</span></div></a></li><li class="depth-1"><a href="org.apache.clojure-mxnet.ndarray-random-api.html#var-uniform"><div class="inner"><span>uniform</span></div></a></li><li class="depth-1"><a href="org.apache.clojure-mxnet.ndarray-random-api.html#var-uniform-like"><div class="inner"><span>uniform-like</span></div></a></li></ul></div><div class="namespace-docs" id="content"><h1 class="anchor" id="top">org.apache.clojure-mxnet.ndarray-random-api</h1><div class="doc"><pre class="plaintext">Experimental
</pre></div><div class="public anchor" id="var-exponential"><h3>exponential</h3><div class="usage"><code>(exponential)</code><code>(exponential {:keys [lam shape ctx dtype out], :or {lam nil, shape nil, ctx nil, dtype nil, out nil}, :as opts})</code></div><div class="doc"><pre class="plaintext">Draw random samples from an exponential distribution.

Samples are distributed according to an exponential distribution parametrized by *lambda* (rate).

Example::

   exponential(lam=4, shape=(2,2)) = [[ 0.0097189 ,  0.08999364],
                                      [ 0.04146638,  0.31715935]]


Defined in src/operator/random/sample_op.cc:L137

`lam`: Lambda parameter (rate) of the exponential distribution. (optional)
`shape`: Shape of the output. (optional)
`ctx`: Context of output, in format [cpu|gpu|cpu_pinned](n). Only used for imperative calls. (optional)
`dtype`: DType of the output in case this can't be inferred. Defaults to float32 if not defined (dtype=None). (optional)
`out`: Output array. (optional)</pre></div></div><div class="public anchor" id="var-exponential-like"><h3>exponential-like</h3><div class="usage"><code>(exponential-like {:keys [lam shape dtype out], :or {shape nil, dtype nil, out nil}, :as opts})</code></div><div class="doc"><pre class="plaintext">Concurrent sampling from multiple
exponential distributions with parameters lambda (rate).

The parameters of the distributions are provided as an input array.
Let *[s]* be the shape of the input array, *n* be the dimension of *[s]*, *[t]*
be the shape specified as the parameter of the operator, and *m* be the dimension
of *[t]*. Then the output will be a *(n+m)*-dimensional array with shape *[s]x[t]*.

For any valid *n*-dimensional index *i* with respect to the input array, *output[i]*
will be an *m*-dimensional array that holds randomly drawn samples from the distribution
which is parameterized by the input value at index *i*. If the shape parameter of the
operator is not set, then one sample will be drawn per distribution and the output array
has the same shape as the input array.

Examples::

   lam = [ 1.0, 8.5 ]

   // Draw a single sample for each distribution
   sample_exponential(lam) = [ 0.51837951,  0.09994757]

   // Draw a vector containing two samples for each distribution
   sample_exponential(lam, shape=(2)) = [[ 0.51837951,  0.19866663],
                                         [ 0.09994757,  0.50447971]]


Defined in src/operator/random/multisample_op.cc:L284

`lam`: Lambda (rate) parameters of the distributions.
`shape`: Shape to be sampled from each random distribution. (optional)
`dtype`: DType of the output in case this can't be inferred. Defaults to float32 if not defined (dtype=None). (optional)
`out`: Output array. (optional)</pre></div></div><div class="public anchor" id="var-gamma"><h3>gamma</h3><div class="usage"><code>(gamma)</code><code>(gamma {:keys [alpha beta shape ctx dtype out], :or {alpha nil, beta nil, shape nil, ctx nil, dtype nil, out nil}, :as opts})</code></div><div class="doc"><pre class="plaintext">Draw random samples from a gamma distribution.

Samples are distributed according to a gamma distribution parametrized by *alpha* (shape) and *beta* (scale).

Example::

   gamma(alpha=9, beta=0.5, shape=(2,2)) = [[ 7.10486984,  3.37695289],
                                            [ 3.91697288,  3.65933681]]


Defined in src/operator/random/sample_op.cc:L125

`alpha`: Alpha parameter (shape) of the gamma distribution. (optional)
`beta`: Beta parameter (scale) of the gamma distribution. (optional)
`shape`: Shape of the output. (optional)
`ctx`: Context of output, in format [cpu|gpu|cpu_pinned](n). Only used for imperative calls. (optional)
`dtype`: DType of the output in case this can't be inferred. Defaults to float32 if not defined (dtype=None). (optional)
`out`: Output array. (optional)</pre></div></div><div class="public anchor" id="var-gamma-like"><h3>gamma-like</h3><div class="usage"><code>(gamma-like alpha beta)</code><code>(gamma-like {:keys [alpha shape dtype beta out], :or {shape nil, dtype nil, out nil}, :as opts})</code></div><div class="doc"><pre class="plaintext">Concurrent sampling from multiple
gamma distributions with parameters *alpha* (shape) and *beta* (scale).

The parameters of the distributions are provided as input arrays.
Let *[s]* be the shape of the input arrays, *n* be the dimension of *[s]*, *[t]*
be the shape specified as the parameter of the operator, and *m* be the dimension
of *[t]*. Then the output will be a *(n+m)*-dimensional array with shape *[s]x[t]*.

For any valid *n*-dimensional index *i* with respect to the input arrays, *output[i]*
will be an *m*-dimensional array that holds randomly drawn samples from the distribution
which is parameterized by the input values at index *i*. If the shape parameter of the
operator is not set, then one sample will be drawn per distribution and the output array
has the same shape as the input arrays.

Examples::

   alpha = [ 0.0, 2.5 ]
   beta = [ 1.0, 0.7 ]

   // Draw a single sample for each distribution
   sample_gamma(alpha, beta) = [ 0.        ,  2.25797319]

   // Draw a vector containing two samples for each distribution
   sample_gamma(alpha, beta, shape=(2)) = [[ 0.        ,  0.        ],
                                           [ 2.25797319,  1.70734084]]


Defined in src/operator/random/multisample_op.cc:L282

`alpha`: Alpha (shape) parameters of the distributions.
`shape`: Shape to be sampled from each random distribution. (optional)
`dtype`: DType of the output in case this can't be inferred. Defaults to float32 if not defined (dtype=None). (optional)
`beta`: Beta (scale) parameters of the distributions.
`out`: Output array. (optional)</pre></div></div><div class="public anchor" id="var-generalized-negative-binomial"><h3>generalized-negative-binomial</h3><div class="usage"><code>(generalized-negative-binomial)</code><code>(generalized-negative-binomial {:keys [mu alpha shape ctx dtype out], :or {mu nil, alpha nil, shape nil, ctx nil, dtype nil, out nil}, :as opts})</code></div><div class="doc"><pre class="plaintext">Draw random samples from a generalized negative binomial distribution.

Samples are distributed according to a generalized negative binomial distribution parametrized by
*mu* (mean) and *alpha* (dispersion). *alpha* is defined as *1/k* where *k* is the failure limit of the
number of unsuccessful experiments (generalized to real numbers).
Samples will always be returned as a floating point data type.

Example::

   generalized_negative_binomial(mu=2.0, alpha=0.3, shape=(2,2)) = [[ 2.,  1.],
                                                                    [ 6.,  4.]]


Defined in src/operator/random/sample_op.cc:L179

`mu`: Mean of the negative binomial distribution. (optional)
`alpha`: Alpha (dispersion) parameter of the negative binomial distribution. (optional)
`shape`: Shape of the output. (optional)
`ctx`: Context of output, in format [cpu|gpu|cpu_pinned](n). Only used for imperative calls. (optional)
`dtype`: DType of the output in case this can't be inferred. Defaults to float32 if not defined (dtype=None). (optional)
`out`: Output array. (optional)</pre></div></div><div class="public anchor" id="var-generalized-negative-binomial-like"><h3>generalized-negative-binomial-like</h3><div class="usage"><code>(generalized-negative-binomial-like mu alpha)</code><code>(generalized-negative-binomial-like {:keys [mu shape dtype alpha out], :or {shape nil, dtype nil, out nil}, :as opts})</code></div><div class="doc"><pre class="plaintext">Concurrent sampling from multiple
generalized negative binomial distributions with parameters *mu* (mean) and *alpha* (dispersion).

The parameters of the distributions are provided as input arrays.
Let *[s]* be the shape of the input arrays, *n* be the dimension of *[s]*, *[t]*
be the shape specified as the parameter of the operator, and *m* be the dimension
of *[t]*. Then the output will be a *(n+m)*-dimensional array with shape *[s]x[t]*.

For any valid *n*-dimensional index *i* with respect to the input arrays, *output[i]*
will be an *m*-dimensional array that holds randomly drawn samples from the distribution
which is parameterized by the input values at index *i*. If the shape parameter of the
operator is not set, then one sample will be drawn per distribution and the output array
has the same shape as the input arrays.

Samples will always be returned as a floating point data type.

Examples::

   mu = [ 2.0, 2.5 ]
   alpha = [ 1.0, 0.1 ]

   // Draw a single sample for each distribution
   sample_generalized_negative_binomial(mu, alpha) = [ 0.,  3.]

   // Draw a vector containing two samples for each distribution
   sample_generalized_negative_binomial(mu, alpha, shape=(2)) = [[ 0.,  3.],
                                                                 [ 3.,  1.]]


Defined in src/operator/random/multisample_op.cc:L293

`mu`: Means of the distributions.
`shape`: Shape to be sampled from each random distribution. (optional)
`dtype`: DType of the output in case this can't be inferred. Defaults to float32 if not defined (dtype=None). (optional)
`alpha`: Alpha (dispersion) parameters of the distributions.
`out`: Output array. (optional)</pre></div></div><div class="public anchor" id="var-multinomial-like"><h3>multinomial-like</h3><div class="usage"><code>(multinomial-like {:keys [data shape get-prob dtype out], :or {shape nil, get-prob nil, dtype nil, out nil}, :as opts})</code></div><div class="doc"><pre class="plaintext">Concurrent sampling from multiple multinomial distributions.

*data* is an *n* dimensional array whose last dimension has length *k*, where
*k* is the number of possible outcomes of each multinomial distribution. This
operator will draw *shape* samples from each distribution. If shape is empty
one sample will be drawn from each distribution.

If *get_prob* is true, a second array containing log likelihood of the drawn
samples will also be returned. This is usually used for reinforcement learning
where you can provide reward as head gradient for this array to estimate
gradient.

Note that the input distribution must be normalized, i.e. *data* must sum to
1 along its last axis.

Examples::

   probs = [[0, 0.1, 0.2, 0.3, 0.4], [0.4, 0.3, 0.2, 0.1, 0]]

   // Draw a single sample for each distribution
   sample_multinomial(probs) = [3, 0]

   // Draw a vector containing two samples for each distribution
   sample_multinomial(probs, shape=(2)) = [[4, 2],
                                           [0, 0]]

   // requests log likelihood
   sample_multinomial(probs, get_prob=True) = [2, 1], [0.2, 0.3]


`data`: Distribution probabilities. Must sum to one on the last axis.
`shape`: Shape to be sampled from each random distribution. (optional)
`get-prob`: Whether to also return the log probability of sampled result. This is usually used for differentiating through stochastic variables, e.g. in reinforcement learning. (optional)
`dtype`: DType of the output in case this can't be inferred. (optional)
`out`: Output array. (optional)</pre></div></div><div class="public anchor" id="var-negative-binomial"><h3>negative-binomial</h3><div class="usage"><code>(negative-binomial)</code><code>(negative-binomial {:keys [k p shape ctx dtype out], :or {k nil, p nil, shape nil, ctx nil, dtype nil, out nil}, :as opts})</code></div><div class="doc"><pre class="plaintext">Draw random samples from a negative binomial distribution.

Samples are distributed according to a negative binomial distribution parametrized by
*k* (limit of unsuccessful experiments) and *p* (failure probability in each experiment).
Samples will always be returned as a floating point data type.

Example::

   negative_binomial(k=3, p=0.4, shape=(2,2)) = [[ 4.,  7.],
                                                 [ 2.,  5.]]


Defined in src/operator/random/sample_op.cc:L164

`k`: Limit of unsuccessful experiments. (optional)
`p`: Failure probability in each experiment. (optional)
`shape`: Shape of the output. (optional)
`ctx`: Context of output, in format [cpu|gpu|cpu_pinned](n). Only used for imperative calls. (optional)
`dtype`: DType of the output in case this can't be inferred. Defaults to float32 if not defined (dtype=None). (optional)
`out`: Output array. (optional)</pre></div></div><div class="public anchor" id="var-negative-binomial-like"><h3>negative-binomial-like</h3><div class="usage"><code>(negative-binomial-like k p)</code><code>(negative-binomial-like {:keys [k shape dtype p out], :or {shape nil, dtype nil, out nil}, :as opts})</code></div><div class="doc"><pre class="plaintext">Concurrent sampling from multiple
negative binomial distributions with parameters *k* (failure limit) and *p* (failure probability).

The parameters of the distributions are provided as input arrays.
Let *[s]* be the shape of the input arrays, *n* be the dimension of *[s]*, *[t]*
be the shape specified as the parameter of the operator, and *m* be the dimension
of *[t]*. Then the output will be a *(n+m)*-dimensional array with shape *[s]x[t]*.

For any valid *n*-dimensional index *i* with respect to the input arrays, *output[i]*
will be an *m*-dimensional array that holds randomly drawn samples from the distribution
which is parameterized by the input values at index *i*. If the shape parameter of the
operator is not set, then one sample will be drawn per distribution and the output array
has the same shape as the input arrays.

Samples will always be returned as a floating point data type.

Examples::

   k = [ 20, 49 ]
   p = [ 0.4 , 0.77 ]

   // Draw a single sample for each distribution
   sample_negative_binomial(k, p) = [ 15.,  16.]

   // Draw a vector containing two samples for each distribution
   sample_negative_binomial(k, p, shape=(2)) = [[ 15.,  50.],
                                                [ 16.,  12.]]


Defined in src/operator/random/multisample_op.cc:L289

`k`: Limits of unsuccessful experiments.
`shape`: Shape to be sampled from each random distribution. (optional)
`dtype`: DType of the output in case this can't be inferred. Defaults to float32 if not defined (dtype=None). (optional)
`p`: Failure probabilities in each experiment.
`out`: Output array. (optional)</pre></div></div><div class="public anchor" id="var-normal"><h3>normal</h3><div class="usage"><code>(normal)</code><code>(normal {:keys [loc scale shape ctx dtype out], :or {loc nil, scale nil, shape nil, ctx nil, dtype nil, out nil}, :as opts})</code></div><div class="doc"><pre class="plaintext">Draw random samples from a normal (Gaussian) distribution.

.. note:: The existing alias ``normal`` is deprecated.

Samples are distributed according to a normal distribution parametrized by *loc* (mean) and *scale*
(standard deviation).

Example::

   normal(loc=0, scale=1, shape=(2,2)) = [[ 1.89171135, -1.16881478],
                                          [-1.23474145,  1.55807114]]


Defined in src/operator/random/sample_op.cc:L113

`loc`: Mean of the distribution. (optional)
`scale`: Standard deviation of the distribution. (optional)
`shape`: Shape of the output. (optional)
`ctx`: Context of output, in format [cpu|gpu|cpu_pinned](n). Only used for imperative calls. (optional)
`dtype`: DType of the output in case this can't be inferred. Defaults to float32 if not defined (dtype=None). (optional)
`out`: Output array. (optional)</pre></div></div><div class="public anchor" id="var-normal-like"><h3>normal-like</h3><div class="usage"><code>(normal-like mu sigma)</code><code>(normal-like {:keys [mu shape dtype sigma out], :or {shape nil, dtype nil, out nil}, :as opts})</code></div><div class="doc"><pre class="plaintext">Concurrent sampling from multiple
normal distributions with parameters *mu* (mean) and *sigma* (standard deviation).

The parameters of the distributions are provided as input arrays.
Let *[s]* be the shape of the input arrays, *n* be the dimension of *[s]*, *[t]*
be the shape specified as the parameter of the operator, and *m* be the dimension
of *[t]*. Then the output will be a *(n+m)*-dimensional array with shape *[s]x[t]*.

For any valid *n*-dimensional index *i* with respect to the input arrays, *output[i]*
will be an *m*-dimensional array that holds randomly drawn samples from the distribution
which is parameterized by the input values at index *i*. If the shape parameter of the
operator is not set, then one sample will be drawn per distribution and the output array
has the same shape as the input arrays.

Examples::

   mu = [ 0.0, 2.5 ]
   sigma = [ 1.0, 3.7 ]

   // Draw a single sample for each distribution
   sample_normal(mu, sigma) = [-0.56410581,  0.95934606]

   // Draw a vector containing two samples for each distribution
   sample_normal(mu, sigma, shape=(2)) = [[-0.56410581,  0.2928229 ],
                                          [ 0.95934606,  4.48287058]]


Defined in src/operator/random/multisample_op.cc:L279

`mu`: Means of the distributions.
`shape`: Shape to be sampled from each random distribution. (optional)
`dtype`: DType of the output in case this can't be inferred. Defaults to float32 if not defined (dtype=None). (optional)
`sigma`: Standard deviations of the distributions.
`out`: Output array. (optional)</pre></div></div><div class="public anchor" id="var-poisson"><h3>poisson</h3><div class="usage"><code>(poisson)</code><code>(poisson {:keys [lam shape ctx dtype out], :or {lam nil, shape nil, ctx nil, dtype nil, out nil}, :as opts})</code></div><div class="doc"><pre class="plaintext">Draw random samples from a Poisson distribution.

Samples are distributed according to a Poisson distribution parametrized by *lambda* (rate).
Samples will always be returned as a floating point data type.

Example::

   poisson(lam=4, shape=(2,2)) = [[ 5.,  2.],
                                  [ 4.,  6.]]


Defined in src/operator/random/sample_op.cc:L150

`lam`: Lambda parameter (rate) of the Poisson distribution. (optional)
`shape`: Shape of the output. (optional)
`ctx`: Context of output, in format [cpu|gpu|cpu_pinned](n). Only used for imperative calls. (optional)
`dtype`: DType of the output in case this can't be inferred. Defaults to float32 if not defined (dtype=None). (optional)
`out`: Output array. (optional)</pre></div></div><div class="public anchor" id="var-poisson-like"><h3>poisson-like</h3><div class="usage"><code>(poisson-like {:keys [lam shape dtype out], :or {shape nil, dtype nil, out nil}, :as opts})</code></div><div class="doc"><pre class="plaintext">Concurrent sampling from multiple
Poisson distributions with parameters lambda (rate).

The parameters of the distributions are provided as an input array.
Let *[s]* be the shape of the input array, *n* be the dimension of *[s]*, *[t]*
be the shape specified as the parameter of the operator, and *m* be the dimension
of *[t]*. Then the output will be a *(n+m)*-dimensional array with shape *[s]x[t]*.

For any valid *n*-dimensional index *i* with respect to the input array, *output[i]*
will be an *m*-dimensional array that holds randomly drawn samples from the distribution
which is parameterized by the input value at index *i*. If the shape parameter of the
operator is not set, then one sample will be drawn per distribution and the output array
has the same shape as the input array.

Samples will always be returned as a floating point data type.

Examples::

   lam = [ 1.0, 8.5 ]

   // Draw a single sample for each distribution
   sample_poisson(lam) = [  0.,  13.]

   // Draw a vector containing two samples for each distribution
   sample_poisson(lam, shape=(2)) = [[  0.,   4.],
                                     [ 13.,   8.]]


Defined in src/operator/random/multisample_op.cc:L286

`lam`: Lambda (rate) parameters of the distributions.
`shape`: Shape to be sampled from each random distribution. (optional)
`dtype`: DType of the output in case this can't be inferred. Defaults to float32 if not defined (dtype=None). (optional)
`out`: Output array. (optional)</pre></div></div><div class="public anchor" id="var-randint"><h3>randint</h3><div class="usage"><code>(randint low high)</code><code>(randint {:keys [low high shape ctx dtype out], :or {shape nil, ctx nil, dtype nil, out nil}, :as opts})</code></div><div class="doc"><pre class="plaintext">Draw random samples from a discrete uniform distribution.

Samples are uniformly distributed over the half-open interval *[low, high)*
(includes *low*, but excludes *high*).

Example::

   randint(low=0, high=5, shape=(2,2)) = [[ 0,  2],
                                          [ 3,  1]]



Defined in src/operator/random/sample_op.cc:L193

`low`: Lower bound of the distribution.
`high`: Upper bound of the distribution.
`shape`: Shape of the output. (optional)
`ctx`: Context of output, in format [cpu|gpu|cpu_pinned](n). Only used for imperative calls. (optional)
`dtype`: DType of the output in case this can't be inferred. Defaults to int32 if not defined (dtype=None). (optional)
`out`: Output array. (optional)</pre></div></div><div class="public anchor" id="var-uniform"><h3>uniform</h3><div class="usage"><code>(uniform)</code><code>(uniform {:keys [low high shape ctx dtype out], :or {low nil, high nil, shape nil, ctx nil, dtype nil, out nil}, :as opts})</code></div><div class="doc"><pre class="plaintext">Draw random samples from a uniform distribution.

.. note:: The existing alias ``uniform`` is deprecated.

Samples are uniformly distributed over the half-open interval *[low, high)*
(includes *low*, but excludes *high*).

Example::

   uniform(low=0, high=1, shape=(2,2)) = [[ 0.60276335,  0.85794562],
                                          [ 0.54488319,  0.84725171]]



Defined in src/operator/random/sample_op.cc:L96

`low`: Lower bound of the distribution. (optional)
`high`: Upper bound of the distribution. (optional)
`shape`: Shape of the output. (optional)
`ctx`: Context of output, in format [cpu|gpu|cpu_pinned](n). Only used for imperative calls. (optional)
`dtype`: DType of the output in case this can't be inferred. Defaults to float32 if not defined (dtype=None). (optional)
`out`: Output array. (optional)</pre></div></div><div class="public anchor" id="var-uniform-like"><h3>uniform-like</h3><div class="usage"><code>(uniform-like low high)</code><code>(uniform-like {:keys [low shape dtype high out], :or {shape nil, dtype nil, out nil}, :as opts})</code></div><div class="doc"><pre class="plaintext">Concurrent sampling from multiple
uniform distributions on the intervals given by *[low,high)*.

The parameters of the distributions are provided as input arrays.
Let *[s]* be the shape of the input arrays, *n* be the dimension of *[s]*, *[t]*
be the shape specified as the parameter of the operator, and *m* be the dimension
of *[t]*. Then the output will be a *(n+m)*-dimensional array with shape *[s]x[t]*.

For any valid *n*-dimensional index *i* with respect to the input arrays, *output[i]*
will be an *m*-dimensional array that holds randomly drawn samples from the distribution
which is parameterized by the input values at index *i*. If the shape parameter of the
operator is not set, then one sample will be drawn per distribution and the output array
has the same shape as the input arrays.

Examples::

   low = [ 0.0, 2.5 ]
   high = [ 1.0, 3.7 ]

   // Draw a single sample for each distribution
   sample_uniform(low, high) = [ 0.40451524,  3.18687344]

   // Draw a vector containing two samples for each distribution
   sample_uniform(low, high, shape=(2)) = [[ 0.40451524,  0.18017688],
                                           [ 3.18687344,  3.68352246]]


Defined in src/operator/random/multisample_op.cc:L277

`low`: Lower bounds of the distributions.
`shape`: Shape to be sampled from each random distribution. (optional)
`dtype`: DType of the output in case this can't be inferred. Defaults to float32 if not defined (dtype=None). (optional)
`high`: Upper bounds of the distributions.
`out`: Output array. (optional)</pre></div></div></div></body></html>