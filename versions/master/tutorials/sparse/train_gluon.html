<!DOCTYPE html>

<html lang="en">
<head>
<meta charset="utf-8"/>
<meta content="IE=edge" http-equiv="X-UA-Compatible"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="Sparse NDArrays with Gluon" property="og:title">
<meta content="https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/image/og-logo.png" property="og:image">
<meta content="https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/image/og-logo.png" property="og:image:secure_url">
<meta content="Sparse NDArrays with Gluon" property="og:description"/>
<title>Sparse NDArrays with Gluon — mxnet  documentation</title>
<link crossorigin="anonymous" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css" integrity="sha384-1q8mTJOASx8j1Au+a5WDVnPi2lkFfwwEAa8hDDdjZlpLegxhjVME1fgjWPGmkzs7" rel="stylesheet"/>
<link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css" rel="stylesheet"/>
<link href="../../_static/basic.css" rel="stylesheet" type="text/css">
<link href="../../_static/pygments.css" rel="stylesheet" type="text/css">
<link href="../../_static/mxnet.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../../',
        VERSION:     '',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true,
        SOURCELINK_SUFFIX: '.txt'
      };
    </script>
<script src="https://code.jquery.com/jquery-1.11.1.min.js" type="text/javascript"></script>
<script src="../../_static/underscore.js" type="text/javascript"></script>
<script src="../../_static/searchtools_custom.js" type="text/javascript"></script>
<script src="../../_static/doctools.js" type="text/javascript"></script>
<script src="../../_static/selectlang.js" type="text/javascript"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
<script type="text/javascript"> jQuery(function() { Search.loadIndex("/searchindex.js"); Search.init();}); </script>
<script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new
      Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-96378503-1', 'auto');
      ga('send', 'pageview');

    </script>
<!-- -->
<!-- <script type="text/javascript" src="../../_static/jquery.js"></script> -->
<!-- -->
<!-- <script type="text/javascript" src="../../_static/underscore.js"></script> -->
<!-- -->
<!-- <script type="text/javascript" src="../../_static/doctools.js"></script> -->
<!-- -->
<!-- <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script> -->
<!-- -->
<link href="../../genindex.html" rel="index" title="Index">
<link href="../../search.html" rel="search" title="Search"/>
<link href="index.html" rel="up" title="Tutorials"/>
<link href="../speech_recognition/index.html" rel="next" title="Tutorials"/>
<link href="train.html" rel="prev" title="Train a Linear Regression Model with Sparse Symbols"/>
<link href="https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/image/mxnet-icon.png" rel="icon" type="image/png"/>
</link></link></link></meta></meta></meta></head>
<body background="https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/image/mxnet-background-compressed.jpeg" role="document">
<div class="content-block"><div class="navbar navbar-fixed-top">
<div class="container" id="navContainer">
<div class="innder" id="header-inner">
<h1 id="logo-wrap">
<a href="../../" id="logo"><img src="https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/image/mxnet_logo.png"/></a>
</h1>
<nav class="nav-bar" id="main-nav">
<a class="main-nav-link" href="../../install/index.html">Install</a>
<span id="dropdown-menu-position-anchor">
<a aria-expanded="true" aria-haspopup="true" class="main-nav-link dropdown-toggle" data-toggle="dropdown" href="#" role="button">Gluon <span class="caret"></span></a>
<ul class="dropdown-menu navbar-menu" id="package-dropdown-menu">
<li><a class="main-nav-link" href="../../gluon/index.html">About</a></li>
<li><a class="main-nav-link" href="https://www.d2l.ai/">Dive into Deep Learning</a></li>
<li><a class="main-nav-link" href="https://gluon-cv.mxnet.io">GluonCV Toolkit</a></li>
<li><a class="main-nav-link" href="https://gluon-nlp.mxnet.io/">GluonNLP Toolkit</a></li>
</ul>
</span>
<span id="dropdown-menu-position-anchor">
<a aria-expanded="true" aria-haspopup="true" class="main-nav-link dropdown-toggle" data-toggle="dropdown" href="#" role="button">API <span class="caret"></span></a>
<ul class="dropdown-menu navbar-menu" id="package-dropdown-menu">
<li><a class="main-nav-link" href="../../api/python/index.html">Python</a></li>
<li><a class="main-nav-link" href="../../api/c++/index.html">C++</a></li>
<li><a class="main-nav-link" href="../../api/clojure/index.html">Clojure</a></li>
<li><a class="main-nav-link" href="../../api/java/index.html">Java</a></li>
<li><a class="main-nav-link" href="../../api/julia/index.html">Julia</a></li>
<li><a class="main-nav-link" href="../../api/perl/index.html">Perl</a></li>
<li><a class="main-nav-link" href="../../api/r/index.html">R</a></li>
<li><a class="main-nav-link" href="../../api/scala/index.html">Scala</a></li>
</ul>
</span>
<span id="dropdown-menu-position-anchor-docs">
<a aria-expanded="true" aria-haspopup="true" class="main-nav-link dropdown-toggle" data-toggle="dropdown" href="#" role="button">Docs <span class="caret"></span></a>
<ul class="dropdown-menu navbar-menu" id="package-dropdown-menu-docs">
<li><a class="main-nav-link" href="../../faq/index.html">FAQ</a></li>
<li><a class="main-nav-link" href="../../tutorials/index.html">Tutorials</a>
<li><a class="main-nav-link" href="https://github.com/apache/incubator-mxnet/tree/master/example">Examples</a></li>
<li><a class="main-nav-link" href="../../architecture/index.html">Architecture</a></li>
<li><a class="main-nav-link" href="https://cwiki.apache.org/confluence/display/MXNET/Apache+MXNet+Home">Developer Wiki</a></li>
<li><a class="main-nav-link" href="../../api/python/gluon/model_zoo.html">Model Zoo</a></li>
<li><a class="main-nav-link" href="../../api/python/contrib/onnx.html">ONNX</a></li>
</li></ul>
</span>
<span id="dropdown-menu-position-anchor-community">
<a aria-expanded="true" aria-haspopup="true" class="main-nav-link dropdown-toggle" data-toggle="dropdown" href="#" role="button">Community <span class="caret"></span></a>
<ul class="dropdown-menu navbar-menu" id="package-dropdown-menu-community">
<li><a class="main-nav-link" href="http://discuss.mxnet.io">Forum</a></li>
<li><a class="main-nav-link" href="https://github.com/apache/incubator-mxnet">Github</a></li>
<li><a class="main-nav-link" href="../../community/contribute.html">Contribute</a></li>
<li><a class="main-nav-link" href="../../community/ecosystem.html">Ecosystem</a></li>
<li><a class="main-nav-link" href="../../community/powered_by.html">Powered By</a></li>
</ul>
</span>
<span id="dropdown-menu-position-anchor-version" style="position: relative"><a href="#" class="main-nav-link dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="true">Versions(master)<span class="caret"></span></a><ul id="package-dropdown-menu" class="dropdown-menu"><li><a class="main-nav-link" href=http://mxnet.incubator.apache.org/versions/1.5.0/index.html>1.5.0</a></li><li><a class="main-nav-link" href=http://mxnet.incubator.apache.org/versions/1.4.1/index.html>1.4.1</a></li><li><a class="main-nav-link" href=http://mxnet.incubator.apache.org/versions/1.3.1/index.html>1.3.1</a></li><li><a class="main-nav-link" href=http://mxnet.incubator.apache.org/versions/1.2.1/index.html>1.2.1</a></li><li><a class="main-nav-link" href=http://mxnet.incubator.apache.org/versions/1.1.0/index.html>1.1.0</a></li><li><a class="main-nav-link" href=http://mxnet.incubator.apache.org/versions/1.0.0/index.html>1.0.0</a></li><li><a class="main-nav-link" href=http://mxnet.incubator.apache.org/versions/0.12.1/index.html>0.12.1</a></li><li><a class="main-nav-link" href=http://mxnet.incubator.apache.org/versions/0.11.0/index.html>0.11.0</a></li><li><a class="main-nav-link" href=http://mxnet.incubator.apache.org/versions/master/index.html>master</a></li></ul></span></nav>
<script> function getRootPath(){ return "../../" } </script>
<div class="burgerIcon dropdown">
<a class="dropdown-toggle" data-toggle="dropdown" href="#" role="button">☰</a>
<ul class="dropdown-menu" id="burgerMenu">
<li><a href="../../install/index.html">Install</a></li>
<li><a class="main-nav-link" href="../../tutorials/index.html">Tutorials</a></li>
<li class="dropdown-submenu dropdown">
<a aria-expanded="true" aria-haspopup="true" class="dropdown-toggle burger-link" data-toggle="dropdown" href="#" tabindex="-1">Gluon</a>
<ul class="dropdown-menu navbar-menu" id="package-dropdown-menu">
<li><a class="main-nav-link" href="../../gluon/index.html">About</a></li>
<li><a class="main-nav-link" href="http://gluon.mxnet.io">The Straight Dope (Tutorials)</a></li>
<li><a class="main-nav-link" href="https://gluon-cv.mxnet.io">GluonCV Toolkit</a></li>
<li><a class="main-nav-link" href="https://gluon-nlp.mxnet.io/">GluonNLP Toolkit</a></li>
</ul>
</li>
<li class="dropdown-submenu">
<a aria-expanded="true" aria-haspopup="true" class="dropdown-toggle burger-link" data-toggle="dropdown" href="#" tabindex="-1">API</a>
<ul class="dropdown-menu">
<li><a class="main-nav-link" href="../../api/python/index.html">Python</a></li>
<li><a class="main-nav-link" href="../../api/c++/index.html">C++</a></li>
<li><a class="main-nav-link" href="../../api/clojure/index.html">Clojure</a></li>
<li><a class="main-nav-link" href="../../api/java/index.html">Java</a></li>
<li><a class="main-nav-link" href="../../api/julia/index.html">Julia</a></li>
<li><a class="main-nav-link" href="../../api/perl/index.html">Perl</a></li>
<li><a class="main-nav-link" href="../../api/r/index.html">R</a></li>
<li><a class="main-nav-link" href="../../api/scala/index.html">Scala</a></li>
</ul>
</li>
<li class="dropdown-submenu">
<a aria-expanded="true" aria-haspopup="true" class="dropdown-toggle burger-link" data-toggle="dropdown" href="#" tabindex="-1">Docs</a>
<ul class="dropdown-menu">
<li><a href="../../faq/index.html" tabindex="-1">FAQ</a></li>
<li><a href="../../tutorials/index.html" tabindex="-1">Tutorials</a></li>
<li><a href="https://github.com/apache/incubator-mxnet/tree/master/example" tabindex="-1">Examples</a></li>
<li><a href="../../architecture/index.html" tabindex="-1">Architecture</a></li>
<li><a href="https://cwiki.apache.org/confluence/display/MXNET/Apache+MXNet+Home" tabindex="-1">Developer Wiki</a></li>
<li><a href="../../api/python/gluon/model_zoo.html" tabindex="-1">Gluon Model Zoo</a></li>
<li><a href="../../api/python/contrib/onnx.html" tabindex="-1">ONNX</a></li>
</ul>
</li>
<li class="dropdown-submenu dropdown">
<a aria-haspopup="true" class="dropdown-toggle burger-link" data-toggle="dropdown" href="#" role="button" tabindex="-1">Community</a>
<ul class="dropdown-menu">
<li><a href="http://discuss.mxnet.io" tabindex="-1">Forum</a></li>
<li><a href="https://github.com/apache/incubator-mxnet" tabindex="-1">Github</a></li>
<li><a href="../../community/contribute.html" tabindex="-1">Contribute</a></li>
<li><a href="../../community/ecosystem.html" tabindex="-1">Ecosystem</a></li>
<li><a href="../../community/powered_by.html" tabindex="-1">Powered By</a></li>
</ul>
</li>
<li id="dropdown-menu-position-anchor-version-mobile" class="dropdown-submenu" style="position: relative"><a href="#" tabindex="-1">Versions(master)</a><ul class="dropdown-menu"><li><a tabindex="-1" href=http://mxnet.incubator.apache.org/versions/1.5.0/index.html>1.5.0</a></li><li><a tabindex="-1" href=http://mxnet.incubator.apache.org/versions/1.4.1/index.html>1.4.1</a></li><li><a tabindex="-1" href=http://mxnet.incubator.apache.org/versions/1.3.1/index.html>1.3.1</a></li><li><a tabindex="-1" href=http://mxnet.incubator.apache.org/versions/1.2.1/index.html>1.2.1</a></li><li><a tabindex="-1" href=http://mxnet.incubator.apache.org/versions/1.1.0/index.html>1.1.0</a></li><li><a tabindex="-1" href=http://mxnet.incubator.apache.org/versions/1.0.0/index.html>1.0.0</a></li><li><a tabindex="-1" href=http://mxnet.incubator.apache.org/versions/0.12.1/index.html>0.12.1</a></li><li><a tabindex="-1" href=http://mxnet.incubator.apache.org/versions/0.11.0/index.html>0.11.0</a></li><li><a tabindex="-1" href=http://mxnet.incubator.apache.org/versions/master/index.html>master</a></li></ul></li></ul>
</div>
<div class="plusIcon dropdown">
<a class="dropdown-toggle" data-toggle="dropdown" href="#" role="button"><span aria-hidden="true" class="glyphicon glyphicon-plus"></span></a>
<ul class="dropdown-menu dropdown-menu-right" id="plusMenu"></ul>
</div>
<div id="search-input-wrap">
<form action="../../search.html" autocomplete="off" class="" method="get" role="search">
<div class="form-group inner-addon left-addon">
<i class="glyphicon glyphicon-search"></i>
<input class="form-control" name="q" placeholder="Search" type="text"/>
</div>
<input name="check_keywords" type="hidden" value="yes">
<input name="area" type="hidden" value="default"/>
</input></form>
<div id="search-preview"></div>
</div>
<div id="searchIcon">
<span aria-hidden="true" class="glyphicon glyphicon-search"></span>
</div>
<!-- <div id="lang-select-wrap"> -->
<!--   <label id="lang-select-label"> -->
<!--     <\!-- <i class="fa fa-globe"></i> -\-> -->
<!--     <span></span> -->
<!--   </label> -->
<!--   <select id="lang-select"> -->
<!--     <option value="en">Eng</option> -->
<!--     <option value="zh">中文</option> -->
<!--   </select> -->
<!-- </div> -->
<!--     <a id="mobile-nav-toggle">
        <span class="mobile-nav-toggle-bar"></span>
        <span class="mobile-nav-toggle-bar"></span>
        <span class="mobile-nav-toggle-bar"></span>
      </a> -->
</div>
</div>
</div>
<script type="text/javascript">
        $('body').css('background', 'white');
    </script>
<div class="container">
<div class="row">
<div aria-label="main navigation" class="sphinxsidebar leftsidebar" role="navigation">
<div class="sphinxsidebarwrapper">
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../api/index.html">MXNet APIs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../architecture/index.html">MXNet Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../community/index.html">MXNet Community</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/index.html">MXNet FAQ</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../gluon/index.html">About Gluon</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../install/index.html">Installing MXNet</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../install/index.html#nvidia-jetson-devices">NVIDIA Jetson Devices</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../install/index.html#source-download">Source Download</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model_zoo/index.html">MXNet Model Zoo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../index.html">Tutorials</a></li>
</ul>
</div>
</div>
<div class="content">
<div class="page-tracker"></div>
<!--- Licensed to the Apache Software Foundation (ASF) under one -->
<!--- or more contributor license agreements.  See the NOTICE file -->
<!--- distributed with this work for additional information -->
<!--- regarding copyright ownership.  The ASF licenses this file -->
<!--- to you under the Apache License, Version 2.0 (the -->
<!--- "License"); you may not use this file except in compliance -->
<!--- with the License.  You may obtain a copy of the License at --><!---   http://www.apache.org/licenses/LICENSE-2.0 --><!--- Unless required by applicable law or agreed to in writing, -->
<!--- software distributed under the License is distributed on an -->
<!--- "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY -->
<!--- KIND, either express or implied.  See the License for the -->
<!--- specific language governing permissions and limitations -->
<!--- under the License. --><div class="section" id="sparse-ndarrays-with-gluon">
<span id="sparse-ndarrays-with-gluon"></span><h1>Sparse NDArrays with Gluon<a class="headerlink" href="#sparse-ndarrays-with-gluon" title="Permalink to this headline">¶</a></h1>
<p>When working on machine learning problems, you may encounter situations where the input data is sparse (i.e. the majority of values are zero). One example of this is in recommendation systems. You could have millions of user and product features, but only a few of these features are present for each sample. Without special treatment, the sheer magnitude of the feature space can lead to out-of-memory situations and cause significant slowdowns when training and making predictions.</p>
<p>MXNet supports a number of sparse storage types (often called ‘stype’ for short) for these situations. In this tutorial, we’ll start by generating some sparse data, write it to disk in the LibSVM format and then read back using the <a class="reference external" href="https://mxnet.incubator.apache.org/api/python/io/io.html"><code class="docutils literal"><span class="pre">LibSVMIter</span></code></a> for training. We use the Gluon API to train the model and leverage sparse storage types such as <a class="reference external" href="https://mxnet.incubator.apache.org/api/python/ndarray/sparse.html?highlight=csrndarray#mxnet.ndarray.sparse.CSRNDArray"><code class="docutils literal"><span class="pre">CSRNDArray</span></code></a> and <a class="reference external" href="https://mxnet.incubator.apache.org/api/python/ndarray/sparse.html?highlight=rowsparsendarray#mxnet.ndarray.sparse.RowSparseNDArray"><code class="docutils literal"><span class="pre">RowSparseNDArray</span></code></a> to maximise performance and memory efficiency.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mxnet</span> <span class="kn">as</span> <span class="nn">mx</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">time</span>
</pre></div>
</div>
<div class="section" id="generating-sparse-data">
<span id="generating-sparse-data"></span><h2>Generating Sparse Data<a class="headerlink" href="#generating-sparse-data" title="Permalink to this headline">¶</a></h2>
<p>You will most likely have a sparse dataset in mind already if you’re reading this tutorial, but let’s create a dummy dataset to use in the examples that follow. Using <code class="docutils literal"><span class="pre">rand_ndarray</span></code> we will generate 1000 samples, each with 1,000,000 features of which 99.999% of values will be zero (i.e. 10 non-zero features for each sample). We take this as our input data for training and calculate a label based on an arbitrary rule: whether the feature sum is higher than average.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">num_samples</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">num_features</span> <span class="o">=</span> <span class="mi">1000000</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">mx</span><span class="o">.</span><span class="n">test_utils</span><span class="o">.</span><span class="n">rand_ndarray</span><span class="p">((</span><span class="n">num_samples</span><span class="p">,</span> <span class="n">num_features</span><span class="p">),</span> <span class="n">stype</span><span class="o">=</span><span class="s1">'csr'</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="mf">0.00001</span><span class="p">)</span>
<span class="c1"># generate label: 1 if row sum above average, 0 otherwise.</span>
<span class="n">label</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">></span> <span class="n">data</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">data</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="n">data</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">())</span>
<span class="k">print</span><span class="p">(</span><span class="s1">'{:,.0f} elements'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">product</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">)))</span>
<span class="k">print</span><span class="p">(</span><span class="s1">'{:,.0f} non-zero elements'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">size</span><span class="p">))</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><class 'mxnet.ndarray.sparse.CSRNDArray'>
[[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
1,000,000,000 elements
10,000 non-zero elements
</pre></div>
</div>
<p>Our storage type is CSR (Compressed Sparse Row) which is the ideal type for sparse data along multiple axes. See <a class="reference external" href="https://mxnet.incubator.apache.org/versions/master/tutorials/sparse/csr.html">this in-depth tutorial</a> for more information. Just to confirm the generation process ran correctly, we can see that the vast majority of values are indeed zero. One of the first questions to ask would be how much memory is saved by storing this data in a <a class="reference external" href="https://mxnet.incubator.apache.org/api/python/ndarray/sparse.html?highlight=csrndarray#mxnet.ndarray.sparse.CSRNDArray"><code class="docutils literal"><span class="pre">CSRNDArray</span></code></a> versus a standard <a class="reference external" href="https://mxnet.incubator.apache.org/versions/master/api/python/ndarray/sparse.html?highlight=ndarray#module-mxnet.ndarray"><code class="docutils literal"><span class="pre">NDArray</span></code></a>. Since sparse arrays are constructed from many components (e.g. <code class="docutils literal"><span class="pre">data</span></code>, <code class="docutils literal"><span class="pre">indices</span></code> and <code class="docutils literal"><span class="pre">indptr</span></code>) we define a function called <code class="docutils literal"><span class="pre">get_nbytes</span></code> to calculate the number of bytes taken in memory to store an array. We compare the same data stored in a standard <a class="reference external" href="https://mxnet.incubator.apache.org/versions/master/api/python/ndarray/sparse.html?highlight=ndarray#module-mxnet.ndarray"><code class="docutils literal"><span class="pre">NDArray</span></code></a> (with <code class="docutils literal"><span class="pre">data.tostype('default')</span></code>) to the <a class="reference external" href="https://mxnet.incubator.apache.org/api/python/ndarray/sparse.html?highlight=csrndarray#mxnet.ndarray.sparse.CSRNDArray"><code class="docutils literal"><span class="pre">CSRNDArray</span></code></a>.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_nbytes</span><span class="p">(</span><span class="n">array</span><span class="p">):</span>
    <span class="n">fn</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">a</span><span class="p">:</span> <span class="n">a</span><span class="o">.</span><span class="n">size</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="n">a</span><span class="p">)</span><span class="o">.</span><span class="n">itemsize</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">array</span><span class="p">,</span> <span class="n">mx</span><span class="o">.</span><span class="n">ndarray</span><span class="o">.</span><span class="n">sparse</span><span class="o">.</span><span class="n">CSRNDArray</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">fn</span><span class="p">(</span><span class="n">array</span><span class="o">.</span><span class="n">data</span><span class="p">)</span> <span class="o">+</span> <span class="n">fn</span><span class="p">(</span><span class="n">array</span><span class="o">.</span><span class="n">indices</span><span class="p">)</span> <span class="o">+</span> <span class="n">fn</span><span class="p">(</span><span class="n">array</span><span class="o">.</span><span class="n">indptr</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">array</span><span class="p">,</span> <span class="n">mx</span><span class="o">.</span><span class="n">ndarray</span><span class="o">.</span><span class="n">sparse</span><span class="o">.</span><span class="n">RowSparseNDArray</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">fn</span><span class="p">(</span><span class="n">array</span><span class="o">.</span><span class="n">data</span><span class="p">)</span> <span class="o">+</span> <span class="n">fn</span><span class="p">(</span><span class="n">array</span><span class="o">.</span><span class="n">indices</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">array</span><span class="p">,</span> <span class="n">mx</span><span class="o">.</span><span class="n">ndarray</span><span class="o">.</span><span class="n">NDArray</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">fn</span><span class="p">(</span><span class="n">array</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="ne">TypeError</span><span class="p">(</span><span class="s1">'{} not supported'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">array</span><span class="p">)))</span>
</pre></div>
</div>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="s1">'NDarray:'</span><span class="p">,</span> <span class="n">get_nbytes</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">tostype</span><span class="p">(</span><span class="s1">'default'</span><span class="p">))</span><span class="o">/</span><span class="mi">1000000</span><span class="p">,</span> <span class="s1">'MBs'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s1">'CSRNDArray'</span><span class="p">,</span> <span class="n">get_nbytes</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="o">/</span><span class="mi">1000000</span><span class="p">,</span> <span class="s1">'MBs'</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">NDarray</span><span class="p">:</span> <span class="mf">4000.0</span> <span class="n">MBs</span>
<span class="n">CSRNDArray</span> <span class="mf">0.128008</span> <span class="n">MBs</span>
</pre></div>
</div>
<p>Given the extremely high sparsity of the data, we observe a huge memory saving here! 0.13 MBs versus 4 GBs: ~30,000 times smaller. You can experiment with the amount of sparsity and see how these two storage types compare. When the number of non-zero values increases, this difference will reduce. And when the number of non-zero values exceeds ~1/3 you will find that this sparse storage type take more memory than dense! So use wisely.</p>
</div>
<div class="section" id="writing-sparse-data">
<span id="writing-sparse-data"></span><h2>Writing Sparse Data<a class="headerlink" href="#writing-sparse-data" title="Permalink to this headline">¶</a></h2>
<p>Since there is such a large size difference between dense and sparse storage formats here, we ideally want to store the data on disk in a sparse storage format too. MXNet supports a format called LibSVM and has a data iterator called <a class="reference external" href="https://mxnet.incubator.apache.org/api/python/io/io.html?highlight=libsvmiter"><code class="docutils literal"><span class="pre">LibSVMIter</span></code></a> specifically for data formatted this way.</p>
<p>A LibSVM file has a row for each sample, and each row starts with the label: in this case <code class="docutils literal"><span class="pre">0.0</span></code> or <code class="docutils literal"><span class="pre">1.0</span></code> since we have a classification task. After this we have a variable number of <code class="docutils literal"><span class="pre">key:value</span></code> pairs separated by spaces, where the key is column/feature index and the value is the value of that feature. When working with your own sparse data in a custom format you should try to convert your data into this format. We define a <code class="docutils literal"><span class="pre">save_as_libsvm</span></code> function to save the <code class="docutils literal"><span class="pre">data</span></code> (<a class="reference external" href="https://mxnet.incubator.apache.org/versions/master/api/python/ndarray/sparse.html?highlight=csrndarray#mxnet.ndarray.sparse.CSRNDArray"><code class="docutils literal"><span class="pre">CSRNDArray</span></code></a>) and <code class="docutils literal"><span class="pre">label</span></code> (<code class="docutils literal"><span class="pre">NDArray</span></code>) to disk in LibSVM format.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">save_as_libsvm</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">label</span><span class="p">):</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span> <span class="s1">'w'</span><span class="p">)</span> <span class="k">as</span> <span class="n">openfile</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">row_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
            <span class="n">data_sample</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">row_idx</span><span class="p">]</span>
            <span class="n">label_sample</span> <span class="o">=</span> <span class="n">label</span><span class="p">[</span><span class="n">row_idx</span><span class="p">]</span>
            <span class="n">col_idxs</span> <span class="o">=</span> <span class="n">data_sample</span><span class="o">.</span><span class="n">indices</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
            <span class="n">values</span> <span class="o">=</span> <span class="n">data_sample</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
            <span class="n">label_str</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">label_sample</span><span class="o">.</span><span class="n">asscalar</span><span class="p">())</span>
            <span class="n">value_strs</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'{}:{}'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span> <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">col_idxs</span><span class="p">,</span> <span class="n">values</span><span class="p">)]</span>
            <span class="n">value_str</span> <span class="o">=</span> <span class="s2">" "</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">value_strs</span><span class="p">)</span>
            <span class="n">sample_str</span> <span class="o">=</span> <span class="s1">'{} {}</span><span class="se">\n</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">label_str</span><span class="p">,</span> <span class="n">value_str</span><span class="p">)</span>
            <span class="n">openfile</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">sample_str</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">filepath</span> <span class="o">=</span> <span class="s1">'dataset.libsvm'</span>
<span class="n">save_as_libsvm</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
</pre></div>
</div>
<p>We have now written the <code class="docutils literal"><span class="pre">data</span></code> and <code class="docutils literal"><span class="pre">label</span></code> to disk, and can inspect the first 10 lines of the file:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span> <span class="s1">'r'</span><span class="p">)</span> <span class="k">as</span> <span class="n">openfile</span><span class="p">:</span>
    <span class="n">lines</span> <span class="o">=</span> <span class="p">[</span><span class="n">openfile</span><span class="o">.</span><span class="n">readline</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">)]</span>
<span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">lines</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="n">line</span><span class="p">[:</span><span class="mi">80</span><span class="p">]</span> <span class="o">+</span> <span class="s1">'...'</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">line</span><span class="p">)</span> <span class="o">></span> <span class="mi">80</span> <span class="k">else</span> <span class="n">line</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="mf">0.0</span> <span class="mi">35454</span><span class="p">:</span><span class="mf">0.22486156225204468</span> <span class="mi">80954</span><span class="p">:</span><span class="mf">0.39130592346191406</span> <span class="mi">81941</span><span class="p">:</span><span class="mf">0.1988530308008194</span><span class="o">...</span>
<span class="mf">1.0</span> <span class="mi">37029</span><span class="p">:</span><span class="mf">0.5980494618415833</span> <span class="mi">52916</span><span class="p">:</span><span class="mf">0.15797750651836395</span> <span class="mi">71623</span><span class="p">:</span><span class="mf">0.32251599431037903</span><span class="o">...</span>
<span class="mf">1.0</span> <span class="mi">89962</span><span class="p">:</span><span class="mf">0.47770974040031433</span> <span class="mi">216426</span><span class="p">:</span><span class="mf">0.21326342225074768</span> <span class="mi">271027</span><span class="p">:</span><span class="mf">0.18589609861373</span><span class="o">...</span>
<span class="mf">1.0</span> <span class="mi">7071</span><span class="p">:</span><span class="mf">0.9432336688041687</span> <span class="mi">81664</span><span class="p">:</span><span class="mf">0.7788773775100708</span> <span class="mi">117459</span><span class="p">:</span><span class="mf">0.8166475296020508</span> <span class="mf">4.</span><span class="o">..</span>
<span class="mf">0.0</span> <span class="mi">380966</span><span class="p">:</span><span class="mf">0.16906292736530304</span> <span class="mi">394363</span><span class="p">:</span><span class="mf">0.7987179756164551</span> <span class="mi">458442</span><span class="p">:</span><span class="mf">0.56873309612274</span><span class="o">...</span>
<span class="mf">0.0</span> <span class="mi">89361</span><span class="p">:</span><span class="mf">0.9099966287612915</span> <span class="mi">141813</span><span class="p">:</span><span class="mf">0.5927085280418396</span> <span class="mi">282489</span><span class="p">:</span><span class="mf">0.293381005525589</span> <span class="o">...</span>
<span class="mf">0.0</span> <span class="mi">150427</span><span class="p">:</span><span class="mf">0.4747847020626068</span> <span class="mi">169376</span><span class="p">:</span><span class="mf">0.2603490948677063</span> <span class="mi">179377</span><span class="p">:</span><span class="mf">0.237988427281379</span><span class="o">...</span>
<span class="mf">0.0</span> <span class="mi">49774</span><span class="p">:</span><span class="mf">0.2822582423686981</span> <span class="mi">91245</span><span class="p">:</span><span class="mf">0.5794865489006042</span> <span class="mi">102970</span><span class="p">:</span><span class="mf">0.7004560232162476</span> <span class="o">...</span>
<span class="mf">1.0</span> <span class="mi">97133</span><span class="p">:</span><span class="mf">0.0024336236529052258</span> <span class="mi">109855</span><span class="p">:</span><span class="mf">0.9895315766334534</span> <span class="mi">116765</span><span class="p">:</span><span class="mf">0.2465638816356</span><span class="o">...</span>
<span class="mf">0.0</span> <span class="mi">803440</span><span class="p">:</span><span class="mf">0.4020800292491913</span>
</pre></div>
</div>
<p>Some storage overhead is introduced by serializing the data as characters (with spaces and colons). <code class="docutils literal"><span class="pre">dataset.libsvm</span></code> is 250 KBs but the original <code class="docutils literal"><span class="pre">data</span></code> and <code class="docutils literal"><span class="pre">label</span></code> were 132 KBs combined. Compared with the 4GB dense <code class="docutils literal"><span class="pre">NDArray</span></code> though, this isn’t a huge issue.</p>
</div>
<div class="section" id="reading-sparse-data">
<span id="reading-sparse-data"></span><h2>Reading Sparse Data<a class="headerlink" href="#reading-sparse-data" title="Permalink to this headline">¶</a></h2>
<p>Using <a class="reference external" href="https://mxnet.incubator.apache.org/api/python/io/io.html?highlight=libsvmiter"><code class="docutils literal"><span class="pre">LibSVMIter</span></code></a>, we can quickly and easily load data into batches ready for training. Although Gluon <a class="reference external" href="https://mxnet.incubator.apache.org/versions/master/api/python/gluon/data.html?highlight=dataset#mxnet.gluon.data.Dataset"><code class="docutils literal"><span class="pre">Dataset</span></code></a>s can be written to return sparse arrays, Gluon <a class="reference external" href="https://mxnet.incubator.apache.org/versions/master/api/python/gluon/data.html?highlight=dataloader#mxnet.gluon.data.DataLoader"><code class="docutils literal"><span class="pre">DataLoader</span></code></a>s currently convert each sample to dense before stacking up to create the batch. As a result, <a class="reference external" href="https://mxnet.incubator.apache.org/api/python/io/io.html?highlight=libsvmiter"><code class="docutils literal"><span class="pre">LibSVMIter</span></code></a> is the recommended method of loading sparse data in batches.</p>
<p>Similar to using a <a class="reference external" href="https://mxnet.incubator.apache.org/versions/master/api/python/gluon/data.html?highlight=dataloader#mxnet.gluon.data.DataLoader"><code class="docutils literal"><span class="pre">DataLoader</span></code></a>, you must specify the required <code class="docutils literal"><span class="pre">batch_size</span></code>. Since we’re dealing with sparse data and the column shape isn’t explicitly stored in the LibSVM file, we additionally need to provide the shape of the data and label. Our <a class="reference external" href="https://mxnet.incubator.apache.org/api/python/io/io.html?highlight=libsvmiter"><code class="docutils literal"><span class="pre">LibSVMIter</span></code></a> returns batches in a slightly different form to a <a class="reference external" href="https://mxnet.incubator.apache.org/versions/master/api/python/gluon/data.html?highlight=dataloader#mxnet.gluon.data.DataLoader"><code class="docutils literal"><span class="pre">DataLoader</span></code></a>. We get <code class="docutils literal"><span class="pre">DataBatch</span></code> objects instead of <code class="docutils literal"><span class="pre">tuple</span></code>. See the <a class="reference external" href="https://mxnet.incubator.apache.org/versions/master/tutorials/gluon/datasets.html">appendix of this tutorial</a> for more information.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">data_iter</span> <span class="o">=</span> <span class="n">mx</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">LibSVMIter</span><span class="p">(</span><span class="n">data_libsvm</span><span class="o">=</span><span class="s1">'test.libsvm'</span><span class="p">,</span> <span class="n">data_shape</span><span class="o">=</span><span class="p">(</span><span class="n">num_features</span><span class="p">,),</span> <span class="n">label_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,),</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">data_iter</span><span class="p">:</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">'data.stype: {}'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">stype</span><span class="p">))</span>
    <span class="n">label</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">label</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">'label.stype: {}'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">label</span><span class="o">.</span><span class="n">stype</span><span class="p">))</span>
    <span class="k">break</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">data</span><span class="o">.</span><span class="n">stype</span><span class="p">:</span> <span class="n">csr</span>
<span class="n">label</span><span class="o">.</span><span class="n">stype</span><span class="p">:</span> <span class="n">default</span>
</pre></div>
</div>
<p>We can see that <code class="docutils literal"><span class="pre">data</span></code> and <code class="docutils literal"><span class="pre">label</span></code> are in the appropriate storage formats, given their sparse and dense values respectively. We can avoid out-of-memory issues that might have occurred if <code class="docutils literal"><span class="pre">data</span></code> was in dense storage format. Another benefit of storing the data efficiently is the reduced data transfer time when using GPUs. Although the transfer time for a single batch is small, we transfer <code class="docutils literal"><span class="pre">data</span></code> and <code class="docutils literal"><span class="pre">label</span></code> to the GPU every iteration so this time can become significant. We will time the transfer of the sparse <code class="docutils literal"><span class="pre">data</span></code> to GPU (if available) and compare to the time for its dense counterpart.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">ctx</span> <span class="o">=</span> <span class="n">mx</span><span class="o">.</span><span class="n">gpu</span><span class="p">()</span> <span class="k">if</span> <span class="n">mx</span><span class="o">.</span><span class="n">test_utils</span><span class="o">.</span><span class="n">list_gpus</span><span class="p">()</span> <span class="k">else</span> <span class="n">mx</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">timeit</span>
<span class="n">data_on_ctx</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">as_in_context</span><span class="p">(</span><span class="n">ctx</span><span class="p">)</span>
<span class="n">data_on_ctx</span><span class="o">.</span><span class="n">wait_to_read</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="mi">192</span> <span class="n">microseconds</span> <span class="o">+-</span> <span class="mf">51.1</span> <span class="n">microseconds</span> <span class="n">per</span> <span class="n">loop</span> <span class="p">(</span><span class="n">mean</span> <span class="o">+-</span> <span class="n">std</span><span class="o">.</span> <span class="n">dev</span><span class="o">.</span> <span class="n">of</span> <span class="mi">7</span> <span class="n">runs</span><span class="p">,</span> <span class="mi">1</span> <span class="n">loop</span> <span class="n">each</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="s1">'sparse batch: {} MBs'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">get_nbytes</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="o">/</span><span class="mi">1000000</span><span class="p">))</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">tostype</span><span class="p">(</span><span class="s1">'default'</span><span class="p">)</span>  <span class="c1"># avoid timing this sparse to dense conversion</span>
<span class="k">print</span><span class="p">(</span><span class="s1">'dense batch: {} MBs'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">get_nbytes</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="o">/</span><span class="mi">1000000</span><span class="p">))</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">sparse</span> <span class="n">batch</span><span class="p">:</span> <span class="mf">0.001348</span> <span class="n">MBs</span>
<span class="n">dense</span> <span class="n">batch</span><span class="p">:</span> <span class="mf">40.0</span> <span class="n">MBs</span>
</pre></div>
</div>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">timeit</span>
<span class="n">data_on_ctx</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">as_in_context</span><span class="p">(</span><span class="n">ctx</span><span class="p">)</span>
<span class="n">data_on_ctx</span><span class="o">.</span><span class="n">wait_to_read</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="mi">4</span> <span class="n">ms</span> <span class="o">+-</span> <span class="mf">36.8</span> <span class="n">microseconds</span> <span class="n">per</span> <span class="n">loop</span> <span class="p">(</span><span class="n">mean</span> <span class="o">+-</span> <span class="n">std</span><span class="o">.</span> <span class="n">dev</span><span class="o">.</span> <span class="n">of</span> <span class="mi">7</span> <span class="n">runs</span><span class="p">,</span> <span class="mi">100</span> <span class="n">loops</span> <span class="n">each</span><span class="p">)</span>
</pre></div>
</div>
<p>Although results will change depending on system specifications and degree of sparsity, the sparse array can be transferred from CPU to GPU significantly faster than the dense array. We see a ~25x speed up for sparse vs dense for this specific batch of data.</p>
</div>
<div class="section" id="gluon-models-for-sparse-data">
<span id="gluon-models-for-sparse-data"></span><h2>Gluon Models for Sparse Data<a class="headerlink" href="#gluon-models-for-sparse-data" title="Permalink to this headline">¶</a></h2>
<p>Our next step is to define a network. We have an input of 1,000,000 features and we want to make a binary prediction. We don’t have any spatial or temporal relationships between features, so we’ll use a 3 layer fully-connected network where the last layer has 1 output unit (with sigmoid activation). Since we’re working with sparse data, we’d ideally like to use network operators that can exploit this sparsity for improved performance and memory efficiency.</p>
<p>Gluon’s <a class="reference external" href="https://mxnet.incubator.apache.org/versions/master/api/python/gluon/nn.html?highlight=dense#mxnet.gluon.nn.Dense"><code class="docutils literal"><span class="pre">nn.Dense</span></code></a> block can used with <a class="reference external" href="https://mxnet.incubator.apache.org/api/python/ndarray/sparse.html?highlight=csrndarray#mxnet.ndarray.sparse.CSRNDArray"><code class="docutils literal"><span class="pre">CSRNDArray</span></code></a> input arrays but it doesn’t exploit the sparsity. Under the hood, <a class="reference external" href="https://mxnet.incubator.apache.org/versions/master/api/python/gluon/nn.html?highlight=dense#mxnet.gluon.nn.Dense"><code class="docutils literal"><span class="pre">Dense</span></code></a> uses the <a class="reference external" href="https://mxnet.incubator.apache.org/versions/master/api/python/ndarray/ndarray.html?highlight=fullyconnected#mxnet.ndarray.FullyConnected"><code class="docutils literal"><span class="pre">FullyConnected</span></code></a> operator which isn’t optimized for <a class="reference external" href="https://mxnet.incubator.apache.org/api/python/ndarray/sparse.html?highlight=csrndarray#mxnet.ndarray.sparse.CSRNDArray"><code class="docutils literal"><span class="pre">CSRNDArray</span></code></a> arrays. We’ll implement a <code class="docutils literal"><span class="pre">Block</span></code> that does exploit this sparsity, <em>but first</em>, let’s just remind ourselves of the <a class="reference external" href="https://mxnet.incubator.apache.org/versions/master/api/python/gluon/nn.html?highlight=dense#mxnet.gluon.nn.Dense"><code class="docutils literal"><span class="pre">Dense</span></code></a> implementation by creating an equivalent <code class="docutils literal"><span class="pre">Block</span></code> called <code class="docutils literal"><span class="pre">FullyConnected</span></code>.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">FullyConnected</span><span class="p">(</span><span class="n">mx</span><span class="o">.</span><span class="n">gluon</span><span class="o">.</span><span class="n">HybridBlock</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_units</span><span class="p">,</span> <span class="n">units</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">FullyConnected</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">name_scope</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_units</span> <span class="o">=</span> <span class="n">units</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">'weight'</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">units</span><span class="p">,</span> <span class="n">in_units</span><span class="p">),</span>
                                          <span class="n">init</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">allow_deferred_init</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                                          <span class="n">dtype</span><span class="o">=</span><span class="s1">'float32'</span><span class="p">,</span> <span class="n">stype</span><span class="o">=</span><span class="s1">'default'</span><span class="p">,</span> <span class="n">grad_stype</span><span class="o">=</span><span class="s1">'default'</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">'bias'</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">units</span><span class="p">),</span>
                                          <span class="n">init</span><span class="o">=</span><span class="s1">'zeros'</span><span class="p">,</span> <span class="n">allow_deferred_init</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                                          <span class="n">dtype</span><span class="o">=</span><span class="s1">'float32'</span><span class="p">,</span> <span class="n">stype</span><span class="o">=</span><span class="s1">'default'</span><span class="p">,</span> <span class="n">grad_stype</span><span class="o">=</span><span class="s1">'default'</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">hybrid_forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">F</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">FullyConnected</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">num_hidden</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_units</span><span class="p">)</span>
</pre></div>
</div>
<p>Our <code class="docutils literal"><span class="pre">weight</span></code> and <code class="docutils literal"><span class="pre">bias</span></code> parameters are dense (see <code class="docutils literal"><span class="pre">stype='default'</span></code>) and so are their gradients (see <code class="docutils literal"><span class="pre">grad_stype='default'</span></code>). Our <code class="docutils literal"><span class="pre">weight</span></code> parameter has shape <code class="docutils literal"><span class="pre">(units,</span> <span class="pre">in_units)</span></code> because the <a class="reference external" href="https://mxnet.incubator.apache.org/versions/master/api/python/ndarray/ndarray.html?highlight=fullyconnected#mxnet.ndarray.FullyConnected"><code class="docutils literal"><span class="pre">FullyConnected</span></code></a> operator performs the following calculation:</p>
<p>$$Y = XW^T + b$$</p>
<p>We could instead have created our parameter with shape <code class="docutils literal"><span class="pre">(in_units,</span> <span class="pre">units)</span></code> and avoid the transpose of the weight matrix. We’ll see why this is so important later on. And instead of <a class="reference external" href="https://mxnet.incubator.apache.org/versions/master/api/python/ndarray/ndarray.html?highlight=fullyconnected#mxnet.ndarray.FullyConnected"><code class="docutils literal"><span class="pre">FullyConnected</span></code></a> we could have used <a class="reference external" href="https://mxnet.incubator.apache.org/versions/master/api/python/ndarray/sparse.html?highlight=sparse.dot#mxnet.ndarray.sparse.dot"><code class="docutils literal"><span class="pre">mx.sparse.dot</span></code></a> to fully exploit the sparsity of the <a class="reference external" href="https://mxnet.incubator.apache.org/api/python/ndarray/sparse.html?highlight=csrndarray#mxnet.ndarray.sparse.CSRNDArray"><code class="docutils literal"><span class="pre">CSRNDArray</span></code></a> input arrays. We’ll now implement an alternative <code class="docutils literal"><span class="pre">Block</span></code> called <code class="docutils literal"><span class="pre">FullyConnectedSparse</span></code> using these ideas. We take <code class="docutils literal"><span class="pre">grad_stype</span></code> of the <code class="docutils literal"><span class="pre">weight</span></code> as an argument (called <code class="docutils literal"><span class="pre">weight_grad_stype</span></code>), since we’re going to change this later on.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">FullyConnectedSparse</span><span class="p">(</span><span class="n">mx</span><span class="o">.</span><span class="n">gluon</span><span class="o">.</span><span class="n">HybridBlock</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_units</span><span class="p">,</span> <span class="n">units</span><span class="p">,</span> <span class="n">weight_grad_stype</span><span class="o">=</span><span class="s1">'default'</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">FullyConnectedSparse</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">name_scope</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_units</span> <span class="o">=</span> <span class="n">units</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">'weight'</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">in_units</span><span class="p">,</span> <span class="n">units</span><span class="p">),</span>
                                          <span class="n">init</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">allow_deferred_init</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                                          <span class="n">dtype</span><span class="o">=</span><span class="s1">'float32'</span><span class="p">,</span> <span class="n">stype</span><span class="o">=</span><span class="s1">'default'</span><span class="p">,</span> <span class="n">grad_stype</span><span class="o">=</span><span class="n">weight_grad_stype</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">'bias'</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">units</span><span class="p">),</span>
                                          <span class="n">init</span><span class="o">=</span><span class="s1">'zeros'</span><span class="p">,</span> <span class="n">allow_deferred_init</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                                          <span class="n">dtype</span><span class="o">=</span><span class="s1">'float32'</span><span class="p">,</span> <span class="n">stype</span><span class="o">=</span><span class="s1">'default'</span><span class="p">,</span> <span class="n">grad_stype</span><span class="o">=</span><span class="s1">'default'</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">hybrid_forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">F</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">sparse</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">weight</span><span class="p">)</span> <span class="o">+</span> <span class="n">bias</span>
</pre></div>
</div>
<p>Once again, we’re using a dense <code class="docutils literal"><span class="pre">weight</span></code>, so both <code class="docutils literal"><span class="pre">FullyConnected</span></code> and <code class="docutils literal"><span class="pre">FullyConnectedSparse</span></code> will return dense array outputs. When constructing a multi-layer network therefore, only the first layer needs to be optimized for sparse inputs. Our first layer is often responsible for reducing the feature dimension dramatically (e.g. 1,000,000 features down to 128 features). We’ll set the number of units in our 3 layers to be 128, 8 and 1.</p>
<p>We will use <a class="reference external" href="https://docs.python.org/2/library/timeit.html"><code class="docutils literal"><span class="pre">timeit</span></code></a> to check the performance of these two variants, and analyse some <a class="reference external" href="https://mxnet.incubator.apache.org/versions/master/tutorials/python/profiler.html">MXNet Profiler</a> traces that have been created from these benchmarks. Additionally, we will inspect the memory usage of the weights (and gradients) using the <code class="docutils literal"><span class="pre">print_memory_allocation</span></code> function defined below:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">print_memory_allocation</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">block_idxs</span><span class="p">):</span>
    <span class="n">blocks</span> <span class="o">=</span> <span class="p">[</span><span class="n">net</span><span class="p">[</span><span class="n">block_idx</span><span class="p">]</span> <span class="k">for</span> <span class="n">block_idx</span> <span class="ow">in</span> <span class="n">block_idxs</span><span class="p">]</span>
    <span class="n">weight_nbytes</span> <span class="o">=</span> <span class="p">[</span><span class="n">get_nbytes</span><span class="p">(</span><span class="n">b</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">())</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">blocks</span><span class="p">]</span>
    <span class="n">weight_nbytes_pct</span> <span class="o">=</span> <span class="p">[</span><span class="n">b</span><span class="o">/</span><span class="nb">sum</span><span class="p">(</span><span class="n">weight_nbytes</span><span class="p">)</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">weight_nbytes</span><span class="p">]</span>
    <span class="n">weight_grad_nbytes</span> <span class="o">=</span> <span class="p">[</span><span class="n">get_nbytes</span><span class="p">(</span><span class="n">b</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">grad</span><span class="p">())</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">blocks</span><span class="p">]</span>
    <span class="n">weight_grad_nbytes_pct</span> <span class="o">=</span> <span class="p">[</span><span class="n">b</span><span class="o">/</span><span class="nb">sum</span><span class="p">(</span><span class="n">weight_grad_nbytes</span><span class="p">)</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">weight_grad_nbytes</span><span class="p">]</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">"Memory Allocation for Weight:"</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">block_idxs</span><span class="p">)):</span>
        <span class="k">print</span><span class="p">(</span><span class="s1">'{:7.3f} MBs ({:7.3f}%) for {:<40}'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">weight_nbytes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">/</span><span class="mi">1000000</span><span class="p">,</span>
                                                              <span class="n">weight_nbytes_pct</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span>
                                                              <span class="n">blocks</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">name</span><span class="p">))</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">"Memory Allocation for Weight Gradient:"</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">block_idxs</span><span class="p">)):</span>
        <span class="k">print</span><span class="p">(</span><span class="s1">'{:7.3f} MBs ({:7.3f}%) for {:<40}'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">weight_grad_nbytes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">/</span><span class="mi">1000000</span><span class="p">,</span>
                                                              <span class="n">weight_grad_nbytes_pct</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span>
                                                              <span class="n">blocks</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">name</span><span class="p">))</span>
</pre></div>
</div>
<div class="section" id="benchmark-fullyconnected">
<span id="benchmark-fullyconnected"></span><h3>Benchmark: <code class="docutils literal"><span class="pre">FullyConnected</span></code><a class="headerlink" href="#benchmark-fullyconnected" title="Permalink to this headline">¶</a></h3>
<p>We’ll create a network using <code class="docutils literal"><span class="pre">nn.Dense</span></code> and benchmark the training.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">net</span> <span class="o">=</span> <span class="n">mx</span><span class="o">.</span><span class="n">gluon</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
<span class="n">net</span><span class="o">.</span><span class="n">add</span><span class="p">(</span>
    <span class="n">mx</span><span class="o">.</span><span class="n">gluon</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">in_units</span><span class="o">=</span><span class="n">num_features</span><span class="p">,</span> <span class="n">units</span><span class="o">=</span><span class="mi">128</span><span class="p">),</span>
    <span class="n">mx</span><span class="o">.</span><span class="n">gluon</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Activation</span><span class="p">(</span><span class="s1">'sigmoid'</span><span class="p">),</span>
    <span class="n">mx</span><span class="o">.</span><span class="n">gluon</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">in_units</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">units</span><span class="o">=</span><span class="mi">8</span><span class="p">),</span>
    <span class="n">mx</span><span class="o">.</span><span class="n">gluon</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Activation</span><span class="p">(</span><span class="s1">'sigmoid'</span><span class="p">),</span>
    <span class="n">mx</span><span class="o">.</span><span class="n">gluon</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">in_units</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">units</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
    <span class="n">mx</span><span class="o">.</span><span class="n">gluon</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Activation</span><span class="p">(</span><span class="s1">'sigmoid'</span><span class="p">),</span>
<span class="p">)</span>
<span class="n">net</span><span class="o">.</span><span class="n">initialize</span><span class="p">(</span><span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">)</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">mx</span><span class="o">.</span><span class="n">gluon</span><span class="o">.</span><span class="n">Trainer</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">collect_params</span><span class="p">(),</span> <span class="s1">'sgd'</span><span class="p">)</span>
<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">mx</span><span class="o">.</span><span class="n">gluon</span><span class="o">.</span><span class="n">loss</span><span class="o">.</span><span class="n">SigmoidBinaryCrossEntropyLoss</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">timeit</span>
<span class="n">data_iter</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
<span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">data_iter</span><span class="p">:</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">as_in_context</span><span class="p">(</span><span class="n">ctx</span><span class="p">)</span>
    <span class="n">label</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">label</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">as_in_context</span><span class="p">(</span><span class="n">ctx</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">mx</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">record</span><span class="p">():</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">trainer</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">wait_to_read</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="mi">532</span> <span class="n">ms</span> <span class="o">+-</span> <span class="mf">3.47</span> <span class="n">ms</span> <span class="n">per</span> <span class="n">loop</span> <span class="p">(</span><span class="n">mean</span> <span class="o">+-</span> <span class="n">std</span><span class="o">.</span> <span class="n">dev</span><span class="o">.</span> <span class="n">of</span> <span class="mi">7</span> <span class="n">runs</span><span class="p">,</span> <span class="mi">1</span> <span class="n">loop</span> <span class="n">each</span><span class="p">)</span>
</pre></div>
</div>
<p><img alt="fully connected" src="https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/doc/tutorials/ndarray/sparse/fully_connected.png"/></p>
<p>We can see the first <a class="reference external" href="https://mxnet.incubator.apache.org/versions/master/api/python/ndarray/ndarray.html?highlight=fullyconnected#mxnet.ndarray.FullyConnected"><code class="docutils literal"><span class="pre">FullyConnected</span></code></a> operator takes a significant proportion of time to execute (~25% of the iteration) because there are 1,000,000 input features (to 128). After this, the other <a class="reference external" href="https://mxnet.incubator.apache.org/versions/master/api/python/ndarray/ndarray.html?highlight=fullyconnected#mxnet.ndarray.FullyConnected"><code class="docutils literal"><span class="pre">FullyConnected</span></code></a> operators are much faster because they have input features of 128 (to 8) and 8 (to 1). On the backward pass, we see the same pattern (but in reverse). And finally, the parameter update step takes a large amount of time on the weight matrix of the first <code class="docutils literal"><span class="pre">FullyConnected</span></code> <code class="docutils literal"><span class="pre">Block</span></code>. When checking the memory allocations below, we can see the weight matrix of the first <code class="docutils literal"><span class="pre">FullyConnected</span></code> <code class="docutils literal"><span class="pre">Block</span></code> is responsible for 99.999% of the memory compared to other <a class="reference external" href="https://mxnet.incubator.apache.org/versions/master/api/python/ndarray/ndarray.html?highlight=fullyconnected#mxnet.ndarray.FullyConnected"><code class="docutils literal"><span class="pre">FullyConnected</span></code></a> weight matrices.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">print_memory_allocation</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">block_idxs</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">Memory</span> <span class="n">Allocation</span> <span class="k">for</span> <span class="n">Weight</span><span class="p">:</span>
<span class="mf">512.000</span> <span class="n">MBs</span> <span class="p">(</span> <span class="mf">99.999</span><span class="o">%</span><span class="p">)</span> <span class="k">for</span> <span class="n">dense0</span>                                  
  <span class="mf">0.004</span> <span class="n">MBs</span> <span class="p">(</span>  <span class="mf">0.001</span><span class="o">%</span><span class="p">)</span> <span class="k">for</span> <span class="n">dense1</span>                                  
  <span class="mf">0.000</span> <span class="n">MBs</span> <span class="p">(</span>  <span class="mf">0.000</span><span class="o">%</span><span class="p">)</span> <span class="k">for</span> <span class="n">dense2</span>                                  
<span class="n">Memory</span> <span class="n">Allocation</span> <span class="k">for</span> <span class="n">Weight</span> <span class="n">Gradient</span><span class="p">:</span>
<span class="mf">512.000</span> <span class="n">MBs</span> <span class="p">(</span> <span class="mf">99.999</span><span class="o">%</span><span class="p">)</span> <span class="k">for</span> <span class="n">dense0</span>                                  
  <span class="mf">0.004</span> <span class="n">MBs</span> <span class="p">(</span>  <span class="mf">0.001</span><span class="o">%</span><span class="p">)</span> <span class="k">for</span> <span class="n">dense1</span>                                  
  <span class="mf">0.000</span> <span class="n">MBs</span> <span class="p">(</span>  <span class="mf">0.000</span><span class="o">%</span><span class="p">)</span> <span class="k">for</span> <span class="n">dense2</span>                                  
</pre></div>
</div>
</div>
<div class="section" id="benchmark-fullyconnectedsparse">
<span id="benchmark-fullyconnectedsparse"></span><h3>Benchmark: <code class="docutils literal"><span class="pre">FullyConnectedSparse</span></code><a class="headerlink" href="#benchmark-fullyconnectedsparse" title="Permalink to this headline">¶</a></h3>
<p>We will now switch the first layer from <code class="docutils literal"><span class="pre">FullyConnected</span></code> to <code class="docutils literal"><span class="pre">FullyConnectedSparse</span></code>.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">net</span> <span class="o">=</span> <span class="n">mx</span><span class="o">.</span><span class="n">gluon</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
<span class="n">net</span><span class="o">.</span><span class="n">add</span><span class="p">(</span>
    <span class="n">FullyConnectedSparse</span><span class="p">(</span><span class="n">in_units</span><span class="o">=</span><span class="n">num_features</span><span class="p">,</span> <span class="n">units</span><span class="o">=</span><span class="mi">128</span><span class="p">),</span>
    <span class="n">mx</span><span class="o">.</span><span class="n">gluon</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Activation</span><span class="p">(</span><span class="s1">'sigmoid'</span><span class="p">),</span>
    <span class="n">FullyConnected</span><span class="p">(</span><span class="n">in_units</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">units</span><span class="o">=</span><span class="mi">8</span><span class="p">),</span>
    <span class="n">mx</span><span class="o">.</span><span class="n">gluon</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Activation</span><span class="p">(</span><span class="s1">'sigmoid'</span><span class="p">),</span>
    <span class="n">FullyConnected</span><span class="p">(</span><span class="n">in_units</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">units</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
    <span class="n">mx</span><span class="o">.</span><span class="n">gluon</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Activation</span><span class="p">(</span><span class="s1">'sigmoid'</span><span class="p">),</span>
<span class="p">)</span>
<span class="n">net</span><span class="o">.</span><span class="n">initialize</span><span class="p">(</span><span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">)</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">mx</span><span class="o">.</span><span class="n">gluon</span><span class="o">.</span><span class="n">Trainer</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">collect_params</span><span class="p">(),</span> <span class="s1">'sgd'</span><span class="p">)</span>
<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">mx</span><span class="o">.</span><span class="n">gluon</span><span class="o">.</span><span class="n">loss</span><span class="o">.</span><span class="n">SigmoidBinaryCrossEntropyLoss</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">timeit</span>
<span class="n">data_iter</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
<span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">data_iter</span><span class="p">:</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">as_in_context</span><span class="p">(</span><span class="n">ctx</span><span class="p">)</span>
    <span class="n">label</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">label</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">as_in_context</span><span class="p">(</span><span class="n">ctx</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">mx</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">record</span><span class="p">():</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">trainer</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">wait_to_read</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="mi">528</span> <span class="n">ms</span> <span class="o">+-</span> <span class="mf">22.7</span> <span class="n">ms</span> <span class="n">per</span> <span class="n">loop</span> <span class="p">(</span><span class="n">mean</span> <span class="o">+-</span> <span class="n">std</span><span class="o">.</span> <span class="n">dev</span><span class="o">.</span> <span class="n">of</span> <span class="mi">7</span> <span class="n">runs</span><span class="p">,</span> <span class="mi">1</span> <span class="n">loop</span> <span class="n">each</span><span class="p">)</span>
</pre></div>
</div>
<p><img alt="fully connected sparse" src="https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/doc/tutorials/ndarray/sparse/fully_connected_sparse.png"/></p>
<p>We see the forward pass of <code class="docutils literal"><span class="pre">dot</span></code> and <code class="docutils literal"><span class="pre">add</span></code> (equivalent to <a class="reference external" href="https://mxnet.incubator.apache.org/versions/master/api/python/ndarray/ndarray.html?highlight=fullyconnected#mxnet.ndarray.FullyConnected"><code class="docutils literal"><span class="pre">FullyConnected</span></code></a> operator) is much faster now: 1.54ms vs 0.26ms. And this explains the reduction in overall time for the epoch. We didn’t gain any benefit on the backward pass or parameter updates though.</p>
<p><img alt="fully connected sparse backward" src="https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/doc/tutorials/ndarray/sparse/fully_connected_sparse_backward.png"/></p>
<p>Our first weight matrix and its gradients still take up the same amount of memory as before.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">print_memory_allocation</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">block_idxs</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">Memory</span> <span class="n">Allocation</span> <span class="k">for</span> <span class="n">Weight</span><span class="p">:</span>
<span class="mf">512.000</span> <span class="n">MBs</span> <span class="p">(</span> <span class="mf">99.999</span><span class="o">%</span><span class="p">)</span> <span class="k">for</span> <span class="n">fullyconnectedsparse0</span>                   
  <span class="mf">0.004</span> <span class="n">MBs</span> <span class="p">(</span>  <span class="mf">0.001</span><span class="o">%</span><span class="p">)</span> <span class="k">for</span> <span class="n">fullyconnected0</span>                         
  <span class="mf">0.000</span> <span class="n">MBs</span> <span class="p">(</span>  <span class="mf">0.000</span><span class="o">%</span><span class="p">)</span> <span class="k">for</span> <span class="n">fullyconnected1</span>                         
<span class="n">Memory</span> <span class="n">Allocation</span> <span class="k">for</span> <span class="n">Weight</span> <span class="n">Gradient</span><span class="p">:</span>
<span class="mf">512.000</span> <span class="n">MBs</span> <span class="p">(</span> <span class="mf">99.999</span><span class="o">%</span><span class="p">)</span> <span class="k">for</span> <span class="n">fullyconnectedsparse0</span>                   
  <span class="mf">0.004</span> <span class="n">MBs</span> <span class="p">(</span>  <span class="mf">0.001</span><span class="o">%</span><span class="p">)</span> <span class="k">for</span> <span class="n">fullyconnected0</span>                         
  <span class="mf">0.000</span> <span class="n">MBs</span> <span class="p">(</span>  <span class="mf">0.000</span><span class="o">%</span><span class="p">)</span> <span class="k">for</span> <span class="n">fullyconnected1</span>                         
</pre></div>
</div>
</div>
<div class="section" id="benchmark-fullyconnectedsparse-with-grad-stype-row-sparse">
<span id="benchmark-fullyconnectedsparse-with-grad-stype-row-sparse"></span><h3>Benchmark: <code class="docutils literal"><span class="pre">FullyConnectedSparse</span></code> with <code class="docutils literal"><span class="pre">grad_stype=row_sparse</span></code><a class="headerlink" href="#benchmark-fullyconnectedsparse-with-grad-stype-row-sparse" title="Permalink to this headline">¶</a></h3>
<p>One useful outcome of sparsity in our <a class="reference external" href="https://mxnet.incubator.apache.org/api/python/ndarray/sparse.html?highlight=csrndarray#mxnet.ndarray.sparse.CSRNDArray"><code class="docutils literal"><span class="pre">CSRNDArray</span></code></a> input is that our gradients will be row sparse. We can exploit this fact to give us potentially huge memory savings and speed improvements. Creating our <code class="docutils literal"><span class="pre">weight</span></code> parameter with shape <code class="docutils literal"><span class="pre">(units,</span> <span class="pre">in_units)</span></code> and not transposing in the forward pass are important pre-requisite for obtaining row sparse gradients. Using <a class="reference external" href="https://mxnet.incubator.apache.org/versions/master/api/python/gluon/nn.html?highlight=dense#mxnet.gluon.nn.Dense"><code class="docutils literal"><span class="pre">nn.Dense</span></code></a> would have led to column sparse gradients which are not supported in MXNet. We previously had <code class="docutils literal"><span class="pre">grad_stype</span></code> of the <code class="docutils literal"><span class="pre">weight</span></code> parameter in the first layer set to <code class="docutils literal"><span class="pre">'default'</span></code> so we were handling the gradient as a dense array. Switching this to <code class="docutils literal"><span class="pre">'row_sparse'</span></code> can give us these potential improvements.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">net</span> <span class="o">=</span> <span class="n">mx</span><span class="o">.</span><span class="n">gluon</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
<span class="n">net</span><span class="o">.</span><span class="n">add</span><span class="p">(</span>
    <span class="n">FullyConnectedSparse</span><span class="p">(</span><span class="n">in_units</span><span class="o">=</span><span class="n">num_features</span><span class="p">,</span> <span class="n">units</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">weight_grad_stype</span><span class="o">=</span><span class="s1">'row_sparse'</span><span class="p">),</span>
    <span class="n">mx</span><span class="o">.</span><span class="n">gluon</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Activation</span><span class="p">(</span><span class="s1">'sigmoid'</span><span class="p">),</span>
    <span class="n">FullyConnected</span><span class="p">(</span><span class="n">in_units</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">units</span><span class="o">=</span><span class="mi">8</span><span class="p">),</span>
    <span class="n">mx</span><span class="o">.</span><span class="n">gluon</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Activation</span><span class="p">(</span><span class="s1">'sigmoid'</span><span class="p">),</span>
    <span class="n">FullyConnected</span><span class="p">(</span><span class="n">in_units</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">units</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
    <span class="n">mx</span><span class="o">.</span><span class="n">gluon</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Activation</span><span class="p">(</span><span class="s1">'sigmoid'</span><span class="p">),</span>
<span class="p">)</span>
<span class="n">net</span><span class="o">.</span><span class="n">initialize</span><span class="p">(</span><span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">)</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">mx</span><span class="o">.</span><span class="n">gluon</span><span class="o">.</span><span class="n">Trainer</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">collect_params</span><span class="p">(),</span> <span class="s1">'sgd'</span><span class="p">)</span>
<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">mx</span><span class="o">.</span><span class="n">gluon</span><span class="o">.</span><span class="n">loss</span><span class="o">.</span><span class="n">SigmoidBinaryCrossEntropyLoss</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">timeit</span>
<span class="n">data_iter</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
<span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">data_iter</span><span class="p">:</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">as_in_context</span><span class="p">(</span><span class="n">ctx</span><span class="p">)</span>
    <span class="n">label</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">label</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">as_in_context</span><span class="p">(</span><span class="n">ctx</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">mx</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">record</span><span class="p">():</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">trainer</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">wait_to_read</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="mi">334</span> <span class="n">ms</span> <span class="o">+-</span> <span class="mf">16.9</span> <span class="n">ms</span> <span class="n">per</span> <span class="n">loop</span> <span class="p">(</span><span class="n">mean</span> <span class="o">+-</span> <span class="n">std</span><span class="o">.</span> <span class="n">dev</span><span class="o">.</span> <span class="n">of</span> <span class="mi">7</span> <span class="n">runs</span><span class="p">,</span> <span class="mi">1</span> <span class="n">loop</span> <span class="n">each</span><span class="p">)</span>
</pre></div>
</div>
<p><img alt="fully connected sparse grad backward" src="https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/doc/tutorials/ndarray/sparse/fully_connected_sparse_grad_backward.png"/></p>
<p>We can see a huge reduction in the time taken for the backward pass and parameter update step: 3.99ms vs 0.18ms. And this reduces the overall time of the epoch significantly. Our gradient consumes a much smaller amount of memory and means only a subset of parameters need updating as part of the <code class="docutils literal"><span class="pre">sgd_update</span></code> step. Some optimizers don’t support sparse gradients however, so reference the specific optimizer’s documentation for more details.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">print_memory_allocation</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">block_idxs</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">Memory</span> <span class="n">Allocation</span> <span class="k">for</span> <span class="n">Weight</span><span class="p">:</span>
<span class="mf">512.000</span> <span class="n">MBs</span> <span class="p">(</span> <span class="mf">99.999</span><span class="o">%</span><span class="p">)</span> <span class="k">for</span> <span class="n">fullyconnectedsparse1</span>                   
  <span class="mf">0.004</span> <span class="n">MBs</span> <span class="p">(</span>  <span class="mf">0.001</span><span class="o">%</span><span class="p">)</span> <span class="k">for</span> <span class="n">fullyconnected2</span>                         
  <span class="mf">0.000</span> <span class="n">MBs</span> <span class="p">(</span>  <span class="mf">0.000</span><span class="o">%</span><span class="p">)</span> <span class="k">for</span> <span class="n">fullyconnected3</span>                         
<span class="n">Memory</span> <span class="n">Allocation</span> <span class="k">for</span> <span class="n">Weight</span> <span class="n">Gradient</span><span class="p">:</span>
  <span class="mf">0.059</span> <span class="n">MBs</span> <span class="p">(</span> <span class="mf">93.490</span><span class="o">%</span><span class="p">)</span> <span class="k">for</span> <span class="n">fullyconnectedsparse1</span>                   
  <span class="mf">0.004</span> <span class="n">MBs</span> <span class="p">(</span>  <span class="mf">6.460</span><span class="o">%</span><span class="p">)</span> <span class="k">for</span> <span class="n">fullyconnected2</span>                         
  <span class="mf">0.000</span> <span class="n">MBs</span> <span class="p">(</span>  <span class="mf">0.050</span><span class="o">%</span><span class="p">)</span> <span class="k">for</span> <span class="n">fullyconnected3</span>                         
</pre></div>
</div>
</div>
<div class="section" id="advanced-sparse-weight">
<span id="advanced-sparse-weight"></span><h3>Advanced: Sparse <code class="docutils literal"><span class="pre">weight</span></code><a class="headerlink" href="#advanced-sparse-weight" title="Permalink to this headline">¶</a></h3>
<p>You can optimize this example further by setting the weight’s <code class="docutils literal"><span class="pre">stype</span></code> to <code class="docutils literal"><span class="pre">'row_sparse'</span></code>, but whether <code class="docutils literal"><span class="pre">'row_sparse'</span></code> weights make sense or not will depends on your specific task. See <a class="reference external" href="https://github.com/apache/incubator-mxnet/blob/master/python/mxnet/gluon/contrib/nn/basic_layers.py#L118"><code class="docutils literal"><span class="pre">contrib.SparseEmbedding</span></code></a> for an example of this.</p>
</div>
</div>
</div>
<div class="section" id="conclusion">
<span id="conclusion"></span><h1>Conclusion<a class="headerlink" href="#conclusion" title="Permalink to this headline">¶</a></h1>
<p>As part of this tutorial, we learned how to write sparse data to disk in LibSVM format and load it back in sparse batches with the <a class="reference external" href="https://mxnet.incubator.apache.org/api/python/io/io.html?highlight=libsvmiter"><code class="docutils literal"><span class="pre">LibSVMIter</span></code></a>. We learned how to improve the performance of Gluon’s <a class="reference external" href="https://mxnet.incubator.apache.org/versions/master/api/python/gluon/nn.html?highlight=dense#mxnet.gluon.nn.Dense"><code class="docutils literal"><span class="pre">nn.Dense</span></code></a> on sparse arrays using <code class="docutils literal"><span class="pre">mx.nd.sparse</span></code>. And lastly, we set <code class="docutils literal"><span class="pre">grad_stype</span></code> to <code class="docutils literal"><span class="pre">'row_sparse'</span></code> to reduce the size of the gradient and speed up the parameter update step.</p>
<div class="section" id="recommended-next-steps">
<span id="recommended-next-steps"></span><h2>Recommended Next Steps<a class="headerlink" href="#recommended-next-steps" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>More detail on the <a class="reference external" href="https://mxnet.incubator.apache.org/api/python/ndarray/sparse.html?highlight=csrndarray#mxnet.ndarray.sparse.CSRNDArray"><code class="docutils literal"><span class="pre">CSRNDArray</span></code></a> sparse array format can be found in <a class="reference external" href="https://mxnet.incubator.apache.org/versions/master/tutorials/sparse/csr.html">this tutorial</a>.</li>
<li>More detail on the <a class="reference external" href="https://mxnet.incubator.apache.org/api/python/ndarray/sparse.html?highlight=rowsparsendarray#mxnet.ndarray.sparse.RowSparseNDArray"><code class="docutils literal"><span class="pre">RowSparseNDArray</span></code></a> sparse array format can be found in <a class="reference external" href="https://mxnet.incubator.apache.org/versions/master/tutorials/sparse/row_sparse.html">this tutorial</a>.</li>
<li>Users of the Module API can see a symbolic only example in <a class="reference external" href="https://mxnet.incubator.apache.org/versions/master/tutorials/sparse/train.html">this tutorial</a>.</li>
</ul>
<div class="btn-group" role="group">
<div class="download-btn"><a download="train_gluon.ipynb" href="train_gluon.ipynb"><span class="glyphicon glyphicon-download-alt"></span> train_gluon.ipynb</a></div></div></div>
</div>
</div>
</div>
<div aria-label="main navigation" class="sphinxsidebar rightsidebar" role="navigation">
<div class="sphinxsidebarwrapper">
<h3><a href="../../index.html">Table Of Contents</a></h3>
<ul>
<li><a class="reference internal" href="#">Sparse NDArrays with Gluon</a><ul>
<li><a class="reference internal" href="#generating-sparse-data">Generating Sparse Data</a></li>
<li><a class="reference internal" href="#writing-sparse-data">Writing Sparse Data</a></li>
<li><a class="reference internal" href="#reading-sparse-data">Reading Sparse Data</a></li>
<li><a class="reference internal" href="#gluon-models-for-sparse-data">Gluon Models for Sparse Data</a><ul>
<li><a class="reference internal" href="#benchmark-fullyconnected">Benchmark: <code class="docutils literal"><span class="pre">FullyConnected</span></code></a></li>
<li><a class="reference internal" href="#benchmark-fullyconnectedsparse">Benchmark: <code class="docutils literal"><span class="pre">FullyConnectedSparse</span></code></a></li>
<li><a class="reference internal" href="#benchmark-fullyconnectedsparse-with-grad-stype-row-sparse">Benchmark: <code class="docutils literal"><span class="pre">FullyConnectedSparse</span></code> with <code class="docutils literal"><span class="pre">grad_stype=row_sparse</span></code></a></li>
<li><a class="reference internal" href="#advanced-sparse-weight">Advanced: Sparse <code class="docutils literal"><span class="pre">weight</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#conclusion">Conclusion</a><ul>
<li><a class="reference internal" href="#recommended-next-steps">Recommended Next Steps</a></li>
</ul>
</li>
</ul>
</div>
</div>
</div><div class="footer">
<div class="section-disclaimer">
<div class="container">
<div>
<img height="60" src="https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/image/apache_incubator_logo.png"/>
<p>
            Apache MXNet is an effort undergoing incubation at The Apache Software Foundation (ASF), <strong>sponsored by the <i>Apache Incubator</i></strong>. Incubation is required of all newly accepted projects until a further review indicates that the infrastructure, communications, and decision making process have stabilized in a manner consistent with other successful ASF projects. While incubation status is not necessarily a reflection of the completeness or stability of the code, it does indicate that the project has yet to be fully endorsed by the ASF.
        </p>
<p>
            "Copyright © 2017-2018, The Apache Software Foundation
            Apache MXNet, MXNet, Apache, the Apache feather, and the Apache MXNet project logo are either registered trademarks or trademarks of the Apache Software Foundation."
        </p>
</div>
</div>
</div>
</div> <!-- pagename != index -->
</div>
<script crossorigin="anonymous" integrity="sha384-0mSbJDEHialfmuBBQP6A4Qrprq5OVfW37PRR3j5ELqxss1yVqOtnepnHVP9aJ7xS" src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/js/bootstrap.min.js"></script>
<script src="../../_static/js/sidebar.js" type="text/javascript"></script>
<script src="../../_static/js/search.js" type="text/javascript"></script>
<script src="../../_static/js/navbar.js" type="text/javascript"></script>
<script src="../../_static/js/clipboard.min.js" type="text/javascript"></script>
<script src="../../_static/js/copycode.js" type="text/javascript"></script>
<script src="../../_static/js/page.js" type="text/javascript"></script>
<script src="../../_static/js/docversion.js" type="text/javascript"></script>
<script type="text/javascript">
        $('body').ready(function () {
            $('body').css('visibility', 'visible');
        });
    </script>
</body>
</html>