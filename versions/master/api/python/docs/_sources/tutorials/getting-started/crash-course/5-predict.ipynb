{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--- Licensed to the Apache Software Foundation (ASF) under one -->\n",
    "<!--- or more contributor license agreements.  See the NOTICE file -->\n",
    "<!--- distributed with this work for additional information -->\n",
    "<!--- regarding copyright ownership.  The ASF licenses this file -->\n",
    "<!--- to you under the Apache License, Version 2.0 (the -->\n",
    "<!--- \"License\"); you may not use this file except in compliance -->\n",
    "<!--- with the License.  You may obtain a copy of the License at -->\n",
    "\n",
    "<!---   http://www.apache.org/licenses/LICENSE-2.0 -->\n",
    "\n",
    "<!--- Unless required by applicable law or agreed to in writing, -->\n",
    "<!--- software distributed under the License is distributed on an -->\n",
    "<!--- \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY -->\n",
    "<!--- KIND, either express or implied.  See the License for the -->\n",
    "<!--- specific language governing permissions and limitations -->\n",
    "<!--- under the License. -->\n",
    "\n",
    "# Step 5: Predict with a pretrained model\n",
    "\n",
    "In this step, you learn how to predict new examples using a pretrained model. A saved model can be used in multiple places, such as to continue training, to fine tune the model, and for prediction.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Before you begin the procedures here, run :label:`crash_course_train` to train the network and save its parameters to file. You use this file to run the following steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "1"
    }
   },
   "outputs": [],
   "source": [
    "from mxnet import np, npx, gluon, image\n",
    "from mxnet.gluon import nn\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "npx.set_np()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start, copy a simple model's definition by using the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "2"
    }
   },
   "outputs": [],
   "source": [
    "net = nn.Sequential()\n",
    "net.add(nn.Conv2D(channels=6, kernel_size=5, activation='relu'),\n",
    "        nn.MaxPool2D(pool_size=2, strides=2),\n",
    "        nn.Conv2D(channels=16, kernel_size=3, activation='relu'),\n",
    "        nn.MaxPool2D(pool_size=2, strides=2),\n",
    "        nn.Dense(120, activation=\"relu\"),\n",
    "        nn.Dense(84, activation=\"relu\"),\n",
    "        nn.Dense(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous step, you saved all parameters to a file. Now load it back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "3"
    }
   },
   "outputs": [],
   "source": [
    "net.load_parameters('net.params')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict\n",
    "\n",
    "Remember the data transformation you did for the training step? The following code provides the same transformation for predicting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "4"
    }
   },
   "outputs": [],
   "source": [
    "transformer = gluon.data.vision.transforms.Compose([\n",
    "    gluon.data.vision.transforms.ToTensor(),\n",
    "    gluon.data.vision.transforms.Normalize(0.13, 0.31)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the following code to predict the first six images in the validation dataset and store the predictions into `preds`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "5"
    }
   },
   "outputs": [],
   "source": [
    "mnist_valid = gluon.data.vision.datasets.FashionMNIST(train=False)\n",
    "X, y = mnist_valid[:10]\n",
    "preds = []\n",
    "for x in X:\n",
    "    x = np.expand_dims(transformer(x), axis=0)\n",
    "    pred = net(x).argmax(axis=1)\n",
    "    preds.append(int(pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, use the following code to visualize the images and compare the prediction with the ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "15"
    }
   },
   "outputs": [],
   "source": [
    "_, figs = plt.subplots(1, 10, figsize=(15, 15))\n",
    "text_labels = ['t-shirt', 'trouser', 'pullover', 'dress', 'coat',\n",
    "               'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']\n",
    "display.set_matplotlib_formats('svg')\n",
    "for f, x, yi, pyi in zip(figs, X, y, preds):\n",
    "    f.imshow(x.reshape((28,28)).asnumpy())\n",
    "    ax = f.axes\n",
    "    ax.set_title(text_labels[int(yi)]+'\\n'+text_labels[pyi])\n",
    "    ax.title.set_fontsize(14)\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict with models from Gluon model zoo\n",
    "\n",
    "\n",
    "The LeNet, trained on FashionMNIST, is a good example to start with. However, it's too simple to predict real-life pictures. In order to save the time and effort of training a large-scale model from scratch, the [Gluon model zoo](https://mxnet.incubator.apache.org/api/python/gluon/model_zoo.html) provides multiple pre-trained models. For example, with the following code example, you can download a pre-trained ResNet-50 V2 model that was trained on the ImageNet dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "7"
    }
   },
   "outputs": [],
   "source": [
    "net = gluon.model_zoo.vision.resnet50_v2(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll also need to download the text labels for each class, as in the following example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "8"
    }
   },
   "outputs": [],
   "source": [
    "url = 'http://data.mxnet.io/models/imagenet/synset.txt'\n",
    "fname = gluon.utils.download(url)\n",
    "with open(fname, 'r') as f:\n",
    "    text_labels = [' '.join(l.split()[1:]) for l in f]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following example shows how to select a dog image from Wikipedia as a test, download and read it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "9"
    }
   },
   "outputs": [],
   "source": [
    "url = 'https://upload.wikimedia.org/wikipedia/commons/thumb/b/b5/\\\n",
    "Golden_Retriever_medium-to-light-coat.jpg/\\\n",
    "365px-Golden_Retriever_medium-to-light-coat.jpg'\n",
    "fname = gluon.utils.download(url)\n",
    "x = image.imread(fname)  # TODO, use npx.image instead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the conventional way of preprocessing ImageNet data, do the following:\n",
    "\n",
    "1. Resize the short edge into 256 pixes.\n",
    "2. Perform a center crop to obtain a 224-by-224 image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "10"
    }
   },
   "outputs": [],
   "source": [
    "x = image.resize_short(x, 256)\n",
    "x, _ = image.center_crop(x, (224,224))\n",
    "plt.imshow(x.asnumpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can see it is a golden retriever. You can also infer it from the image URL.\n",
    "\n",
    "The next data transformation is similar to FashionMNIST. Here, you subtract the RGB means and divide by the corresponding variances to normalize each color channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "11"
    }
   },
   "outputs": [],
   "source": [
    "def transform(data):\n",
    "    data = np.expand_dims(np.transpose(data, (2,0,1)), axis=0)\n",
    "    rgb_mean = np.array([0.485, 0.456, 0.406]).reshape((1,3,1,1))\n",
    "    rgb_std = np.array([0.229, 0.224, 0.225]).reshape((1,3,1,1))\n",
    "    return (data.astype('float32') / 255 - rgb_mean) / rgb_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can recognize the object in the image. Perform an additional softmax on the output to obtain probability scores. Print the top-5 recognized objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "12"
    }
   },
   "outputs": [],
   "source": [
    "prob = npx.softmax(net(transform(x)))\n",
    "idx = npx.topk(prob, k=5)[0]\n",
    "for i in idx:\n",
    "    print('With prob = %.5f, it contains %s' % (\n",
    "        prob[0, int(i)], text_labels[int(i)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, the model is fairly confident that the image contains a golden retriever.\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "You might find that both training and prediction are a little bit slow. If you have a GPU\n",
    "available, learn how to accomplish your tasks faster in [Step 6: Use GPUs to increase efficiency](6-use_gpus.md)."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}